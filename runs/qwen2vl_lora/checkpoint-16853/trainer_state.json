{
  "best_global_step": 8000,
  "best_metric": 0.5076618154656621,
  "best_model_checkpoint": "runs/qwen2vl_lora\\checkpoint-8000",
  "epoch": 1.0,
  "eval_steps": 8000,
  "global_step": 16853,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0011867323325223996,
      "grad_norm": 16.058977127075195,
      "learning_rate": 7.509881422924901e-06,
      "loss": 1.0387,
      "step": 20
    },
    {
      "epoch": 0.0023734646650447992,
      "grad_norm": 3.338996648788452,
      "learning_rate": 1.541501976284585e-05,
      "loss": 0.2969,
      "step": 40
    },
    {
      "epoch": 0.003560196997567199,
      "grad_norm": 1.3963139057159424,
      "learning_rate": 2.33201581027668e-05,
      "loss": 0.204,
      "step": 60
    },
    {
      "epoch": 0.0047469293300895984,
      "grad_norm": 2.1808836460113525,
      "learning_rate": 3.1225296442687746e-05,
      "loss": 0.1983,
      "step": 80
    },
    {
      "epoch": 0.005933661662611998,
      "grad_norm": 1.7146931886672974,
      "learning_rate": 3.91304347826087e-05,
      "loss": 0.2173,
      "step": 100
    },
    {
      "epoch": 0.007120393995134398,
      "grad_norm": 2.4646217823028564,
      "learning_rate": 4.7035573122529645e-05,
      "loss": 0.2057,
      "step": 120
    },
    {
      "epoch": 0.008307126327656797,
      "grad_norm": 3.84330677986145,
      "learning_rate": 5.49407114624506e-05,
      "loss": 0.1816,
      "step": 140
    },
    {
      "epoch": 0.009493858660179197,
      "grad_norm": 3.1994810104370117,
      "learning_rate": 6.284584980237155e-05,
      "loss": 0.1888,
      "step": 160
    },
    {
      "epoch": 0.010680590992701596,
      "grad_norm": 1.7622168064117432,
      "learning_rate": 7.075098814229249e-05,
      "loss": 0.2153,
      "step": 180
    },
    {
      "epoch": 0.011867323325223996,
      "grad_norm": 1.826794147491455,
      "learning_rate": 7.865612648221344e-05,
      "loss": 0.199,
      "step": 200
    },
    {
      "epoch": 0.013054055657746396,
      "grad_norm": 1.4592976570129395,
      "learning_rate": 8.65612648221344e-05,
      "loss": 0.1932,
      "step": 220
    },
    {
      "epoch": 0.014240787990268795,
      "grad_norm": 1.7129484415054321,
      "learning_rate": 9.446640316205534e-05,
      "loss": 0.194,
      "step": 240
    },
    {
      "epoch": 0.015427520322791195,
      "grad_norm": 1.2574540376663208,
      "learning_rate": 0.0001023715415019763,
      "loss": 0.1964,
      "step": 260
    },
    {
      "epoch": 0.016614252655313595,
      "grad_norm": 1.1025922298431396,
      "learning_rate": 0.00011027667984189724,
      "loss": 0.2198,
      "step": 280
    },
    {
      "epoch": 0.017800984987835992,
      "grad_norm": 1.7750619649887085,
      "learning_rate": 0.0001181818181818182,
      "loss": 0.1846,
      "step": 300
    },
    {
      "epoch": 0.018987717320358394,
      "grad_norm": 2.868051767349243,
      "learning_rate": 0.00012608695652173915,
      "loss": 0.1973,
      "step": 320
    },
    {
      "epoch": 0.02017444965288079,
      "grad_norm": 2.3595893383026123,
      "learning_rate": 0.0001339920948616601,
      "loss": 0.2145,
      "step": 340
    },
    {
      "epoch": 0.021361181985403193,
      "grad_norm": 1.1372511386871338,
      "learning_rate": 0.00014189723320158103,
      "loss": 0.2057,
      "step": 360
    },
    {
      "epoch": 0.02254791431792559,
      "grad_norm": 1.2041963338851929,
      "learning_rate": 0.00014980237154150198,
      "loss": 0.2178,
      "step": 380
    },
    {
      "epoch": 0.023734646650447992,
      "grad_norm": 1.4164191484451294,
      "learning_rate": 0.00015770750988142293,
      "loss": 0.199,
      "step": 400
    },
    {
      "epoch": 0.02492137898297039,
      "grad_norm": 1.6751861572265625,
      "learning_rate": 0.00016561264822134388,
      "loss": 0.1895,
      "step": 420
    },
    {
      "epoch": 0.02610811131549279,
      "grad_norm": 0.9750273823738098,
      "learning_rate": 0.00017351778656126484,
      "loss": 0.2022,
      "step": 440
    },
    {
      "epoch": 0.02729484364801519,
      "grad_norm": 0.9211957454681396,
      "learning_rate": 0.00018142292490118576,
      "loss": 0.1938,
      "step": 460
    },
    {
      "epoch": 0.02848157598053759,
      "grad_norm": 2.0753254890441895,
      "learning_rate": 0.00018932806324110672,
      "loss": 0.2231,
      "step": 480
    },
    {
      "epoch": 0.02966830831305999,
      "grad_norm": 0.5854642987251282,
      "learning_rate": 0.00019723320158102767,
      "loss": 0.2142,
      "step": 500
    },
    {
      "epoch": 0.03085504064558239,
      "grad_norm": 1.4102602005004883,
      "learning_rate": 0.00019984094940967762,
      "loss": 0.1912,
      "step": 520
    },
    {
      "epoch": 0.03204177297810479,
      "grad_norm": 1.4193586111068726,
      "learning_rate": 0.00019959625619379702,
      "loss": 0.2024,
      "step": 540
    },
    {
      "epoch": 0.03322850531062719,
      "grad_norm": 0.5126264095306396,
      "learning_rate": 0.00019935156297791644,
      "loss": 0.1806,
      "step": 560
    },
    {
      "epoch": 0.03441523764314959,
      "grad_norm": 1.0130695104599,
      "learning_rate": 0.00019910686976203586,
      "loss": 0.2038,
      "step": 580
    },
    {
      "epoch": 0.035601969975671985,
      "grad_norm": 1.4461658000946045,
      "learning_rate": 0.00019886217654615525,
      "loss": 0.1836,
      "step": 600
    },
    {
      "epoch": 0.036788702308194386,
      "grad_norm": 0.7882236242294312,
      "learning_rate": 0.00019861748333027467,
      "loss": 0.1725,
      "step": 620
    },
    {
      "epoch": 0.03797543464071679,
      "grad_norm": 0.9355607628822327,
      "learning_rate": 0.0001983727901143941,
      "loss": 0.2008,
      "step": 640
    },
    {
      "epoch": 0.03916216697323919,
      "grad_norm": 0.725584864616394,
      "learning_rate": 0.00019812809689851352,
      "loss": 0.1828,
      "step": 660
    },
    {
      "epoch": 0.04034889930576158,
      "grad_norm": 0.6243165135383606,
      "learning_rate": 0.0001978834036826329,
      "loss": 0.1859,
      "step": 680
    },
    {
      "epoch": 0.041535631638283985,
      "grad_norm": 1.5250613689422607,
      "learning_rate": 0.0001976387104667523,
      "loss": 0.2031,
      "step": 700
    },
    {
      "epoch": 0.042722363970806386,
      "grad_norm": 0.5795774459838867,
      "learning_rate": 0.00019739401725087173,
      "loss": 0.1653,
      "step": 720
    },
    {
      "epoch": 0.04390909630332879,
      "grad_norm": 0.9088283777236938,
      "learning_rate": 0.00019714932403499115,
      "loss": 0.181,
      "step": 740
    },
    {
      "epoch": 0.04509582863585118,
      "grad_norm": 1.0226508378982544,
      "learning_rate": 0.00019690463081911054,
      "loss": 0.2002,
      "step": 760
    },
    {
      "epoch": 0.04628256096837358,
      "grad_norm": 1.668888807296753,
      "learning_rate": 0.00019665993760322996,
      "loss": 0.1855,
      "step": 780
    },
    {
      "epoch": 0.047469293300895984,
      "grad_norm": 0.7595623135566711,
      "learning_rate": 0.00019641524438734938,
      "loss": 0.1957,
      "step": 800
    },
    {
      "epoch": 0.048656025633418386,
      "grad_norm": 0.9116789102554321,
      "learning_rate": 0.00019617055117146878,
      "loss": 0.204,
      "step": 820
    },
    {
      "epoch": 0.04984275796594078,
      "grad_norm": 1.3977446556091309,
      "learning_rate": 0.0001959258579555882,
      "loss": 0.1719,
      "step": 840
    },
    {
      "epoch": 0.05102949029846318,
      "grad_norm": 0.8237901926040649,
      "learning_rate": 0.00019568116473970762,
      "loss": 0.1888,
      "step": 860
    },
    {
      "epoch": 0.05221622263098558,
      "grad_norm": 0.5934572815895081,
      "learning_rate": 0.000195436471523827,
      "loss": 0.1743,
      "step": 880
    },
    {
      "epoch": 0.053402954963507984,
      "grad_norm": 0.6059253811836243,
      "learning_rate": 0.0001951917783079464,
      "loss": 0.1773,
      "step": 900
    },
    {
      "epoch": 0.05458968729603038,
      "grad_norm": 1.4160877466201782,
      "learning_rate": 0.00019494708509206583,
      "loss": 0.1744,
      "step": 920
    },
    {
      "epoch": 0.05577641962855278,
      "grad_norm": 0.5923179388046265,
      "learning_rate": 0.00019470239187618525,
      "loss": 0.1929,
      "step": 940
    },
    {
      "epoch": 0.05696315196107518,
      "grad_norm": 0.9830272197723389,
      "learning_rate": 0.00019445769866030464,
      "loss": 0.1737,
      "step": 960
    },
    {
      "epoch": 0.058149884293597576,
      "grad_norm": 0.758945882320404,
      "learning_rate": 0.00019421300544442406,
      "loss": 0.2056,
      "step": 980
    },
    {
      "epoch": 0.05933661662611998,
      "grad_norm": 1.1990796327590942,
      "learning_rate": 0.00019396831222854349,
      "loss": 0.1612,
      "step": 1000
    },
    {
      "epoch": 0.06052334895864238,
      "grad_norm": 0.9584963321685791,
      "learning_rate": 0.0001937236190126629,
      "loss": 0.1779,
      "step": 1020
    },
    {
      "epoch": 0.06171008129116478,
      "grad_norm": 1.80588698387146,
      "learning_rate": 0.00019347892579678227,
      "loss": 0.1805,
      "step": 1040
    },
    {
      "epoch": 0.06289681362368718,
      "grad_norm": 0.6639304757118225,
      "learning_rate": 0.0001932342325809017,
      "loss": 0.1635,
      "step": 1060
    },
    {
      "epoch": 0.06408354595620958,
      "grad_norm": 0.7055984139442444,
      "learning_rate": 0.00019298953936502112,
      "loss": 0.1655,
      "step": 1080
    },
    {
      "epoch": 0.06527027828873197,
      "grad_norm": 2.0254199504852295,
      "learning_rate": 0.0001927448461491405,
      "loss": 0.1898,
      "step": 1100
    },
    {
      "epoch": 0.06645701062125438,
      "grad_norm": 1.2921186685562134,
      "learning_rate": 0.00019250015293325993,
      "loss": 0.1735,
      "step": 1120
    },
    {
      "epoch": 0.06764374295377677,
      "grad_norm": 1.146475911140442,
      "learning_rate": 0.00019225545971737935,
      "loss": 0.1949,
      "step": 1140
    },
    {
      "epoch": 0.06883047528629918,
      "grad_norm": 0.8779932856559753,
      "learning_rate": 0.00019201076650149877,
      "loss": 0.1917,
      "step": 1160
    },
    {
      "epoch": 0.07001720761882158,
      "grad_norm": 0.6404765248298645,
      "learning_rate": 0.00019176607328561817,
      "loss": 0.179,
      "step": 1180
    },
    {
      "epoch": 0.07120393995134397,
      "grad_norm": 0.766296923160553,
      "learning_rate": 0.00019152138006973756,
      "loss": 0.1793,
      "step": 1200
    },
    {
      "epoch": 0.07239067228386638,
      "grad_norm": 0.694268524646759,
      "learning_rate": 0.00019127668685385698,
      "loss": 0.1531,
      "step": 1220
    },
    {
      "epoch": 0.07357740461638877,
      "grad_norm": 1.2137054204940796,
      "learning_rate": 0.0001910319936379764,
      "loss": 0.1685,
      "step": 1240
    },
    {
      "epoch": 0.07476413694891117,
      "grad_norm": 0.563490629196167,
      "learning_rate": 0.0001907873004220958,
      "loss": 0.1883,
      "step": 1260
    },
    {
      "epoch": 0.07595086928143358,
      "grad_norm": 0.3835148811340332,
      "learning_rate": 0.00019054260720621522,
      "loss": 0.1536,
      "step": 1280
    },
    {
      "epoch": 0.07713760161395597,
      "grad_norm": 1.0763607025146484,
      "learning_rate": 0.00019029791399033464,
      "loss": 0.1852,
      "step": 1300
    },
    {
      "epoch": 0.07832433394647838,
      "grad_norm": 1.0360091924667358,
      "learning_rate": 0.00019005322077445403,
      "loss": 0.1669,
      "step": 1320
    },
    {
      "epoch": 0.07951106627900077,
      "grad_norm": 0.7025079727172852,
      "learning_rate": 0.00018980852755857346,
      "loss": 0.1596,
      "step": 1340
    },
    {
      "epoch": 0.08069779861152317,
      "grad_norm": 0.8763463497161865,
      "learning_rate": 0.00018956383434269285,
      "loss": 0.1774,
      "step": 1360
    },
    {
      "epoch": 0.08188453094404557,
      "grad_norm": 1.1772055625915527,
      "learning_rate": 0.00018931914112681227,
      "loss": 0.1965,
      "step": 1380
    },
    {
      "epoch": 0.08307126327656797,
      "grad_norm": 0.9459922909736633,
      "learning_rate": 0.00018907444791093166,
      "loss": 0.182,
      "step": 1400
    },
    {
      "epoch": 0.08425799560909036,
      "grad_norm": 1.053378939628601,
      "learning_rate": 0.00018882975469505109,
      "loss": 0.1654,
      "step": 1420
    },
    {
      "epoch": 0.08544472794161277,
      "grad_norm": 1.0819978713989258,
      "learning_rate": 0.0001885850614791705,
      "loss": 0.172,
      "step": 1440
    },
    {
      "epoch": 0.08663146027413517,
      "grad_norm": 0.6912683248519897,
      "learning_rate": 0.0001883403682632899,
      "loss": 0.2027,
      "step": 1460
    },
    {
      "epoch": 0.08781819260665757,
      "grad_norm": 0.4822098910808563,
      "learning_rate": 0.00018809567504740932,
      "loss": 0.1669,
      "step": 1480
    },
    {
      "epoch": 0.08900492493917997,
      "grad_norm": 0.9574181437492371,
      "learning_rate": 0.00018785098183152874,
      "loss": 0.1726,
      "step": 1500
    },
    {
      "epoch": 0.09019165727170236,
      "grad_norm": 0.7048868536949158,
      "learning_rate": 0.00018760628861564814,
      "loss": 0.1518,
      "step": 1520
    },
    {
      "epoch": 0.09137838960422477,
      "grad_norm": 1.0499224662780762,
      "learning_rate": 0.00018736159539976753,
      "loss": 0.164,
      "step": 1540
    },
    {
      "epoch": 0.09256512193674717,
      "grad_norm": 1.0764355659484863,
      "learning_rate": 0.00018711690218388695,
      "loss": 0.1847,
      "step": 1560
    },
    {
      "epoch": 0.09375185426926956,
      "grad_norm": 0.7772706151008606,
      "learning_rate": 0.00018687220896800637,
      "loss": 0.18,
      "step": 1580
    },
    {
      "epoch": 0.09493858660179197,
      "grad_norm": 0.5502411723136902,
      "learning_rate": 0.00018662751575212577,
      "loss": 0.1595,
      "step": 1600
    },
    {
      "epoch": 0.09612531893431436,
      "grad_norm": 0.9970443844795227,
      "learning_rate": 0.0001863828225362452,
      "loss": 0.159,
      "step": 1620
    },
    {
      "epoch": 0.09731205126683677,
      "grad_norm": 0.8331958055496216,
      "learning_rate": 0.0001861381293203646,
      "loss": 0.1841,
      "step": 1640
    },
    {
      "epoch": 0.09849878359935917,
      "grad_norm": 0.9332199096679688,
      "learning_rate": 0.00018589343610448403,
      "loss": 0.1677,
      "step": 1660
    },
    {
      "epoch": 0.09968551593188156,
      "grad_norm": 0.5376999378204346,
      "learning_rate": 0.00018564874288860343,
      "loss": 0.1886,
      "step": 1680
    },
    {
      "epoch": 0.10087224826440397,
      "grad_norm": 0.3745105266571045,
      "learning_rate": 0.00018540404967272282,
      "loss": 0.1938,
      "step": 1700
    },
    {
      "epoch": 0.10205898059692636,
      "grad_norm": 0.9584606289863586,
      "learning_rate": 0.00018515935645684224,
      "loss": 0.1727,
      "step": 1720
    },
    {
      "epoch": 0.10324571292944876,
      "grad_norm": 1.3053098917007446,
      "learning_rate": 0.00018491466324096166,
      "loss": 0.1894,
      "step": 1740
    },
    {
      "epoch": 0.10443244526197117,
      "grad_norm": 0.9485064744949341,
      "learning_rate": 0.00018466997002508106,
      "loss": 0.1881,
      "step": 1760
    },
    {
      "epoch": 0.10561917759449356,
      "grad_norm": 0.7136642932891846,
      "learning_rate": 0.00018442527680920048,
      "loss": 0.1846,
      "step": 1780
    },
    {
      "epoch": 0.10680590992701597,
      "grad_norm": 0.4535760283470154,
      "learning_rate": 0.0001841805835933199,
      "loss": 0.1728,
      "step": 1800
    },
    {
      "epoch": 0.10799264225953836,
      "grad_norm": 1.4677637815475464,
      "learning_rate": 0.0001839358903774393,
      "loss": 0.1763,
      "step": 1820
    },
    {
      "epoch": 0.10917937459206076,
      "grad_norm": 1.056240200996399,
      "learning_rate": 0.0001836911971615587,
      "loss": 0.1528,
      "step": 1840
    },
    {
      "epoch": 0.11036610692458317,
      "grad_norm": 0.57002192735672,
      "learning_rate": 0.0001834465039456781,
      "loss": 0.1695,
      "step": 1860
    },
    {
      "epoch": 0.11155283925710556,
      "grad_norm": 0.4732687175273895,
      "learning_rate": 0.00018320181072979753,
      "loss": 0.1578,
      "step": 1880
    },
    {
      "epoch": 0.11273957158962795,
      "grad_norm": 1.073503851890564,
      "learning_rate": 0.00018295711751391692,
      "loss": 0.1831,
      "step": 1900
    },
    {
      "epoch": 0.11392630392215036,
      "grad_norm": 0.7111108303070068,
      "learning_rate": 0.00018271242429803634,
      "loss": 0.171,
      "step": 1920
    },
    {
      "epoch": 0.11511303625467276,
      "grad_norm": 0.49186792969703674,
      "learning_rate": 0.00018246773108215576,
      "loss": 0.1724,
      "step": 1940
    },
    {
      "epoch": 0.11629976858719515,
      "grad_norm": 0.7406271696090698,
      "learning_rate": 0.00018222303786627516,
      "loss": 0.1906,
      "step": 1960
    },
    {
      "epoch": 0.11748650091971756,
      "grad_norm": 1.094698190689087,
      "learning_rate": 0.00018197834465039458,
      "loss": 0.1829,
      "step": 1980
    },
    {
      "epoch": 0.11867323325223995,
      "grad_norm": 0.5397536158561707,
      "learning_rate": 0.000181733651434514,
      "loss": 0.1666,
      "step": 2000
    },
    {
      "epoch": 0.11985996558476236,
      "grad_norm": 0.6664129495620728,
      "learning_rate": 0.0001814889582186334,
      "loss": 0.1749,
      "step": 2020
    },
    {
      "epoch": 0.12104669791728476,
      "grad_norm": 1.1101148128509521,
      "learning_rate": 0.0001812442650027528,
      "loss": 0.1686,
      "step": 2040
    },
    {
      "epoch": 0.12223343024980715,
      "grad_norm": 0.5911523699760437,
      "learning_rate": 0.0001809995717868722,
      "loss": 0.1777,
      "step": 2060
    },
    {
      "epoch": 0.12342016258232956,
      "grad_norm": 0.7469328045845032,
      "learning_rate": 0.00018075487857099163,
      "loss": 0.1861,
      "step": 2080
    },
    {
      "epoch": 0.12460689491485195,
      "grad_norm": 0.31800663471221924,
      "learning_rate": 0.00018051018535511105,
      "loss": 0.1627,
      "step": 2100
    },
    {
      "epoch": 0.12579362724737436,
      "grad_norm": 0.48015668988227844,
      "learning_rate": 0.00018026549213923045,
      "loss": 0.1627,
      "step": 2120
    },
    {
      "epoch": 0.12698035957989676,
      "grad_norm": 1.0048174858093262,
      "learning_rate": 0.00018002079892334987,
      "loss": 0.1843,
      "step": 2140
    },
    {
      "epoch": 0.12816709191241915,
      "grad_norm": 0.6180223226547241,
      "learning_rate": 0.0001797761057074693,
      "loss": 0.1774,
      "step": 2160
    },
    {
      "epoch": 0.12935382424494155,
      "grad_norm": 0.8206998109817505,
      "learning_rate": 0.00017953141249158866,
      "loss": 0.1609,
      "step": 2180
    },
    {
      "epoch": 0.13054055657746394,
      "grad_norm": 1.3118736743927002,
      "learning_rate": 0.00017928671927570808,
      "loss": 0.1886,
      "step": 2200
    },
    {
      "epoch": 0.13172728890998636,
      "grad_norm": 0.9671075940132141,
      "learning_rate": 0.0001790420260598275,
      "loss": 0.1776,
      "step": 2220
    },
    {
      "epoch": 0.13291402124250876,
      "grad_norm": 1.5553646087646484,
      "learning_rate": 0.00017879733284394692,
      "loss": 0.1747,
      "step": 2240
    },
    {
      "epoch": 0.13410075357503115,
      "grad_norm": 0.6957961320877075,
      "learning_rate": 0.0001785526396280663,
      "loss": 0.1555,
      "step": 2260
    },
    {
      "epoch": 0.13528748590755355,
      "grad_norm": 1.2844537496566772,
      "learning_rate": 0.00017830794641218573,
      "loss": 0.1815,
      "step": 2280
    },
    {
      "epoch": 0.13647421824007594,
      "grad_norm": 0.8869533538818359,
      "learning_rate": 0.00017806325319630516,
      "loss": 0.1681,
      "step": 2300
    },
    {
      "epoch": 0.13766095057259836,
      "grad_norm": 0.6070054173469543,
      "learning_rate": 0.00017781855998042455,
      "loss": 0.1884,
      "step": 2320
    },
    {
      "epoch": 0.13884768290512076,
      "grad_norm": 0.6387043595314026,
      "learning_rate": 0.00017757386676454397,
      "loss": 0.1785,
      "step": 2340
    },
    {
      "epoch": 0.14003441523764315,
      "grad_norm": 0.8562039136886597,
      "learning_rate": 0.00017732917354866336,
      "loss": 0.1765,
      "step": 2360
    },
    {
      "epoch": 0.14122114757016554,
      "grad_norm": 0.6733729243278503,
      "learning_rate": 0.00017708448033278279,
      "loss": 0.1728,
      "step": 2380
    },
    {
      "epoch": 0.14240787990268794,
      "grad_norm": 0.541414201259613,
      "learning_rate": 0.00017683978711690218,
      "loss": 0.1751,
      "step": 2400
    },
    {
      "epoch": 0.14359461223521036,
      "grad_norm": 0.72004634141922,
      "learning_rate": 0.0001765950939010216,
      "loss": 0.1768,
      "step": 2420
    },
    {
      "epoch": 0.14478134456773276,
      "grad_norm": 1.3256465196609497,
      "learning_rate": 0.00017635040068514102,
      "loss": 0.1982,
      "step": 2440
    },
    {
      "epoch": 0.14596807690025515,
      "grad_norm": 0.8342276811599731,
      "learning_rate": 0.00017610570746926042,
      "loss": 0.1738,
      "step": 2460
    },
    {
      "epoch": 0.14715480923277754,
      "grad_norm": 0.7471433281898499,
      "learning_rate": 0.00017586101425337984,
      "loss": 0.1691,
      "step": 2480
    },
    {
      "epoch": 0.14834154156529994,
      "grad_norm": 0.6749514937400818,
      "learning_rate": 0.00017561632103749926,
      "loss": 0.1703,
      "step": 2500
    },
    {
      "epoch": 0.14952827389782233,
      "grad_norm": 1.5795814990997314,
      "learning_rate": 0.00017537162782161865,
      "loss": 0.1713,
      "step": 2520
    },
    {
      "epoch": 0.15071500623034476,
      "grad_norm": 0.6846436858177185,
      "learning_rate": 0.00017512693460573805,
      "loss": 0.1813,
      "step": 2540
    },
    {
      "epoch": 0.15190173856286715,
      "grad_norm": 0.8128787875175476,
      "learning_rate": 0.00017488224138985747,
      "loss": 0.1818,
      "step": 2560
    },
    {
      "epoch": 0.15308847089538954,
      "grad_norm": 0.7355286478996277,
      "learning_rate": 0.0001746375481739769,
      "loss": 0.1709,
      "step": 2580
    },
    {
      "epoch": 0.15427520322791194,
      "grad_norm": 0.48653507232666016,
      "learning_rate": 0.0001743928549580963,
      "loss": 0.1807,
      "step": 2600
    },
    {
      "epoch": 0.15546193556043433,
      "grad_norm": 0.47177016735076904,
      "learning_rate": 0.0001741481617422157,
      "loss": 0.159,
      "step": 2620
    },
    {
      "epoch": 0.15664866789295676,
      "grad_norm": 0.7566419243812561,
      "learning_rate": 0.00017390346852633513,
      "loss": 0.1569,
      "step": 2640
    },
    {
      "epoch": 0.15783540022547915,
      "grad_norm": 1.011892318725586,
      "learning_rate": 0.00017365877531045455,
      "loss": 0.1787,
      "step": 2660
    },
    {
      "epoch": 0.15902213255800154,
      "grad_norm": 0.5011774897575378,
      "learning_rate": 0.0001734140820945739,
      "loss": 0.1843,
      "step": 2680
    },
    {
      "epoch": 0.16020886489052394,
      "grad_norm": 0.844852089881897,
      "learning_rate": 0.00017316938887869333,
      "loss": 0.1781,
      "step": 2700
    },
    {
      "epoch": 0.16139559722304633,
      "grad_norm": 0.6301392912864685,
      "learning_rate": 0.00017292469566281276,
      "loss": 0.1694,
      "step": 2720
    },
    {
      "epoch": 0.16258232955556876,
      "grad_norm": 0.4192286729812622,
      "learning_rate": 0.00017268000244693218,
      "loss": 0.1681,
      "step": 2740
    },
    {
      "epoch": 0.16376906188809115,
      "grad_norm": 0.7322239279747009,
      "learning_rate": 0.00017243530923105157,
      "loss": 0.1685,
      "step": 2760
    },
    {
      "epoch": 0.16495579422061354,
      "grad_norm": 0.631675124168396,
      "learning_rate": 0.000172190616015171,
      "loss": 0.1735,
      "step": 2780
    },
    {
      "epoch": 0.16614252655313594,
      "grad_norm": 0.8527517914772034,
      "learning_rate": 0.0001719459227992904,
      "loss": 0.1761,
      "step": 2800
    },
    {
      "epoch": 0.16732925888565833,
      "grad_norm": 0.40665340423583984,
      "learning_rate": 0.0001717012295834098,
      "loss": 0.1615,
      "step": 2820
    },
    {
      "epoch": 0.16851599121818073,
      "grad_norm": 0.5535704493522644,
      "learning_rate": 0.0001714565363675292,
      "loss": 0.1624,
      "step": 2840
    },
    {
      "epoch": 0.16970272355070315,
      "grad_norm": 0.6593342423439026,
      "learning_rate": 0.00017121184315164862,
      "loss": 0.1851,
      "step": 2860
    },
    {
      "epoch": 0.17088945588322554,
      "grad_norm": 1.3504664897918701,
      "learning_rate": 0.00017096714993576804,
      "loss": 0.1818,
      "step": 2880
    },
    {
      "epoch": 0.17207618821574794,
      "grad_norm": 0.3278674781322479,
      "learning_rate": 0.00017072245671988744,
      "loss": 0.162,
      "step": 2900
    },
    {
      "epoch": 0.17326292054827033,
      "grad_norm": 0.7130964994430542,
      "learning_rate": 0.00017047776350400686,
      "loss": 0.1817,
      "step": 2920
    },
    {
      "epoch": 0.17444965288079273,
      "grad_norm": 1.2378586530685425,
      "learning_rate": 0.00017023307028812628,
      "loss": 0.173,
      "step": 2940
    },
    {
      "epoch": 0.17563638521331515,
      "grad_norm": 0.9073180556297302,
      "learning_rate": 0.00016998837707224567,
      "loss": 0.1728,
      "step": 2960
    },
    {
      "epoch": 0.17682311754583754,
      "grad_norm": 0.5911349058151245,
      "learning_rate": 0.0001697436838563651,
      "loss": 0.1748,
      "step": 2980
    },
    {
      "epoch": 0.17800984987835994,
      "grad_norm": 1.4161670207977295,
      "learning_rate": 0.0001694989906404845,
      "loss": 0.1905,
      "step": 3000
    },
    {
      "epoch": 0.17919658221088233,
      "grad_norm": 0.9137594103813171,
      "learning_rate": 0.0001692542974246039,
      "loss": 0.1809,
      "step": 3020
    },
    {
      "epoch": 0.18038331454340473,
      "grad_norm": 0.7186339497566223,
      "learning_rate": 0.0001690096042087233,
      "loss": 0.1522,
      "step": 3040
    },
    {
      "epoch": 0.18157004687592712,
      "grad_norm": 0.7299916744232178,
      "learning_rate": 0.00016876491099284273,
      "loss": 0.1771,
      "step": 3060
    },
    {
      "epoch": 0.18275677920844954,
      "grad_norm": 0.6104021072387695,
      "learning_rate": 0.00016852021777696215,
      "loss": 0.1665,
      "step": 3080
    },
    {
      "epoch": 0.18394351154097194,
      "grad_norm": 0.6279229521751404,
      "learning_rate": 0.00016827552456108157,
      "loss": 0.1763,
      "step": 3100
    },
    {
      "epoch": 0.18513024387349433,
      "grad_norm": 0.799588143825531,
      "learning_rate": 0.00016803083134520096,
      "loss": 0.1895,
      "step": 3120
    },
    {
      "epoch": 0.18631697620601673,
      "grad_norm": 0.7979286909103394,
      "learning_rate": 0.00016778613812932038,
      "loss": 0.1905,
      "step": 3140
    },
    {
      "epoch": 0.18750370853853912,
      "grad_norm": 0.6708881258964539,
      "learning_rate": 0.0001675414449134398,
      "loss": 0.1833,
      "step": 3160
    },
    {
      "epoch": 0.18869044087106154,
      "grad_norm": 0.5099575519561768,
      "learning_rate": 0.0001672967516975592,
      "loss": 0.1652,
      "step": 3180
    },
    {
      "epoch": 0.18987717320358394,
      "grad_norm": 0.707276463508606,
      "learning_rate": 0.0001670520584816786,
      "loss": 0.1729,
      "step": 3200
    },
    {
      "epoch": 0.19106390553610633,
      "grad_norm": 0.6178401708602905,
      "learning_rate": 0.000166807365265798,
      "loss": 0.1633,
      "step": 3220
    },
    {
      "epoch": 0.19225063786862873,
      "grad_norm": 1.486738920211792,
      "learning_rate": 0.00016656267204991743,
      "loss": 0.1774,
      "step": 3240
    },
    {
      "epoch": 0.19343737020115112,
      "grad_norm": 1.163561463356018,
      "learning_rate": 0.00016631797883403683,
      "loss": 0.1828,
      "step": 3260
    },
    {
      "epoch": 0.19462410253367354,
      "grad_norm": 0.5214402079582214,
      "learning_rate": 0.00016607328561815625,
      "loss": 0.1629,
      "step": 3280
    },
    {
      "epoch": 0.19581083486619594,
      "grad_norm": 0.5299138426780701,
      "learning_rate": 0.00016582859240227567,
      "loss": 0.1807,
      "step": 3300
    },
    {
      "epoch": 0.19699756719871833,
      "grad_norm": 0.5696702003479004,
      "learning_rate": 0.00016558389918639506,
      "loss": 0.1799,
      "step": 3320
    },
    {
      "epoch": 0.19818429953124073,
      "grad_norm": 0.7235682606697083,
      "learning_rate": 0.00016533920597051446,
      "loss": 0.1836,
      "step": 3340
    },
    {
      "epoch": 0.19937103186376312,
      "grad_norm": 0.7959086894989014,
      "learning_rate": 0.00016509451275463388,
      "loss": 0.1625,
      "step": 3360
    },
    {
      "epoch": 0.20055776419628552,
      "grad_norm": 0.4778512120246887,
      "learning_rate": 0.0001648498195387533,
      "loss": 0.187,
      "step": 3380
    },
    {
      "epoch": 0.20174449652880794,
      "grad_norm": 0.8882611393928528,
      "learning_rate": 0.0001646051263228727,
      "loss": 0.1747,
      "step": 3400
    },
    {
      "epoch": 0.20293122886133033,
      "grad_norm": 1.088204026222229,
      "learning_rate": 0.00016436043310699212,
      "loss": 0.1752,
      "step": 3420
    },
    {
      "epoch": 0.20411796119385273,
      "grad_norm": 0.6490910649299622,
      "learning_rate": 0.00016411573989111154,
      "loss": 0.1817,
      "step": 3440
    },
    {
      "epoch": 0.20530469352637512,
      "grad_norm": 0.463487446308136,
      "learning_rate": 0.00016387104667523093,
      "loss": 0.1713,
      "step": 3460
    },
    {
      "epoch": 0.20649142585889751,
      "grad_norm": 87.41232299804688,
      "learning_rate": 0.00016362635345935035,
      "loss": 3.4559,
      "step": 3480
    },
    {
      "epoch": 0.20767815819141994,
      "grad_norm": 41.957523345947266,
      "learning_rate": 0.00016338166024346975,
      "loss": 1.8031,
      "step": 3500
    },
    {
      "epoch": 0.20886489052394233,
      "grad_norm": 0.9760203957557678,
      "learning_rate": 0.00016313696702758917,
      "loss": 0.6273,
      "step": 3520
    },
    {
      "epoch": 0.21005162285646473,
      "grad_norm": 0.9361951947212219,
      "learning_rate": 0.00016289227381170856,
      "loss": 0.23,
      "step": 3540
    },
    {
      "epoch": 0.21123835518898712,
      "grad_norm": 1.4854176044464111,
      "learning_rate": 0.00016264758059582798,
      "loss": 0.1715,
      "step": 3560
    },
    {
      "epoch": 0.21242508752150951,
      "grad_norm": 1.2274736166000366,
      "learning_rate": 0.0001624028873799474,
      "loss": 0.5363,
      "step": 3580
    },
    {
      "epoch": 0.21361181985403194,
      "grad_norm": 328.24237060546875,
      "learning_rate": 0.00016215819416406682,
      "loss": 0.2082,
      "step": 3600
    },
    {
      "epoch": 0.21479855218655433,
      "grad_norm": 3.1821999549865723,
      "learning_rate": 0.00016191350094818622,
      "loss": 0.1946,
      "step": 3620
    },
    {
      "epoch": 0.21598528451907673,
      "grad_norm": 0.7440794110298157,
      "learning_rate": 0.00016166880773230564,
      "loss": 0.1614,
      "step": 3640
    },
    {
      "epoch": 0.21717201685159912,
      "grad_norm": 0.850250780582428,
      "learning_rate": 0.00016142411451642503,
      "loss": 0.1897,
      "step": 3660
    },
    {
      "epoch": 0.21835874918412151,
      "grad_norm": 1.1185108423233032,
      "learning_rate": 0.00016117942130054446,
      "loss": 0.1705,
      "step": 3680
    },
    {
      "epoch": 0.2195454815166439,
      "grad_norm": 0.684779942035675,
      "learning_rate": 0.00016093472808466385,
      "loss": 0.1747,
      "step": 3700
    },
    {
      "epoch": 0.22073221384916633,
      "grad_norm": 0.6430562138557434,
      "learning_rate": 0.00016069003486878327,
      "loss": 0.1685,
      "step": 3720
    },
    {
      "epoch": 0.22191894618168873,
      "grad_norm": 0.9009201526641846,
      "learning_rate": 0.0001604453416529027,
      "loss": 0.178,
      "step": 3740
    },
    {
      "epoch": 0.22310567851421112,
      "grad_norm": 1.0389184951782227,
      "learning_rate": 0.00016020064843702209,
      "loss": 0.2022,
      "step": 3760
    },
    {
      "epoch": 0.22429241084673351,
      "grad_norm": 1.5340237617492676,
      "learning_rate": 0.0001599559552211415,
      "loss": 0.1632,
      "step": 3780
    },
    {
      "epoch": 0.2254791431792559,
      "grad_norm": 0.4583185911178589,
      "learning_rate": 0.00015971126200526093,
      "loss": 0.1719,
      "step": 3800
    },
    {
      "epoch": 0.22666587551177833,
      "grad_norm": 0.5563245415687561,
      "learning_rate": 0.00015946656878938032,
      "loss": 0.1711,
      "step": 3820
    },
    {
      "epoch": 0.22785260784430073,
      "grad_norm": 0.9405747056007385,
      "learning_rate": 0.00015922187557349972,
      "loss": 0.1798,
      "step": 3840
    },
    {
      "epoch": 0.22903934017682312,
      "grad_norm": 1.4520392417907715,
      "learning_rate": 0.00015897718235761914,
      "loss": 0.1668,
      "step": 3860
    },
    {
      "epoch": 0.23022607250934551,
      "grad_norm": 1.169108510017395,
      "learning_rate": 0.00015873248914173856,
      "loss": 0.1927,
      "step": 3880
    },
    {
      "epoch": 0.2314128048418679,
      "grad_norm": 1.0358880758285522,
      "learning_rate": 0.00015848779592585795,
      "loss": 0.1796,
      "step": 3900
    },
    {
      "epoch": 0.2325995371743903,
      "grad_norm": 0.611681342124939,
      "learning_rate": 0.00015824310270997737,
      "loss": 0.18,
      "step": 3920
    },
    {
      "epoch": 0.23378626950691273,
      "grad_norm": 0.5284295082092285,
      "learning_rate": 0.0001579984094940968,
      "loss": 0.1576,
      "step": 3940
    },
    {
      "epoch": 0.23497300183943512,
      "grad_norm": 4.736672401428223,
      "learning_rate": 0.0001577537162782162,
      "loss": 0.2205,
      "step": 3960
    },
    {
      "epoch": 0.2361597341719575,
      "grad_norm": 0.5845065116882324,
      "learning_rate": 0.0001575090230623356,
      "loss": 0.1528,
      "step": 3980
    },
    {
      "epoch": 0.2373464665044799,
      "grad_norm": 0.8949515223503113,
      "learning_rate": 0.000157264329846455,
      "loss": 0.1781,
      "step": 4000
    },
    {
      "epoch": 0.2385331988370023,
      "grad_norm": 1.2211978435516357,
      "learning_rate": 0.00015701963663057442,
      "loss": 0.1595,
      "step": 4020
    },
    {
      "epoch": 0.23971993116952472,
      "grad_norm": 1.1786205768585205,
      "learning_rate": 0.00015677494341469382,
      "loss": 0.1693,
      "step": 4040
    },
    {
      "epoch": 0.24090666350204712,
      "grad_norm": 0.9738118648529053,
      "learning_rate": 0.00015653025019881324,
      "loss": 0.1639,
      "step": 4060
    },
    {
      "epoch": 0.2420933958345695,
      "grad_norm": 0.8663210272789001,
      "learning_rate": 0.00015628555698293266,
      "loss": 0.1851,
      "step": 4080
    },
    {
      "epoch": 0.2432801281670919,
      "grad_norm": 0.885305643081665,
      "learning_rate": 0.00015604086376705208,
      "loss": 0.1754,
      "step": 4100
    },
    {
      "epoch": 0.2444668604996143,
      "grad_norm": 0.6017959713935852,
      "learning_rate": 0.00015579617055117148,
      "loss": 0.1947,
      "step": 4120
    },
    {
      "epoch": 0.24565359283213672,
      "grad_norm": 1.0310851335525513,
      "learning_rate": 0.0001555514773352909,
      "loss": 0.1864,
      "step": 4140
    },
    {
      "epoch": 0.24684032516465912,
      "grad_norm": 0.7444639205932617,
      "learning_rate": 0.0001553067841194103,
      "loss": 0.196,
      "step": 4160
    },
    {
      "epoch": 0.2480270574971815,
      "grad_norm": 0.8582164645195007,
      "learning_rate": 0.0001550620909035297,
      "loss": 0.1953,
      "step": 4180
    },
    {
      "epoch": 0.2492137898297039,
      "grad_norm": 40.604835510253906,
      "learning_rate": 0.0001548173976876491,
      "loss": 0.2367,
      "step": 4200
    },
    {
      "epoch": 0.2504005221622263,
      "grad_norm": 0.8108139634132385,
      "learning_rate": 0.00015457270447176853,
      "loss": 0.1813,
      "step": 4220
    },
    {
      "epoch": 0.2515872544947487,
      "grad_norm": 13.872315406799316,
      "learning_rate": 0.00015432801125588795,
      "loss": 0.7042,
      "step": 4240
    },
    {
      "epoch": 0.2527739868272711,
      "grad_norm": 6.689643383026123,
      "learning_rate": 0.00015408331804000734,
      "loss": 0.4296,
      "step": 4260
    },
    {
      "epoch": 0.2539607191597935,
      "grad_norm": 8.426287651062012,
      "learning_rate": 0.00015383862482412676,
      "loss": 0.1839,
      "step": 4280
    },
    {
      "epoch": 0.25514745149231594,
      "grad_norm": 2.531038999557495,
      "learning_rate": 0.00015359393160824619,
      "loss": 0.1883,
      "step": 4300
    },
    {
      "epoch": 0.2563341838248383,
      "grad_norm": 0.8161940574645996,
      "learning_rate": 0.00015334923839236558,
      "loss": 0.202,
      "step": 4320
    },
    {
      "epoch": 0.2575209161573607,
      "grad_norm": 3.778665542602539,
      "learning_rate": 0.00015310454517648497,
      "loss": 0.271,
      "step": 4340
    },
    {
      "epoch": 0.2587076484898831,
      "grad_norm": 5.831120491027832,
      "learning_rate": 0.0001528598519606044,
      "loss": 0.239,
      "step": 4360
    },
    {
      "epoch": 0.2598943808224055,
      "grad_norm": 6.120175361633301,
      "learning_rate": 0.00015261515874472382,
      "loss": 0.1873,
      "step": 4380
    },
    {
      "epoch": 0.2610811131549279,
      "grad_norm": 4.9133758544921875,
      "learning_rate": 0.0001523704655288432,
      "loss": 0.2062,
      "step": 4400
    },
    {
      "epoch": 0.2622678454874503,
      "grad_norm": 0.4924696683883667,
      "learning_rate": 0.00015212577231296263,
      "loss": 0.1691,
      "step": 4420
    },
    {
      "epoch": 0.2634545778199727,
      "grad_norm": 8.098684310913086,
      "learning_rate": 0.00015188107909708205,
      "loss": 0.1939,
      "step": 4440
    },
    {
      "epoch": 0.2646413101524951,
      "grad_norm": 1.5233451128005981,
      "learning_rate": 0.00015163638588120145,
      "loss": 0.1836,
      "step": 4460
    },
    {
      "epoch": 0.2658280424850175,
      "grad_norm": 0.876188337802887,
      "learning_rate": 0.00015139169266532087,
      "loss": 0.1827,
      "step": 4480
    },
    {
      "epoch": 0.2670147748175399,
      "grad_norm": 12.803918838500977,
      "learning_rate": 0.00015114699944944026,
      "loss": 0.191,
      "step": 4500
    },
    {
      "epoch": 0.2682015071500623,
      "grad_norm": 2.8493897914886475,
      "learning_rate": 0.00015090230623355968,
      "loss": 0.1769,
      "step": 4520
    },
    {
      "epoch": 0.2693882394825847,
      "grad_norm": 3.8985259532928467,
      "learning_rate": 0.00015065761301767908,
      "loss": 0.1733,
      "step": 4540
    },
    {
      "epoch": 0.2705749718151071,
      "grad_norm": 5.682783126831055,
      "learning_rate": 0.0001504129198017985,
      "loss": 0.215,
      "step": 4560
    },
    {
      "epoch": 0.2717617041476295,
      "grad_norm": 1.2603858709335327,
      "learning_rate": 0.00015016822658591792,
      "loss": 0.1751,
      "step": 4580
    },
    {
      "epoch": 0.2729484364801519,
      "grad_norm": 3.8710672855377197,
      "learning_rate": 0.00014992353337003734,
      "loss": 0.1529,
      "step": 4600
    },
    {
      "epoch": 0.2741351688126743,
      "grad_norm": 4.567991733551025,
      "learning_rate": 0.00014967884015415673,
      "loss": 0.1819,
      "step": 4620
    },
    {
      "epoch": 0.2753219011451967,
      "grad_norm": 1.0108650922775269,
      "learning_rate": 0.00014943414693827616,
      "loss": 0.1851,
      "step": 4640
    },
    {
      "epoch": 0.2765086334777191,
      "grad_norm": 1.1534523963928223,
      "learning_rate": 0.00014918945372239555,
      "loss": 0.1685,
      "step": 4660
    },
    {
      "epoch": 0.2776953658102415,
      "grad_norm": 6.444522380828857,
      "learning_rate": 0.00014894476050651497,
      "loss": 0.1892,
      "step": 4680
    },
    {
      "epoch": 0.2788820981427639,
      "grad_norm": 0.6402760744094849,
      "learning_rate": 0.00014870006729063436,
      "loss": 0.1686,
      "step": 4700
    },
    {
      "epoch": 0.2800688304752863,
      "grad_norm": 6.809281349182129,
      "learning_rate": 0.00014845537407475379,
      "loss": 0.1714,
      "step": 4720
    },
    {
      "epoch": 0.2812555628078087,
      "grad_norm": 2.4935927391052246,
      "learning_rate": 0.0001482106808588732,
      "loss": 0.1788,
      "step": 4740
    },
    {
      "epoch": 0.2824422951403311,
      "grad_norm": 1.403747320175171,
      "learning_rate": 0.0001479659876429926,
      "loss": 0.1745,
      "step": 4760
    },
    {
      "epoch": 0.2836290274728535,
      "grad_norm": 1.0164713859558105,
      "learning_rate": 0.00014772129442711202,
      "loss": 0.1691,
      "step": 4780
    },
    {
      "epoch": 0.2848157598053759,
      "grad_norm": 2.4749810695648193,
      "learning_rate": 0.00014747660121123144,
      "loss": 0.1633,
      "step": 4800
    },
    {
      "epoch": 0.2860024921378983,
      "grad_norm": 0.9152519702911377,
      "learning_rate": 0.00014723190799535084,
      "loss": 0.1925,
      "step": 4820
    },
    {
      "epoch": 0.2871892244704207,
      "grad_norm": 2.941408634185791,
      "learning_rate": 0.00014698721477947023,
      "loss": 0.1728,
      "step": 4840
    },
    {
      "epoch": 0.2883759568029431,
      "grad_norm": 7.200240135192871,
      "learning_rate": 0.00014674252156358965,
      "loss": 0.1784,
      "step": 4860
    },
    {
      "epoch": 0.2895626891354655,
      "grad_norm": 2.1803476810455322,
      "learning_rate": 0.00014649782834770907,
      "loss": 0.2241,
      "step": 4880
    },
    {
      "epoch": 0.2907494214679879,
      "grad_norm": 3.621522903442383,
      "learning_rate": 0.00014625313513182847,
      "loss": 0.1821,
      "step": 4900
    },
    {
      "epoch": 0.2919361538005103,
      "grad_norm": 9.171581268310547,
      "learning_rate": 0.0001460084419159479,
      "loss": 0.1745,
      "step": 4920
    },
    {
      "epoch": 0.29312288613303267,
      "grad_norm": 0.8162786960601807,
      "learning_rate": 0.0001457637487000673,
      "loss": 0.182,
      "step": 4940
    },
    {
      "epoch": 0.2943096184655551,
      "grad_norm": 4.654858112335205,
      "learning_rate": 0.0001455190554841867,
      "loss": 0.1577,
      "step": 4960
    },
    {
      "epoch": 0.2954963507980775,
      "grad_norm": 9.50095272064209,
      "learning_rate": 0.0001452743622683061,
      "loss": 0.2151,
      "step": 4980
    },
    {
      "epoch": 0.2966830831305999,
      "grad_norm": 3.4608633518218994,
      "learning_rate": 0.00014502966905242552,
      "loss": 0.1896,
      "step": 5000
    },
    {
      "epoch": 0.2978698154631223,
      "grad_norm": 6.7744526863098145,
      "learning_rate": 0.00014478497583654494,
      "loss": 0.1817,
      "step": 5020
    },
    {
      "epoch": 0.29905654779564467,
      "grad_norm": 1.6864219903945923,
      "learning_rate": 0.00014454028262066433,
      "loss": 0.1598,
      "step": 5040
    },
    {
      "epoch": 0.3002432801281671,
      "grad_norm": 1.2645649909973145,
      "learning_rate": 0.00014429558940478376,
      "loss": 0.1833,
      "step": 5060
    },
    {
      "epoch": 0.3014300124606895,
      "grad_norm": 0.8296667337417603,
      "learning_rate": 0.00014405089618890318,
      "loss": 0.1665,
      "step": 5080
    },
    {
      "epoch": 0.3026167447932119,
      "grad_norm": 9.670210838317871,
      "learning_rate": 0.0001438062029730226,
      "loss": 0.182,
      "step": 5100
    },
    {
      "epoch": 0.3038034771257343,
      "grad_norm": 1.1169532537460327,
      "learning_rate": 0.000143561509757142,
      "loss": 0.1622,
      "step": 5120
    },
    {
      "epoch": 0.30499020945825667,
      "grad_norm": 5.790740013122559,
      "learning_rate": 0.00014331681654126139,
      "loss": 0.2082,
      "step": 5140
    },
    {
      "epoch": 0.3061769417907791,
      "grad_norm": 1.2531321048736572,
      "learning_rate": 0.0001430721233253808,
      "loss": 0.1838,
      "step": 5160
    },
    {
      "epoch": 0.3073636741233015,
      "grad_norm": 2.624356746673584,
      "learning_rate": 0.00014282743010950023,
      "loss": 0.1741,
      "step": 5180
    },
    {
      "epoch": 0.3085504064558239,
      "grad_norm": 1.0398576259613037,
      "learning_rate": 0.00014258273689361962,
      "loss": 0.1684,
      "step": 5200
    },
    {
      "epoch": 0.3097371387883463,
      "grad_norm": 7.879695415496826,
      "learning_rate": 0.00014233804367773904,
      "loss": 0.1742,
      "step": 5220
    },
    {
      "epoch": 0.31092387112086867,
      "grad_norm": 4.87844181060791,
      "learning_rate": 0.00014209335046185846,
      "loss": 0.1937,
      "step": 5240
    },
    {
      "epoch": 0.3121106034533911,
      "grad_norm": 1.1635853052139282,
      "learning_rate": 0.00014184865724597786,
      "loss": 0.1858,
      "step": 5260
    },
    {
      "epoch": 0.3132973357859135,
      "grad_norm": 2.0461111068725586,
      "learning_rate": 0.00014160396403009728,
      "loss": 0.2123,
      "step": 5280
    },
    {
      "epoch": 0.3144840681184359,
      "grad_norm": 3.1764304637908936,
      "learning_rate": 0.0001413592708142167,
      "loss": 0.1827,
      "step": 5300
    },
    {
      "epoch": 0.3156708004509583,
      "grad_norm": 2.6496407985687256,
      "learning_rate": 0.0001411145775983361,
      "loss": 0.1755,
      "step": 5320
    },
    {
      "epoch": 0.31685753278348067,
      "grad_norm": 3.4342269897460938,
      "learning_rate": 0.0001408698843824555,
      "loss": 0.2048,
      "step": 5340
    },
    {
      "epoch": 0.3180442651160031,
      "grad_norm": 5.3983917236328125,
      "learning_rate": 0.0001406251911665749,
      "loss": 0.1925,
      "step": 5360
    },
    {
      "epoch": 0.3192309974485255,
      "grad_norm": 2.419285535812378,
      "learning_rate": 0.00014038049795069433,
      "loss": 0.1593,
      "step": 5380
    },
    {
      "epoch": 0.3204177297810479,
      "grad_norm": 1.578204870223999,
      "learning_rate": 0.00014013580473481372,
      "loss": 0.1812,
      "step": 5400
    },
    {
      "epoch": 0.3216044621135703,
      "grad_norm": 1.1957728862762451,
      "learning_rate": 0.00013989111151893315,
      "loss": 0.177,
      "step": 5420
    },
    {
      "epoch": 0.32279119444609267,
      "grad_norm": 1.1898016929626465,
      "learning_rate": 0.00013964641830305257,
      "loss": 0.188,
      "step": 5440
    },
    {
      "epoch": 0.3239779267786151,
      "grad_norm": 0.889805793762207,
      "learning_rate": 0.000139401725087172,
      "loss": 0.1745,
      "step": 5460
    },
    {
      "epoch": 0.3251646591111375,
      "grad_norm": 0.8465717434883118,
      "learning_rate": 0.00013915703187129136,
      "loss": 0.1618,
      "step": 5480
    },
    {
      "epoch": 0.3263513914436599,
      "grad_norm": 1.2032173871994019,
      "learning_rate": 0.00013891233865541078,
      "loss": 0.1862,
      "step": 5500
    },
    {
      "epoch": 0.3275381237761823,
      "grad_norm": 1.4246822595596313,
      "learning_rate": 0.0001386676454395302,
      "loss": 0.1893,
      "step": 5520
    },
    {
      "epoch": 0.32872485610870467,
      "grad_norm": 0.6001741290092468,
      "learning_rate": 0.0001384229522236496,
      "loss": 0.1811,
      "step": 5540
    },
    {
      "epoch": 0.3299115884412271,
      "grad_norm": 1.0435596704483032,
      "learning_rate": 0.000138178259007769,
      "loss": 0.1954,
      "step": 5560
    },
    {
      "epoch": 0.33109832077374945,
      "grad_norm": 0.8947221040725708,
      "learning_rate": 0.00013793356579188843,
      "loss": 0.1604,
      "step": 5580
    },
    {
      "epoch": 0.3322850531062719,
      "grad_norm": 1.2344961166381836,
      "learning_rate": 0.00013768887257600785,
      "loss": 0.1779,
      "step": 5600
    },
    {
      "epoch": 0.3334717854387943,
      "grad_norm": 1.0585870742797852,
      "learning_rate": 0.00013744417936012725,
      "loss": 0.1765,
      "step": 5620
    },
    {
      "epoch": 0.33465851777131667,
      "grad_norm": 1.2151741981506348,
      "learning_rate": 0.00013719948614424664,
      "loss": 0.1635,
      "step": 5640
    },
    {
      "epoch": 0.3358452501038391,
      "grad_norm": 1.2959781885147095,
      "learning_rate": 0.00013695479292836606,
      "loss": 0.1617,
      "step": 5660
    },
    {
      "epoch": 0.33703198243636145,
      "grad_norm": 1.0395054817199707,
      "learning_rate": 0.00013671009971248549,
      "loss": 0.1932,
      "step": 5680
    },
    {
      "epoch": 0.3382187147688839,
      "grad_norm": 1.1350691318511963,
      "learning_rate": 0.00013646540649660488,
      "loss": 0.1842,
      "step": 5700
    },
    {
      "epoch": 0.3394054471014063,
      "grad_norm": 1.0142441987991333,
      "learning_rate": 0.0001362207132807243,
      "loss": 0.1752,
      "step": 5720
    },
    {
      "epoch": 0.34059217943392867,
      "grad_norm": 0.9044297337532043,
      "learning_rate": 0.00013597602006484372,
      "loss": 0.1809,
      "step": 5740
    },
    {
      "epoch": 0.3417789117664511,
      "grad_norm": 0.9799180030822754,
      "learning_rate": 0.00013573132684896312,
      "loss": 0.1623,
      "step": 5760
    },
    {
      "epoch": 0.34296564409897345,
      "grad_norm": 0.3925086259841919,
      "learning_rate": 0.00013548663363308254,
      "loss": 0.1676,
      "step": 5780
    },
    {
      "epoch": 0.3441523764314959,
      "grad_norm": 0.8392041921615601,
      "learning_rate": 0.00013524194041720193,
      "loss": 0.1738,
      "step": 5800
    },
    {
      "epoch": 0.3453391087640183,
      "grad_norm": 2.0266966819763184,
      "learning_rate": 0.00013499724720132135,
      "loss": 0.1713,
      "step": 5820
    },
    {
      "epoch": 0.34652584109654067,
      "grad_norm": 0.605461061000824,
      "learning_rate": 0.00013475255398544075,
      "loss": 0.1744,
      "step": 5840
    },
    {
      "epoch": 0.3477125734290631,
      "grad_norm": 1.0020025968551636,
      "learning_rate": 0.00013450786076956017,
      "loss": 0.1715,
      "step": 5860
    },
    {
      "epoch": 0.34889930576158545,
      "grad_norm": 0.8968877792358398,
      "learning_rate": 0.0001342631675536796,
      "loss": 0.168,
      "step": 5880
    },
    {
      "epoch": 0.3500860380941079,
      "grad_norm": 0.6792104244232178,
      "learning_rate": 0.00013401847433779898,
      "loss": 0.17,
      "step": 5900
    },
    {
      "epoch": 0.3512727704266303,
      "grad_norm": 0.5422672629356384,
      "learning_rate": 0.0001337737811219184,
      "loss": 0.1863,
      "step": 5920
    },
    {
      "epoch": 0.35245950275915267,
      "grad_norm": 1.1948546171188354,
      "learning_rate": 0.00013352908790603782,
      "loss": 0.1614,
      "step": 5940
    },
    {
      "epoch": 0.3536462350916751,
      "grad_norm": 2.3576252460479736,
      "learning_rate": 0.00013328439469015725,
      "loss": 0.166,
      "step": 5960
    },
    {
      "epoch": 0.35483296742419745,
      "grad_norm": 0.841102123260498,
      "learning_rate": 0.0001330397014742766,
      "loss": 0.1745,
      "step": 5980
    },
    {
      "epoch": 0.3560196997567199,
      "grad_norm": 0.439403235912323,
      "learning_rate": 0.00013279500825839603,
      "loss": 0.181,
      "step": 6000
    },
    {
      "epoch": 0.3572064320892423,
      "grad_norm": 0.5716937780380249,
      "learning_rate": 0.00013255031504251545,
      "loss": 0.1629,
      "step": 6020
    },
    {
      "epoch": 0.35839316442176467,
      "grad_norm": 0.5035268664360046,
      "learning_rate": 0.00013230562182663485,
      "loss": 0.1713,
      "step": 6040
    },
    {
      "epoch": 0.3595798967542871,
      "grad_norm": 0.896990954875946,
      "learning_rate": 0.00013206092861075427,
      "loss": 0.1732,
      "step": 6060
    },
    {
      "epoch": 0.36076662908680945,
      "grad_norm": 0.7655892372131348,
      "learning_rate": 0.0001318162353948737,
      "loss": 0.1689,
      "step": 6080
    },
    {
      "epoch": 0.3619533614193319,
      "grad_norm": 1.6921346187591553,
      "learning_rate": 0.0001315715421789931,
      "loss": 0.1899,
      "step": 6100
    },
    {
      "epoch": 0.36314009375185424,
      "grad_norm": 1.13388991355896,
      "learning_rate": 0.0001313268489631125,
      "loss": 0.1878,
      "step": 6120
    },
    {
      "epoch": 0.36432682608437666,
      "grad_norm": 0.9791429042816162,
      "learning_rate": 0.0001310821557472319,
      "loss": 0.1774,
      "step": 6140
    },
    {
      "epoch": 0.3655135584168991,
      "grad_norm": 0.6616879105567932,
      "learning_rate": 0.00013083746253135132,
      "loss": 0.1424,
      "step": 6160
    },
    {
      "epoch": 0.36670029074942145,
      "grad_norm": 1.074009895324707,
      "learning_rate": 0.00013059276931547074,
      "loss": 0.1782,
      "step": 6180
    },
    {
      "epoch": 0.3678870230819439,
      "grad_norm": 0.5891243815422058,
      "learning_rate": 0.00013034807609959014,
      "loss": 0.1774,
      "step": 6200
    },
    {
      "epoch": 0.36907375541446624,
      "grad_norm": 0.7237803936004639,
      "learning_rate": 0.00013010338288370956,
      "loss": 0.1698,
      "step": 6220
    },
    {
      "epoch": 0.37026048774698866,
      "grad_norm": 0.6254242062568665,
      "learning_rate": 0.00012985868966782898,
      "loss": 0.1686,
      "step": 6240
    },
    {
      "epoch": 0.3714472200795111,
      "grad_norm": 1.0693565607070923,
      "learning_rate": 0.00012961399645194837,
      "loss": 0.1641,
      "step": 6260
    },
    {
      "epoch": 0.37263395241203345,
      "grad_norm": 0.6986558437347412,
      "learning_rate": 0.0001293693032360678,
      "loss": 0.1608,
      "step": 6280
    },
    {
      "epoch": 0.3738206847445559,
      "grad_norm": 0.792923092842102,
      "learning_rate": 0.0001291246100201872,
      "loss": 0.1636,
      "step": 6300
    },
    {
      "epoch": 0.37500741707707824,
      "grad_norm": 1.2929229736328125,
      "learning_rate": 0.0001288799168043066,
      "loss": 0.1838,
      "step": 6320
    },
    {
      "epoch": 0.37619414940960066,
      "grad_norm": 0.7715321779251099,
      "learning_rate": 0.000128635223588426,
      "loss": 0.1722,
      "step": 6340
    },
    {
      "epoch": 0.3773808817421231,
      "grad_norm": 1.2694029808044434,
      "learning_rate": 0.00012839053037254542,
      "loss": 0.1735,
      "step": 6360
    },
    {
      "epoch": 0.37856761407464545,
      "grad_norm": 0.7846623063087463,
      "learning_rate": 0.00012814583715666485,
      "loss": 0.1868,
      "step": 6380
    },
    {
      "epoch": 0.3797543464071679,
      "grad_norm": 16.973602294921875,
      "learning_rate": 0.00012790114394078424,
      "loss": 0.3464,
      "step": 6400
    },
    {
      "epoch": 0.38094107873969024,
      "grad_norm": 1.2678704261779785,
      "learning_rate": 0.00012765645072490366,
      "loss": 0.167,
      "step": 6420
    },
    {
      "epoch": 0.38212781107221266,
      "grad_norm": 41.899112701416016,
      "learning_rate": 0.00012741175750902308,
      "loss": 0.2807,
      "step": 6440
    },
    {
      "epoch": 0.3833145434047351,
      "grad_norm": 4.935497760772705,
      "learning_rate": 0.00012716706429314248,
      "loss": 0.3913,
      "step": 6460
    },
    {
      "epoch": 0.38450127573725745,
      "grad_norm": 62.05120849609375,
      "learning_rate": 0.00012692237107726187,
      "loss": 0.2166,
      "step": 6480
    },
    {
      "epoch": 0.3856880080697799,
      "grad_norm": 6.091353416442871,
      "learning_rate": 0.0001266776778613813,
      "loss": 0.2494,
      "step": 6500
    },
    {
      "epoch": 0.38687474040230224,
      "grad_norm": 1.0573209524154663,
      "learning_rate": 0.0001264329846455007,
      "loss": 0.1814,
      "step": 6520
    },
    {
      "epoch": 0.38806147273482466,
      "grad_norm": 1.1235077381134033,
      "learning_rate": 0.00012618829142962013,
      "loss": 0.1717,
      "step": 6540
    },
    {
      "epoch": 0.3892482050673471,
      "grad_norm": 2.6438918113708496,
      "learning_rate": 0.00012594359821373953,
      "loss": 0.1663,
      "step": 6560
    },
    {
      "epoch": 0.39043493739986945,
      "grad_norm": 1.5034865140914917,
      "learning_rate": 0.00012569890499785895,
      "loss": 0.1699,
      "step": 6580
    },
    {
      "epoch": 0.3916216697323919,
      "grad_norm": 0.8213186860084534,
      "learning_rate": 0.00012545421178197837,
      "loss": 0.166,
      "step": 6600
    },
    {
      "epoch": 0.39280840206491424,
      "grad_norm": 0.9810675382614136,
      "learning_rate": 0.00012520951856609774,
      "loss": 0.1864,
      "step": 6620
    },
    {
      "epoch": 0.39399513439743666,
      "grad_norm": 0.6361470818519592,
      "learning_rate": 0.00012496482535021716,
      "loss": 0.1666,
      "step": 6640
    },
    {
      "epoch": 0.39518186672995903,
      "grad_norm": 0.7041540741920471,
      "learning_rate": 0.00012472013213433658,
      "loss": 0.172,
      "step": 6660
    },
    {
      "epoch": 0.39636859906248145,
      "grad_norm": 1.1377387046813965,
      "learning_rate": 0.000124475438918456,
      "loss": 0.1673,
      "step": 6680
    },
    {
      "epoch": 0.3975553313950039,
      "grad_norm": 0.7107609510421753,
      "learning_rate": 0.0001242307457025754,
      "loss": 0.1605,
      "step": 6700
    },
    {
      "epoch": 0.39874206372752624,
      "grad_norm": 0.804628849029541,
      "learning_rate": 0.00012398605248669482,
      "loss": 0.1668,
      "step": 6720
    },
    {
      "epoch": 0.39992879606004866,
      "grad_norm": 1.0936119556427002,
      "learning_rate": 0.00012374135927081424,
      "loss": 0.1672,
      "step": 6740
    },
    {
      "epoch": 0.40111552839257103,
      "grad_norm": 4.938705921173096,
      "learning_rate": 0.00012349666605493363,
      "loss": 0.1724,
      "step": 6760
    },
    {
      "epoch": 0.40230226072509345,
      "grad_norm": 1.0894315242767334,
      "learning_rate": 0.00012325197283905305,
      "loss": 0.1584,
      "step": 6780
    },
    {
      "epoch": 0.4034889930576159,
      "grad_norm": 1.688414454460144,
      "learning_rate": 0.00012300727962317245,
      "loss": 0.1822,
      "step": 6800
    },
    {
      "epoch": 0.40467572539013824,
      "grad_norm": 0.5168728828430176,
      "learning_rate": 0.00012276258640729187,
      "loss": 0.1623,
      "step": 6820
    },
    {
      "epoch": 0.40586245772266066,
      "grad_norm": 1.1598070859909058,
      "learning_rate": 0.00012251789319141126,
      "loss": 0.1586,
      "step": 6840
    },
    {
      "epoch": 0.40704919005518303,
      "grad_norm": 1.077757477760315,
      "learning_rate": 0.00012227319997553068,
      "loss": 0.1732,
      "step": 6860
    },
    {
      "epoch": 0.40823592238770545,
      "grad_norm": 1.4394081830978394,
      "learning_rate": 0.0001220285067596501,
      "loss": 0.1852,
      "step": 6880
    },
    {
      "epoch": 0.4094226547202279,
      "grad_norm": 1.2819745540618896,
      "learning_rate": 0.00012178381354376951,
      "loss": 0.1644,
      "step": 6900
    },
    {
      "epoch": 0.41060938705275024,
      "grad_norm": 0.7881737351417542,
      "learning_rate": 0.00012153912032788892,
      "loss": 0.1812,
      "step": 6920
    },
    {
      "epoch": 0.41179611938527266,
      "grad_norm": 1.2907514572143555,
      "learning_rate": 0.00012129442711200834,
      "loss": 0.1684,
      "step": 6940
    },
    {
      "epoch": 0.41298285171779503,
      "grad_norm": 1.647422194480896,
      "learning_rate": 0.00012104973389612772,
      "loss": 0.1543,
      "step": 6960
    },
    {
      "epoch": 0.41416958405031745,
      "grad_norm": 0.9219055771827698,
      "learning_rate": 0.00012080504068024714,
      "loss": 0.164,
      "step": 6980
    },
    {
      "epoch": 0.4153563163828399,
      "grad_norm": 1.1529688835144043,
      "learning_rate": 0.00012056034746436655,
      "loss": 0.1915,
      "step": 7000
    },
    {
      "epoch": 0.41654304871536224,
      "grad_norm": 0.7309156656265259,
      "learning_rate": 0.00012031565424848597,
      "loss": 0.165,
      "step": 7020
    },
    {
      "epoch": 0.41772978104788466,
      "grad_norm": 9.753174781799316,
      "learning_rate": 0.00012007096103260538,
      "loss": 0.1893,
      "step": 7040
    },
    {
      "epoch": 0.41891651338040703,
      "grad_norm": 1.3666372299194336,
      "learning_rate": 0.00011982626781672479,
      "loss": 0.1837,
      "step": 7060
    },
    {
      "epoch": 0.42010324571292945,
      "grad_norm": 0.6707636713981628,
      "learning_rate": 0.0001195815746008442,
      "loss": 0.1713,
      "step": 7080
    },
    {
      "epoch": 0.4212899780454519,
      "grad_norm": 1.3516113758087158,
      "learning_rate": 0.00011933688138496361,
      "loss": 0.168,
      "step": 7100
    },
    {
      "epoch": 0.42247671037797424,
      "grad_norm": 0.8270538449287415,
      "learning_rate": 0.00011909218816908301,
      "loss": 0.1791,
      "step": 7120
    },
    {
      "epoch": 0.42366344271049666,
      "grad_norm": 4.664190292358398,
      "learning_rate": 0.00011884749495320242,
      "loss": 0.15,
      "step": 7140
    },
    {
      "epoch": 0.42485017504301903,
      "grad_norm": 1.1409603357315063,
      "learning_rate": 0.00011860280173732184,
      "loss": 0.1512,
      "step": 7160
    },
    {
      "epoch": 0.42603690737554145,
      "grad_norm": 1.805514931678772,
      "learning_rate": 0.00011835810852144124,
      "loss": 0.4022,
      "step": 7180
    },
    {
      "epoch": 0.4272236397080639,
      "grad_norm": 1.7499234676361084,
      "learning_rate": 0.00011811341530556067,
      "loss": 0.1666,
      "step": 7200
    },
    {
      "epoch": 0.42841037204058624,
      "grad_norm": 0.9275690913200378,
      "learning_rate": 0.00011786872208968007,
      "loss": 0.1703,
      "step": 7220
    },
    {
      "epoch": 0.42959710437310866,
      "grad_norm": 0.5231330990791321,
      "learning_rate": 0.00011762402887379948,
      "loss": 0.1651,
      "step": 7240
    },
    {
      "epoch": 0.43078383670563103,
      "grad_norm": 1.2783204317092896,
      "learning_rate": 0.0001173793356579189,
      "loss": 0.171,
      "step": 7260
    },
    {
      "epoch": 0.43197056903815345,
      "grad_norm": 0.6127715706825256,
      "learning_rate": 0.0001171346424420383,
      "loss": 0.1516,
      "step": 7280
    },
    {
      "epoch": 0.4331573013706758,
      "grad_norm": 1.472511649131775,
      "learning_rate": 0.0001168899492261577,
      "loss": 0.1868,
      "step": 7300
    },
    {
      "epoch": 0.43434403370319824,
      "grad_norm": 1.1705501079559326,
      "learning_rate": 0.00011664525601027711,
      "loss": 0.1658,
      "step": 7320
    },
    {
      "epoch": 0.43553076603572066,
      "grad_norm": 1.1600799560546875,
      "learning_rate": 0.00011640056279439653,
      "loss": 0.1935,
      "step": 7340
    },
    {
      "epoch": 0.43671749836824303,
      "grad_norm": 0.8782849907875061,
      "learning_rate": 0.00011615586957851594,
      "loss": 0.1608,
      "step": 7360
    },
    {
      "epoch": 0.43790423070076545,
      "grad_norm": 1.052977204322815,
      "learning_rate": 0.00011591117636263536,
      "loss": 0.1619,
      "step": 7380
    },
    {
      "epoch": 0.4390909630332878,
      "grad_norm": 0.47992339730262756,
      "learning_rate": 0.00011566648314675477,
      "loss": 0.1506,
      "step": 7400
    },
    {
      "epoch": 0.44027769536581024,
      "grad_norm": 1.2783608436584473,
      "learning_rate": 0.00011542178993087418,
      "loss": 0.1684,
      "step": 7420
    },
    {
      "epoch": 0.44146442769833266,
      "grad_norm": 2.090376853942871,
      "learning_rate": 0.0001151770967149936,
      "loss": 0.1795,
      "step": 7440
    },
    {
      "epoch": 0.44265116003085503,
      "grad_norm": 0.5041515231132507,
      "learning_rate": 0.00011493240349911298,
      "loss": 0.1745,
      "step": 7460
    },
    {
      "epoch": 0.44383789236337745,
      "grad_norm": 9.69812297821045,
      "learning_rate": 0.0001146877102832324,
      "loss": 0.1966,
      "step": 7480
    },
    {
      "epoch": 0.4450246246958998,
      "grad_norm": 1.7831993103027344,
      "learning_rate": 0.0001144430170673518,
      "loss": 0.1808,
      "step": 7500
    },
    {
      "epoch": 0.44621135702842224,
      "grad_norm": 0.9546399116516113,
      "learning_rate": 0.00011419832385147123,
      "loss": 0.1739,
      "step": 7520
    },
    {
      "epoch": 0.44739808936094466,
      "grad_norm": 83.06874084472656,
      "learning_rate": 0.00011395363063559063,
      "loss": 0.1583,
      "step": 7540
    },
    {
      "epoch": 0.44858482169346703,
      "grad_norm": 0.8123738765716553,
      "learning_rate": 0.00011370893741971004,
      "loss": 0.1735,
      "step": 7560
    },
    {
      "epoch": 0.44977155402598945,
      "grad_norm": 1.7758125066757202,
      "learning_rate": 0.00011346424420382946,
      "loss": 0.1609,
      "step": 7580
    },
    {
      "epoch": 0.4509582863585118,
      "grad_norm": 0.5192275643348694,
      "learning_rate": 0.00011321955098794887,
      "loss": 0.1649,
      "step": 7600
    },
    {
      "epoch": 0.45214501869103424,
      "grad_norm": 0.8037506341934204,
      "learning_rate": 0.00011297485777206827,
      "loss": 0.1687,
      "step": 7620
    },
    {
      "epoch": 0.45333175102355666,
      "grad_norm": 0.8955836296081543,
      "learning_rate": 0.00011273016455618767,
      "loss": 0.1799,
      "step": 7640
    },
    {
      "epoch": 0.45451848335607903,
      "grad_norm": 1.079813838005066,
      "learning_rate": 0.0001124854713403071,
      "loss": 0.1715,
      "step": 7660
    },
    {
      "epoch": 0.45570521568860145,
      "grad_norm": 1.1410354375839233,
      "learning_rate": 0.0001122407781244265,
      "loss": 0.18,
      "step": 7680
    },
    {
      "epoch": 0.4568919480211238,
      "grad_norm": 18.730350494384766,
      "learning_rate": 0.00011199608490854592,
      "loss": 0.1637,
      "step": 7700
    },
    {
      "epoch": 0.45807868035364624,
      "grad_norm": 1.0099570751190186,
      "learning_rate": 0.00011175139169266533,
      "loss": 0.1683,
      "step": 7720
    },
    {
      "epoch": 0.45926541268616866,
      "grad_norm": 0.8456980586051941,
      "learning_rate": 0.00011150669847678474,
      "loss": 0.1734,
      "step": 7740
    },
    {
      "epoch": 0.46045214501869103,
      "grad_norm": 0.7574126720428467,
      "learning_rate": 0.00011126200526090416,
      "loss": 0.1727,
      "step": 7760
    },
    {
      "epoch": 0.46163887735121345,
      "grad_norm": 2.4323596954345703,
      "learning_rate": 0.00011101731204502355,
      "loss": 0.1573,
      "step": 7780
    },
    {
      "epoch": 0.4628256096837358,
      "grad_norm": 0.8543254137039185,
      "learning_rate": 0.00011077261882914296,
      "loss": 0.1775,
      "step": 7800
    },
    {
      "epoch": 0.46401234201625824,
      "grad_norm": 3.1066434383392334,
      "learning_rate": 0.00011052792561326237,
      "loss": 0.1586,
      "step": 7820
    },
    {
      "epoch": 0.4651990743487806,
      "grad_norm": 1.8382399082183838,
      "learning_rate": 0.00011028323239738179,
      "loss": 0.1734,
      "step": 7840
    },
    {
      "epoch": 0.46638580668130303,
      "grad_norm": 2.1557140350341797,
      "learning_rate": 0.0001100385391815012,
      "loss": 0.1717,
      "step": 7860
    },
    {
      "epoch": 0.46757253901382545,
      "grad_norm": 0.6277376413345337,
      "learning_rate": 0.00010979384596562062,
      "loss": 0.1662,
      "step": 7880
    },
    {
      "epoch": 0.4687592713463478,
      "grad_norm": 1.2579158544540405,
      "learning_rate": 0.00010954915274974003,
      "loss": 0.1815,
      "step": 7900
    },
    {
      "epoch": 0.46994600367887024,
      "grad_norm": 2.0366077423095703,
      "learning_rate": 0.00010930445953385943,
      "loss": 0.1662,
      "step": 7920
    },
    {
      "epoch": 0.4711327360113926,
      "grad_norm": 0.7427613735198975,
      "learning_rate": 0.00010905976631797883,
      "loss": 0.167,
      "step": 7940
    },
    {
      "epoch": 0.472319468343915,
      "grad_norm": 7.9315266609191895,
      "learning_rate": 0.00010881507310209823,
      "loss": 0.1906,
      "step": 7960
    },
    {
      "epoch": 0.47350620067643745,
      "grad_norm": 0.747260570526123,
      "learning_rate": 0.00010857037988621766,
      "loss": 0.1511,
      "step": 7980
    },
    {
      "epoch": 0.4746929330089598,
      "grad_norm": 14.752504348754883,
      "learning_rate": 0.00010832568667033706,
      "loss": 0.1692,
      "step": 8000
    },
    {
      "epoch": 0.4746929330089598,
      "eval_f1_macro": 0.5076618154656621,
      "eval_f1_micro": 0.6171833100933176,
      "eval_hamming_loss": 0.14276,
      "eval_loss": 0.1727403998374939,
      "eval_runtime": 2549.5716,
      "eval_samples_per_second": 1.961,
      "eval_steps_per_second": 0.49,
      "eval_subset_accuracy": 0.4366,
      "step": 8000
    },
    {
      "epoch": 0.47587966534148224,
      "grad_norm": 1.3373384475708008,
      "learning_rate": 0.00010808099345445648,
      "loss": 0.1529,
      "step": 8020
    },
    {
      "epoch": 0.4770663976740046,
      "grad_norm": 27.513362884521484,
      "learning_rate": 0.00010783630023857589,
      "loss": 0.2621,
      "step": 8040
    },
    {
      "epoch": 0.478253130006527,
      "grad_norm": 1.2890136241912842,
      "learning_rate": 0.0001075916070226953,
      "loss": 0.1557,
      "step": 8060
    },
    {
      "epoch": 0.47943986233904945,
      "grad_norm": 17.868915557861328,
      "learning_rate": 0.00010734691380681472,
      "loss": 0.9721,
      "step": 8080
    },
    {
      "epoch": 0.4806265946715718,
      "grad_norm": 12.354389190673828,
      "learning_rate": 0.00010710222059093413,
      "loss": 1.6496,
      "step": 8100
    },
    {
      "epoch": 0.48181332700409424,
      "grad_norm": 10.629639625549316,
      "learning_rate": 0.00010685752737505352,
      "loss": 0.4707,
      "step": 8120
    },
    {
      "epoch": 0.4830000593366166,
      "grad_norm": 4.014402866363525,
      "learning_rate": 0.00010661283415917293,
      "loss": 0.3528,
      "step": 8140
    },
    {
      "epoch": 0.484186791669139,
      "grad_norm": 1.9063389301300049,
      "learning_rate": 0.00010636814094329235,
      "loss": 0.2537,
      "step": 8160
    },
    {
      "epoch": 0.48537352400166145,
      "grad_norm": 9.228711128234863,
      "learning_rate": 0.00010612344772741176,
      "loss": 0.2374,
      "step": 8180
    },
    {
      "epoch": 0.4865602563341838,
      "grad_norm": 5.748818874359131,
      "learning_rate": 0.00010587875451153118,
      "loss": 0.3659,
      "step": 8200
    },
    {
      "epoch": 0.48774698866670624,
      "grad_norm": 2.998229503631592,
      "learning_rate": 0.00010563406129565059,
      "loss": 0.2172,
      "step": 8220
    },
    {
      "epoch": 0.4889337209992286,
      "grad_norm": 2.1962878704071045,
      "learning_rate": 0.00010538936807977,
      "loss": 0.172,
      "step": 8240
    },
    {
      "epoch": 0.490120453331751,
      "grad_norm": 1.3656944036483765,
      "learning_rate": 0.00010514467486388942,
      "loss": 0.1973,
      "step": 8260
    },
    {
      "epoch": 0.49130718566427345,
      "grad_norm": 0.9109582304954529,
      "learning_rate": 0.00010489998164800881,
      "loss": 0.1611,
      "step": 8280
    },
    {
      "epoch": 0.4924939179967958,
      "grad_norm": 0.6734132170677185,
      "learning_rate": 0.00010465528843212822,
      "loss": 0.1659,
      "step": 8300
    },
    {
      "epoch": 0.49368065032931824,
      "grad_norm": 1.5199755430221558,
      "learning_rate": 0.00010441059521624763,
      "loss": 0.1633,
      "step": 8320
    },
    {
      "epoch": 0.4948673826618406,
      "grad_norm": 1.421998381614685,
      "learning_rate": 0.00010416590200036705,
      "loss": 0.1747,
      "step": 8340
    },
    {
      "epoch": 0.496054114994363,
      "grad_norm": 5.94478702545166,
      "learning_rate": 0.00010392120878448645,
      "loss": 0.1779,
      "step": 8360
    },
    {
      "epoch": 0.4972408473268854,
      "grad_norm": 1.3415584564208984,
      "learning_rate": 0.00010367651556860588,
      "loss": 0.1667,
      "step": 8380
    },
    {
      "epoch": 0.4984275796594078,
      "grad_norm": 0.7025728225708008,
      "learning_rate": 0.00010343182235272528,
      "loss": 0.1652,
      "step": 8400
    },
    {
      "epoch": 0.49961431199193024,
      "grad_norm": 0.9568811655044556,
      "learning_rate": 0.00010318712913684469,
      "loss": 0.1635,
      "step": 8420
    },
    {
      "epoch": 0.5008010443244526,
      "grad_norm": 1.1478936672210693,
      "learning_rate": 0.00010294243592096408,
      "loss": 0.1661,
      "step": 8440
    },
    {
      "epoch": 0.501987776656975,
      "grad_norm": 0.9952514171600342,
      "learning_rate": 0.0001026977427050835,
      "loss": 0.1659,
      "step": 8460
    },
    {
      "epoch": 0.5031745089894974,
      "grad_norm": 1.3214573860168457,
      "learning_rate": 0.00010245304948920291,
      "loss": 0.161,
      "step": 8480
    },
    {
      "epoch": 0.5043612413220199,
      "grad_norm": 0.5480879545211792,
      "learning_rate": 0.00010220835627332232,
      "loss": 0.1711,
      "step": 8500
    },
    {
      "epoch": 0.5055479736545422,
      "grad_norm": 0.6845139265060425,
      "learning_rate": 0.00010196366305744174,
      "loss": 0.1732,
      "step": 8520
    },
    {
      "epoch": 0.5067347059870646,
      "grad_norm": 0.7880728840827942,
      "learning_rate": 0.00010171896984156115,
      "loss": 0.1441,
      "step": 8540
    },
    {
      "epoch": 0.507921438319587,
      "grad_norm": 0.9640655517578125,
      "learning_rate": 0.00010147427662568057,
      "loss": 0.1561,
      "step": 8560
    },
    {
      "epoch": 0.5091081706521094,
      "grad_norm": 1.209417700767517,
      "learning_rate": 0.00010122958340979998,
      "loss": 0.1602,
      "step": 8580
    },
    {
      "epoch": 0.5102949029846319,
      "grad_norm": 1.1005580425262451,
      "learning_rate": 0.00010098489019391937,
      "loss": 0.1535,
      "step": 8600
    },
    {
      "epoch": 0.5114816353171542,
      "grad_norm": 0.9173972606658936,
      "learning_rate": 0.00010074019697803878,
      "loss": 0.1891,
      "step": 8620
    },
    {
      "epoch": 0.5126683676496766,
      "grad_norm": 0.8962728977203369,
      "learning_rate": 0.00010049550376215819,
      "loss": 0.1648,
      "step": 8640
    },
    {
      "epoch": 0.513855099982199,
      "grad_norm": 1.3051421642303467,
      "learning_rate": 0.00010025081054627761,
      "loss": 0.1891,
      "step": 8660
    },
    {
      "epoch": 0.5150418323147214,
      "grad_norm": 0.9307860136032104,
      "learning_rate": 0.00010000611733039702,
      "loss": 0.1725,
      "step": 8680
    },
    {
      "epoch": 0.5162285646472438,
      "grad_norm": 3.460831880569458,
      "learning_rate": 9.976142411451644e-05,
      "loss": 0.1723,
      "step": 8700
    },
    {
      "epoch": 0.5174152969797662,
      "grad_norm": 0.4645256996154785,
      "learning_rate": 9.951673089863583e-05,
      "loss": 0.1537,
      "step": 8720
    },
    {
      "epoch": 0.5186020293122886,
      "grad_norm": 0.781754732131958,
      "learning_rate": 9.927203768275525e-05,
      "loss": 0.1642,
      "step": 8740
    },
    {
      "epoch": 0.519788761644811,
      "grad_norm": 0.6904216408729553,
      "learning_rate": 9.902734446687466e-05,
      "loss": 0.1773,
      "step": 8760
    },
    {
      "epoch": 0.5209754939773334,
      "grad_norm": 1.1753853559494019,
      "learning_rate": 9.878265125099407e-05,
      "loss": 0.1649,
      "step": 8780
    },
    {
      "epoch": 0.5221622263098558,
      "grad_norm": 1.196356177330017,
      "learning_rate": 9.853795803511348e-05,
      "loss": 0.1709,
      "step": 8800
    },
    {
      "epoch": 0.5233489586423782,
      "grad_norm": 1.5145725011825562,
      "learning_rate": 9.829326481923288e-05,
      "loss": 0.168,
      "step": 8820
    },
    {
      "epoch": 0.5245356909749006,
      "grad_norm": 1.2233328819274902,
      "learning_rate": 9.80485716033523e-05,
      "loss": 0.1675,
      "step": 8840
    },
    {
      "epoch": 0.525722423307423,
      "grad_norm": 1.2438229322433472,
      "learning_rate": 9.780387838747171e-05,
      "loss": 0.1623,
      "step": 8860
    },
    {
      "epoch": 0.5269091556399454,
      "grad_norm": 3.24249005317688,
      "learning_rate": 9.755918517159113e-05,
      "loss": 0.1951,
      "step": 8880
    },
    {
      "epoch": 0.5280958879724678,
      "grad_norm": 1.502921223640442,
      "learning_rate": 9.731449195571053e-05,
      "loss": 0.1817,
      "step": 8900
    },
    {
      "epoch": 0.5292826203049902,
      "grad_norm": 0.37311500310897827,
      "learning_rate": 9.706979873982995e-05,
      "loss": 0.1741,
      "step": 8920
    },
    {
      "epoch": 0.5304693526375126,
      "grad_norm": 0.7174970507621765,
      "learning_rate": 9.682510552394936e-05,
      "loss": 0.1664,
      "step": 8940
    },
    {
      "epoch": 0.531656084970035,
      "grad_norm": 1.2991693019866943,
      "learning_rate": 9.658041230806876e-05,
      "loss": 0.1496,
      "step": 8960
    },
    {
      "epoch": 0.5328428173025574,
      "grad_norm": 1.1527961492538452,
      "learning_rate": 9.633571909218817e-05,
      "loss": 0.168,
      "step": 8980
    },
    {
      "epoch": 0.5340295496350798,
      "grad_norm": 0.9031045436859131,
      "learning_rate": 9.609102587630758e-05,
      "loss": 0.2022,
      "step": 9000
    },
    {
      "epoch": 0.5352162819676022,
      "grad_norm": 1.6840100288391113,
      "learning_rate": 9.5846332660427e-05,
      "loss": 0.1672,
      "step": 9020
    },
    {
      "epoch": 0.5364030143001246,
      "grad_norm": 1.1786848306655884,
      "learning_rate": 9.560163944454641e-05,
      "loss": 0.1647,
      "step": 9040
    },
    {
      "epoch": 0.537589746632647,
      "grad_norm": 0.7449392080307007,
      "learning_rate": 9.535694622866581e-05,
      "loss": 0.1666,
      "step": 9060
    },
    {
      "epoch": 0.5387764789651694,
      "grad_norm": 2.1577987670898438,
      "learning_rate": 9.511225301278522e-05,
      "loss": 0.1692,
      "step": 9080
    },
    {
      "epoch": 0.5399632112976918,
      "grad_norm": 0.8253656029701233,
      "learning_rate": 9.486755979690464e-05,
      "loss": 0.1636,
      "step": 9100
    },
    {
      "epoch": 0.5411499436302142,
      "grad_norm": 1.361838698387146,
      "learning_rate": 9.462286658102405e-05,
      "loss": 0.1768,
      "step": 9120
    },
    {
      "epoch": 0.5423366759627366,
      "grad_norm": 1.0262514352798462,
      "learning_rate": 9.437817336514345e-05,
      "loss": 0.1559,
      "step": 9140
    },
    {
      "epoch": 0.543523408295259,
      "grad_norm": 0.8440461754798889,
      "learning_rate": 9.413348014926287e-05,
      "loss": 0.1571,
      "step": 9160
    },
    {
      "epoch": 0.5447101406277814,
      "grad_norm": 1.2586268186569214,
      "learning_rate": 9.388878693338227e-05,
      "loss": 0.1746,
      "step": 9180
    },
    {
      "epoch": 0.5458968729603038,
      "grad_norm": 1.003884196281433,
      "learning_rate": 9.36440937175017e-05,
      "loss": 0.1571,
      "step": 9200
    },
    {
      "epoch": 0.5470836052928262,
      "grad_norm": 1.9615572690963745,
      "learning_rate": 9.339940050162109e-05,
      "loss": 0.171,
      "step": 9220
    },
    {
      "epoch": 0.5482703376253486,
      "grad_norm": 1.904029130935669,
      "learning_rate": 9.315470728574051e-05,
      "loss": 0.1695,
      "step": 9240
    },
    {
      "epoch": 0.549457069957871,
      "grad_norm": 1.3810856342315674,
      "learning_rate": 9.291001406985992e-05,
      "loss": 0.1607,
      "step": 9260
    },
    {
      "epoch": 0.5506438022903934,
      "grad_norm": 1.0624585151672363,
      "learning_rate": 9.266532085397933e-05,
      "loss": 0.1679,
      "step": 9280
    },
    {
      "epoch": 0.5518305346229158,
      "grad_norm": 0.6716486811637878,
      "learning_rate": 9.242062763809873e-05,
      "loss": 0.1597,
      "step": 9300
    },
    {
      "epoch": 0.5530172669554382,
      "grad_norm": 0.7917985916137695,
      "learning_rate": 9.217593442221814e-05,
      "loss": 0.176,
      "step": 9320
    },
    {
      "epoch": 0.5542039992879606,
      "grad_norm": 0.9057766199111938,
      "learning_rate": 9.193124120633756e-05,
      "loss": 0.1774,
      "step": 9340
    },
    {
      "epoch": 0.555390731620483,
      "grad_norm": 1.4474252462387085,
      "learning_rate": 9.168654799045697e-05,
      "loss": 0.1579,
      "step": 9360
    },
    {
      "epoch": 0.5565774639530054,
      "grad_norm": 1.5514397621154785,
      "learning_rate": 9.144185477457638e-05,
      "loss": 0.1677,
      "step": 9380
    },
    {
      "epoch": 0.5577641962855278,
      "grad_norm": 3.20963716506958,
      "learning_rate": 9.119716155869578e-05,
      "loss": 0.1546,
      "step": 9400
    },
    {
      "epoch": 0.5589509286180502,
      "grad_norm": 2.0647146701812744,
      "learning_rate": 9.09524683428152e-05,
      "loss": 0.1713,
      "step": 9420
    },
    {
      "epoch": 0.5601376609505726,
      "grad_norm": 1.4477627277374268,
      "learning_rate": 9.070777512693461e-05,
      "loss": 0.1539,
      "step": 9440
    },
    {
      "epoch": 0.561324393283095,
      "grad_norm": 1.5645662546157837,
      "learning_rate": 9.046308191105402e-05,
      "loss": 0.1712,
      "step": 9460
    },
    {
      "epoch": 0.5625111256156174,
      "grad_norm": 0.7419193983078003,
      "learning_rate": 9.021838869517343e-05,
      "loss": 0.1534,
      "step": 9480
    },
    {
      "epoch": 0.5636978579481398,
      "grad_norm": 0.6194939613342285,
      "learning_rate": 8.997369547929284e-05,
      "loss": 0.1591,
      "step": 9500
    },
    {
      "epoch": 0.5648845902806622,
      "grad_norm": 1.1348730325698853,
      "learning_rate": 8.972900226341226e-05,
      "loss": 0.1601,
      "step": 9520
    },
    {
      "epoch": 0.5660713226131846,
      "grad_norm": 0.9088714718818665,
      "learning_rate": 8.948430904753166e-05,
      "loss": 0.177,
      "step": 9540
    },
    {
      "epoch": 0.567258054945707,
      "grad_norm": 0.7607436180114746,
      "learning_rate": 8.923961583165107e-05,
      "loss": 0.1717,
      "step": 9560
    },
    {
      "epoch": 0.5684447872782294,
      "grad_norm": 0.9640986919403076,
      "learning_rate": 8.899492261577048e-05,
      "loss": 0.1752,
      "step": 9580
    },
    {
      "epoch": 0.5696315196107518,
      "grad_norm": 1.2132515907287598,
      "learning_rate": 8.87502293998899e-05,
      "loss": 0.1726,
      "step": 9600
    },
    {
      "epoch": 0.5708182519432742,
      "grad_norm": 1.5082755088806152,
      "learning_rate": 8.850553618400931e-05,
      "loss": 0.1485,
      "step": 9620
    },
    {
      "epoch": 0.5720049842757966,
      "grad_norm": 1.0347810983657837,
      "learning_rate": 8.826084296812872e-05,
      "loss": 0.2158,
      "step": 9640
    },
    {
      "epoch": 0.573191716608319,
      "grad_norm": 1.3149455785751343,
      "learning_rate": 8.801614975224812e-05,
      "loss": 0.1767,
      "step": 9660
    },
    {
      "epoch": 0.5743784489408414,
      "grad_norm": 0.9804579615592957,
      "learning_rate": 8.777145653636753e-05,
      "loss": 0.1649,
      "step": 9680
    },
    {
      "epoch": 0.5755651812733638,
      "grad_norm": 0.7767550349235535,
      "learning_rate": 8.752676332048695e-05,
      "loss": 0.1491,
      "step": 9700
    },
    {
      "epoch": 0.5767519136058862,
      "grad_norm": 1.115835189819336,
      "learning_rate": 8.728207010460635e-05,
      "loss": 0.1434,
      "step": 9720
    },
    {
      "epoch": 0.5779386459384086,
      "grad_norm": 1.3298214673995972,
      "learning_rate": 8.703737688872577e-05,
      "loss": 0.166,
      "step": 9740
    },
    {
      "epoch": 0.579125378270931,
      "grad_norm": 1.1583714485168457,
      "learning_rate": 8.679268367284518e-05,
      "loss": 0.1682,
      "step": 9760
    },
    {
      "epoch": 0.5803121106034534,
      "grad_norm": 1.3800996541976929,
      "learning_rate": 8.654799045696458e-05,
      "loss": 0.1731,
      "step": 9780
    },
    {
      "epoch": 0.5814988429359758,
      "grad_norm": 1.1005455255508423,
      "learning_rate": 8.630329724108399e-05,
      "loss": 0.1651,
      "step": 9800
    },
    {
      "epoch": 0.5826855752684982,
      "grad_norm": 1.6584442853927612,
      "learning_rate": 8.60586040252034e-05,
      "loss": 0.1739,
      "step": 9820
    },
    {
      "epoch": 0.5838723076010206,
      "grad_norm": 0.6407015323638916,
      "learning_rate": 8.581391080932282e-05,
      "loss": 0.1687,
      "step": 9840
    },
    {
      "epoch": 0.585059039933543,
      "grad_norm": 2.831235408782959,
      "learning_rate": 8.556921759344223e-05,
      "loss": 0.1522,
      "step": 9860
    },
    {
      "epoch": 0.5862457722660653,
      "grad_norm": 6.428277015686035,
      "learning_rate": 8.532452437756163e-05,
      "loss": 0.1731,
      "step": 9880
    },
    {
      "epoch": 0.5874325045985878,
      "grad_norm": 0.8103683590888977,
      "learning_rate": 8.507983116168104e-05,
      "loss": 0.1489,
      "step": 9900
    },
    {
      "epoch": 0.5886192369311102,
      "grad_norm": 2.0714173316955566,
      "learning_rate": 8.483513794580046e-05,
      "loss": 0.1587,
      "step": 9920
    },
    {
      "epoch": 0.5898059692636326,
      "grad_norm": 0.854547917842865,
      "learning_rate": 8.459044472991987e-05,
      "loss": 0.1531,
      "step": 9940
    },
    {
      "epoch": 0.590992701596155,
      "grad_norm": 0.8453658223152161,
      "learning_rate": 8.434575151403928e-05,
      "loss": 0.1676,
      "step": 9960
    },
    {
      "epoch": 0.5921794339286773,
      "grad_norm": 0.8606142997741699,
      "learning_rate": 8.410105829815869e-05,
      "loss": 0.1616,
      "step": 9980
    },
    {
      "epoch": 0.5933661662611998,
      "grad_norm": 1.1115299463272095,
      "learning_rate": 8.38563650822781e-05,
      "loss": 0.1667,
      "step": 10000
    },
    {
      "epoch": 0.5945528985937222,
      "grad_norm": 0.798319935798645,
      "learning_rate": 8.361167186639751e-05,
      "loss": 0.1708,
      "step": 10020
    },
    {
      "epoch": 0.5957396309262446,
      "grad_norm": 1.3486615419387817,
      "learning_rate": 8.336697865051691e-05,
      "loss": 0.171,
      "step": 10040
    },
    {
      "epoch": 0.596926363258767,
      "grad_norm": 0.8395332098007202,
      "learning_rate": 8.312228543463633e-05,
      "loss": 0.1639,
      "step": 10060
    },
    {
      "epoch": 0.5981130955912893,
      "grad_norm": 0.6181435585021973,
      "learning_rate": 8.287759221875574e-05,
      "loss": 0.1669,
      "step": 10080
    },
    {
      "epoch": 0.5992998279238118,
      "grad_norm": 0.4575267732143402,
      "learning_rate": 8.263289900287516e-05,
      "loss": 0.1688,
      "step": 10100
    },
    {
      "epoch": 0.6004865602563342,
      "grad_norm": 0.952674925327301,
      "learning_rate": 8.238820578699455e-05,
      "loss": 0.1796,
      "step": 10120
    },
    {
      "epoch": 0.6016732925888566,
      "grad_norm": 1.4998407363891602,
      "learning_rate": 8.214351257111397e-05,
      "loss": 0.1556,
      "step": 10140
    },
    {
      "epoch": 0.602860024921379,
      "grad_norm": 0.4141044318675995,
      "learning_rate": 8.189881935523338e-05,
      "loss": 0.1683,
      "step": 10160
    },
    {
      "epoch": 0.6040467572539013,
      "grad_norm": 0.5088438391685486,
      "learning_rate": 8.165412613935279e-05,
      "loss": 0.1642,
      "step": 10180
    },
    {
      "epoch": 0.6052334895864238,
      "grad_norm": 1.0137635469436646,
      "learning_rate": 8.14094329234722e-05,
      "loss": 0.1637,
      "step": 10200
    },
    {
      "epoch": 0.6064202219189462,
      "grad_norm": 1.8078919649124146,
      "learning_rate": 8.11647397075916e-05,
      "loss": 0.1831,
      "step": 10220
    },
    {
      "epoch": 0.6076069542514686,
      "grad_norm": 0.7353655695915222,
      "learning_rate": 8.092004649171103e-05,
      "loss": 0.1768,
      "step": 10240
    },
    {
      "epoch": 0.608793686583991,
      "grad_norm": 3.242995023727417,
      "learning_rate": 8.067535327583043e-05,
      "loss": 0.1642,
      "step": 10260
    },
    {
      "epoch": 0.6099804189165133,
      "grad_norm": 2.854156017303467,
      "learning_rate": 8.043066005994984e-05,
      "loss": 0.2207,
      "step": 10280
    },
    {
      "epoch": 0.6111671512490358,
      "grad_norm": 6.615535736083984,
      "learning_rate": 8.018596684406925e-05,
      "loss": 0.1837,
      "step": 10300
    },
    {
      "epoch": 0.6123538835815582,
      "grad_norm": 1.1014527082443237,
      "learning_rate": 7.994127362818866e-05,
      "loss": 0.1651,
      "step": 10320
    },
    {
      "epoch": 0.6135406159140806,
      "grad_norm": 1.0433247089385986,
      "learning_rate": 7.969658041230808e-05,
      "loss": 0.1646,
      "step": 10340
    },
    {
      "epoch": 0.614727348246603,
      "grad_norm": 1.2581597566604614,
      "learning_rate": 7.945188719642748e-05,
      "loss": 0.1772,
      "step": 10360
    },
    {
      "epoch": 0.6159140805791253,
      "grad_norm": 1.2963052988052368,
      "learning_rate": 7.920719398054689e-05,
      "loss": 0.1546,
      "step": 10380
    },
    {
      "epoch": 0.6171008129116478,
      "grad_norm": 1.2652305364608765,
      "learning_rate": 7.89625007646663e-05,
      "loss": 0.1769,
      "step": 10400
    },
    {
      "epoch": 0.6182875452441702,
      "grad_norm": 0.5101978182792664,
      "learning_rate": 7.871780754878572e-05,
      "loss": 0.1692,
      "step": 10420
    },
    {
      "epoch": 0.6194742775766926,
      "grad_norm": 1.442609190940857,
      "learning_rate": 7.847311433290513e-05,
      "loss": 0.1814,
      "step": 10440
    },
    {
      "epoch": 0.620661009909215,
      "grad_norm": 1.0972439050674438,
      "learning_rate": 7.822842111702454e-05,
      "loss": 0.173,
      "step": 10460
    },
    {
      "epoch": 0.6218477422417373,
      "grad_norm": 1.3130066394805908,
      "learning_rate": 7.798372790114394e-05,
      "loss": 0.1846,
      "step": 10480
    },
    {
      "epoch": 0.6230344745742598,
      "grad_norm": 0.6125274896621704,
      "learning_rate": 7.773903468526335e-05,
      "loss": 0.1599,
      "step": 10500
    },
    {
      "epoch": 0.6242212069067822,
      "grad_norm": 0.97906893491745,
      "learning_rate": 7.749434146938277e-05,
      "loss": 0.1656,
      "step": 10520
    },
    {
      "epoch": 0.6254079392393046,
      "grad_norm": 0.7247392535209656,
      "learning_rate": 7.724964825350217e-05,
      "loss": 0.1736,
      "step": 10540
    },
    {
      "epoch": 0.626594671571827,
      "grad_norm": 0.7509732842445374,
      "learning_rate": 7.700495503762159e-05,
      "loss": 0.1842,
      "step": 10560
    },
    {
      "epoch": 0.6277814039043493,
      "grad_norm": 0.42545396089553833,
      "learning_rate": 7.6760261821741e-05,
      "loss": 0.1658,
      "step": 10580
    },
    {
      "epoch": 0.6289681362368718,
      "grad_norm": 0.8465055823326111,
      "learning_rate": 7.651556860586042e-05,
      "loss": 0.1622,
      "step": 10600
    },
    {
      "epoch": 0.6301548685693942,
      "grad_norm": 0.7756063938140869,
      "learning_rate": 7.627087538997981e-05,
      "loss": 0.1529,
      "step": 10620
    },
    {
      "epoch": 0.6313416009019166,
      "grad_norm": 5.3789472579956055,
      "learning_rate": 7.602618217409923e-05,
      "loss": 0.1754,
      "step": 10640
    },
    {
      "epoch": 0.632528333234439,
      "grad_norm": 0.7595348954200745,
      "learning_rate": 7.578148895821864e-05,
      "loss": 0.1649,
      "step": 10660
    },
    {
      "epoch": 0.6337150655669613,
      "grad_norm": 1.0811842679977417,
      "learning_rate": 7.553679574233805e-05,
      "loss": 0.1701,
      "step": 10680
    },
    {
      "epoch": 0.6349017978994838,
      "grad_norm": 2.3521926403045654,
      "learning_rate": 7.529210252645745e-05,
      "loss": 0.166,
      "step": 10700
    },
    {
      "epoch": 0.6360885302320062,
      "grad_norm": 0.7987802624702454,
      "learning_rate": 7.504740931057686e-05,
      "loss": 0.1745,
      "step": 10720
    },
    {
      "epoch": 0.6372752625645286,
      "grad_norm": 0.8627882599830627,
      "learning_rate": 7.480271609469628e-05,
      "loss": 0.1646,
      "step": 10740
    },
    {
      "epoch": 0.638461994897051,
      "grad_norm": 0.8803730010986328,
      "learning_rate": 7.455802287881569e-05,
      "loss": 0.1491,
      "step": 10760
    },
    {
      "epoch": 0.6396487272295733,
      "grad_norm": 2.230647325515747,
      "learning_rate": 7.43133296629351e-05,
      "loss": 0.1783,
      "step": 10780
    },
    {
      "epoch": 0.6408354595620958,
      "grad_norm": 0.6317568421363831,
      "learning_rate": 7.40686364470545e-05,
      "loss": 0.1588,
      "step": 10800
    },
    {
      "epoch": 0.6420221918946182,
      "grad_norm": 1.7293236255645752,
      "learning_rate": 7.382394323117391e-05,
      "loss": 0.1775,
      "step": 10820
    },
    {
      "epoch": 0.6432089242271406,
      "grad_norm": 1.3850821256637573,
      "learning_rate": 7.357925001529333e-05,
      "loss": 0.1664,
      "step": 10840
    },
    {
      "epoch": 0.644395656559663,
      "grad_norm": 5.118602275848389,
      "learning_rate": 7.333455679941273e-05,
      "loss": 0.17,
      "step": 10860
    },
    {
      "epoch": 0.6455823888921853,
      "grad_norm": 0.6534132361412048,
      "learning_rate": 7.308986358353215e-05,
      "loss": 0.1673,
      "step": 10880
    },
    {
      "epoch": 0.6467691212247078,
      "grad_norm": 1.0654178857803345,
      "learning_rate": 7.284517036765156e-05,
      "loss": 0.1603,
      "step": 10900
    },
    {
      "epoch": 0.6479558535572302,
      "grad_norm": 1.9333240985870361,
      "learning_rate": 7.260047715177098e-05,
      "loss": 0.1691,
      "step": 10920
    },
    {
      "epoch": 0.6491425858897526,
      "grad_norm": 2.2380588054656982,
      "learning_rate": 7.235578393589037e-05,
      "loss": 0.1731,
      "step": 10940
    },
    {
      "epoch": 0.650329318222275,
      "grad_norm": 0.46455246210098267,
      "learning_rate": 7.21110907200098e-05,
      "loss": 0.1582,
      "step": 10960
    },
    {
      "epoch": 0.6515160505547973,
      "grad_norm": 1.7563669681549072,
      "learning_rate": 7.18663975041292e-05,
      "loss": 0.1724,
      "step": 10980
    },
    {
      "epoch": 0.6527027828873198,
      "grad_norm": 0.8319675326347351,
      "learning_rate": 7.162170428824861e-05,
      "loss": 0.1555,
      "step": 11000
    },
    {
      "epoch": 0.6538895152198422,
      "grad_norm": 2.234985589981079,
      "learning_rate": 7.137701107236803e-05,
      "loss": 0.1634,
      "step": 11020
    },
    {
      "epoch": 0.6550762475523646,
      "grad_norm": 5.1534037590026855,
      "learning_rate": 7.113231785648742e-05,
      "loss": 0.1495,
      "step": 11040
    },
    {
      "epoch": 0.6562629798848869,
      "grad_norm": 1.3740261793136597,
      "learning_rate": 7.088762464060684e-05,
      "loss": 0.179,
      "step": 11060
    },
    {
      "epoch": 0.6574497122174093,
      "grad_norm": 4.477190017700195,
      "learning_rate": 7.064293142472625e-05,
      "loss": 0.1471,
      "step": 11080
    },
    {
      "epoch": 0.6586364445499318,
      "grad_norm": 1.7264114618301392,
      "learning_rate": 7.039823820884567e-05,
      "loss": 0.1603,
      "step": 11100
    },
    {
      "epoch": 0.6598231768824542,
      "grad_norm": 1.3767815828323364,
      "learning_rate": 7.015354499296507e-05,
      "loss": 0.1505,
      "step": 11120
    },
    {
      "epoch": 0.6610099092149766,
      "grad_norm": 1.8468517065048218,
      "learning_rate": 6.990885177708449e-05,
      "loss": 0.189,
      "step": 11140
    },
    {
      "epoch": 0.6621966415474989,
      "grad_norm": 1.693273663520813,
      "learning_rate": 6.96641585612039e-05,
      "loss": 0.1534,
      "step": 11160
    },
    {
      "epoch": 0.6633833738800213,
      "grad_norm": 9.392950057983398,
      "learning_rate": 6.94194653453233e-05,
      "loss": 0.1879,
      "step": 11180
    },
    {
      "epoch": 0.6645701062125438,
      "grad_norm": 1.140343427658081,
      "learning_rate": 6.917477212944271e-05,
      "loss": 0.1728,
      "step": 11200
    },
    {
      "epoch": 0.6657568385450662,
      "grad_norm": 1.0328714847564697,
      "learning_rate": 6.893007891356212e-05,
      "loss": 0.164,
      "step": 11220
    },
    {
      "epoch": 0.6669435708775886,
      "grad_norm": 44.877254486083984,
      "learning_rate": 6.868538569768154e-05,
      "loss": 0.1902,
      "step": 11240
    },
    {
      "epoch": 0.6681303032101109,
      "grad_norm": 11.887681007385254,
      "learning_rate": 6.844069248180095e-05,
      "loss": 0.5107,
      "step": 11260
    },
    {
      "epoch": 0.6693170355426333,
      "grad_norm": 19.096023559570312,
      "learning_rate": 6.819599926592036e-05,
      "loss": 1.5278,
      "step": 11280
    },
    {
      "epoch": 0.6705037678751558,
      "grad_norm": 2.629746437072754,
      "learning_rate": 6.795130605003976e-05,
      "loss": 0.2737,
      "step": 11300
    },
    {
      "epoch": 0.6716905002076782,
      "grad_norm": 0.5099070072174072,
      "learning_rate": 6.770661283415918e-05,
      "loss": 0.2096,
      "step": 11320
    },
    {
      "epoch": 0.6728772325402006,
      "grad_norm": 0.8920042514801025,
      "learning_rate": 6.746191961827859e-05,
      "loss": 0.2179,
      "step": 11340
    },
    {
      "epoch": 0.6740639648727229,
      "grad_norm": 13.001335144042969,
      "learning_rate": 6.721722640239799e-05,
      "loss": 0.2248,
      "step": 11360
    },
    {
      "epoch": 0.6752506972052453,
      "grad_norm": 6.245271682739258,
      "learning_rate": 6.697253318651741e-05,
      "loss": 0.1833,
      "step": 11380
    },
    {
      "epoch": 0.6764374295377678,
      "grad_norm": 1.2328226566314697,
      "learning_rate": 6.672783997063681e-05,
      "loss": 0.2074,
      "step": 11400
    },
    {
      "epoch": 0.6776241618702902,
      "grad_norm": 1.1328297853469849,
      "learning_rate": 6.648314675475624e-05,
      "loss": 0.1621,
      "step": 11420
    },
    {
      "epoch": 0.6788108942028126,
      "grad_norm": 1.0289896726608276,
      "learning_rate": 6.623845353887563e-05,
      "loss": 0.1936,
      "step": 11440
    },
    {
      "epoch": 0.6799976265353349,
      "grad_norm": 0.6997275352478027,
      "learning_rate": 6.599376032299505e-05,
      "loss": 0.1568,
      "step": 11460
    },
    {
      "epoch": 0.6811843588678573,
      "grad_norm": 1.114918828010559,
      "learning_rate": 6.574906710711446e-05,
      "loss": 0.1587,
      "step": 11480
    },
    {
      "epoch": 0.6823710912003798,
      "grad_norm": 0.7563111186027527,
      "learning_rate": 6.550437389123387e-05,
      "loss": 0.1785,
      "step": 11500
    },
    {
      "epoch": 0.6835578235329022,
      "grad_norm": 1.1184433698654175,
      "learning_rate": 6.525968067535327e-05,
      "loss": 0.1734,
      "step": 11520
    },
    {
      "epoch": 0.6847445558654246,
      "grad_norm": 1.0686534643173218,
      "learning_rate": 6.501498745947268e-05,
      "loss": 0.1658,
      "step": 11540
    },
    {
      "epoch": 0.6859312881979469,
      "grad_norm": 0.9119386076927185,
      "learning_rate": 6.47702942435921e-05,
      "loss": 0.1741,
      "step": 11560
    },
    {
      "epoch": 0.6871180205304693,
      "grad_norm": 1.2907822132110596,
      "learning_rate": 6.452560102771151e-05,
      "loss": 0.159,
      "step": 11580
    },
    {
      "epoch": 0.6883047528629918,
      "grad_norm": 3.007572889328003,
      "learning_rate": 6.428090781183092e-05,
      "loss": 0.1664,
      "step": 11600
    },
    {
      "epoch": 0.6894914851955142,
      "grad_norm": 0.7591491937637329,
      "learning_rate": 6.403621459595033e-05,
      "loss": 0.1593,
      "step": 11620
    },
    {
      "epoch": 0.6906782175280366,
      "grad_norm": 0.7716914415359497,
      "learning_rate": 6.379152138006975e-05,
      "loss": 0.169,
      "step": 11640
    },
    {
      "epoch": 0.6918649498605589,
      "grad_norm": 0.893073558807373,
      "learning_rate": 6.354682816418915e-05,
      "loss": 0.1515,
      "step": 11660
    },
    {
      "epoch": 0.6930516821930813,
      "grad_norm": 2.2811288833618164,
      "learning_rate": 6.330213494830856e-05,
      "loss": 0.1602,
      "step": 11680
    },
    {
      "epoch": 0.6942384145256038,
      "grad_norm": 1.7777949571609497,
      "learning_rate": 6.305744173242797e-05,
      "loss": 0.1754,
      "step": 11700
    },
    {
      "epoch": 0.6954251468581262,
      "grad_norm": 1.1215248107910156,
      "learning_rate": 6.281274851654738e-05,
      "loss": 0.1676,
      "step": 11720
    },
    {
      "epoch": 0.6966118791906486,
      "grad_norm": 6.461968421936035,
      "learning_rate": 6.25680553006668e-05,
      "loss": 0.1663,
      "step": 11740
    },
    {
      "epoch": 0.6977986115231709,
      "grad_norm": 1.5894825458526611,
      "learning_rate": 6.23233620847862e-05,
      "loss": 0.1657,
      "step": 11760
    },
    {
      "epoch": 0.6989853438556933,
      "grad_norm": 0.45283710956573486,
      "learning_rate": 6.207866886890561e-05,
      "loss": 0.1642,
      "step": 11780
    },
    {
      "epoch": 0.7001720761882158,
      "grad_norm": 4.222274303436279,
      "learning_rate": 6.183397565302502e-05,
      "loss": 0.1727,
      "step": 11800
    },
    {
      "epoch": 0.7013588085207382,
      "grad_norm": 0.776820182800293,
      "learning_rate": 6.158928243714444e-05,
      "loss": 0.1706,
      "step": 11820
    },
    {
      "epoch": 0.7025455408532606,
      "grad_norm": 1.6021605730056763,
      "learning_rate": 6.134458922126385e-05,
      "loss": 0.1625,
      "step": 11840
    },
    {
      "epoch": 0.7037322731857829,
      "grad_norm": 0.7289668321609497,
      "learning_rate": 6.109989600538326e-05,
      "loss": 0.1564,
      "step": 11860
    },
    {
      "epoch": 0.7049190055183053,
      "grad_norm": 1.006149411201477,
      "learning_rate": 6.0855202789502664e-05,
      "loss": 0.1638,
      "step": 11880
    },
    {
      "epoch": 0.7061057378508278,
      "grad_norm": 1.1934640407562256,
      "learning_rate": 6.061050957362208e-05,
      "loss": 0.1811,
      "step": 11900
    },
    {
      "epoch": 0.7072924701833502,
      "grad_norm": 1.8269023895263672,
      "learning_rate": 6.0365816357741486e-05,
      "loss": 0.1732,
      "step": 11920
    },
    {
      "epoch": 0.7084792025158726,
      "grad_norm": 3.453242301940918,
      "learning_rate": 6.0121123141860894e-05,
      "loss": 0.1796,
      "step": 11940
    },
    {
      "epoch": 0.7096659348483949,
      "grad_norm": 2.1346681118011475,
      "learning_rate": 5.98764299259803e-05,
      "loss": 0.2006,
      "step": 11960
    },
    {
      "epoch": 0.7108526671809173,
      "grad_norm": 1.7614405155181885,
      "learning_rate": 5.9631736710099716e-05,
      "loss": 0.1581,
      "step": 11980
    },
    {
      "epoch": 0.7120393995134398,
      "grad_norm": 0.9267100691795349,
      "learning_rate": 5.938704349421913e-05,
      "loss": 0.1754,
      "step": 12000
    },
    {
      "epoch": 0.7132261318459622,
      "grad_norm": 1.1352806091308594,
      "learning_rate": 5.914235027833853e-05,
      "loss": 0.141,
      "step": 12020
    },
    {
      "epoch": 0.7144128641784846,
      "grad_norm": 1.180381417274475,
      "learning_rate": 5.8897657062457946e-05,
      "loss": 0.164,
      "step": 12040
    },
    {
      "epoch": 0.7155995965110069,
      "grad_norm": 0.6289962530136108,
      "learning_rate": 5.865296384657736e-05,
      "loss": 0.1562,
      "step": 12060
    },
    {
      "epoch": 0.7167863288435293,
      "grad_norm": 0.8167892694473267,
      "learning_rate": 5.840827063069677e-05,
      "loss": 0.1773,
      "step": 12080
    },
    {
      "epoch": 0.7179730611760518,
      "grad_norm": 0.9028870463371277,
      "learning_rate": 5.8163577414816175e-05,
      "loss": 0.1763,
      "step": 12100
    },
    {
      "epoch": 0.7191597935085742,
      "grad_norm": 0.9228540658950806,
      "learning_rate": 5.791888419893558e-05,
      "loss": 0.1835,
      "step": 12120
    },
    {
      "epoch": 0.7203465258410965,
      "grad_norm": 2.6607894897460938,
      "learning_rate": 5.7674190983055e-05,
      "loss": 0.1702,
      "step": 12140
    },
    {
      "epoch": 0.7215332581736189,
      "grad_norm": 1.132436752319336,
      "learning_rate": 5.742949776717441e-05,
      "loss": 0.1617,
      "step": 12160
    },
    {
      "epoch": 0.7227199905061413,
      "grad_norm": 0.710364043712616,
      "learning_rate": 5.718480455129381e-05,
      "loss": 0.1574,
      "step": 12180
    },
    {
      "epoch": 0.7239067228386638,
      "grad_norm": 0.8816044330596924,
      "learning_rate": 5.6940111335413227e-05,
      "loss": 0.1618,
      "step": 12200
    },
    {
      "epoch": 0.7250934551711862,
      "grad_norm": 1.0970864295959473,
      "learning_rate": 5.669541811953264e-05,
      "loss": 0.1835,
      "step": 12220
    },
    {
      "epoch": 0.7262801875037085,
      "grad_norm": 0.7525720596313477,
      "learning_rate": 5.6450724903652055e-05,
      "loss": 0.1692,
      "step": 12240
    },
    {
      "epoch": 0.7274669198362309,
      "grad_norm": 0.5586991906166077,
      "learning_rate": 5.6206031687771456e-05,
      "loss": 0.1786,
      "step": 12260
    },
    {
      "epoch": 0.7286536521687533,
      "grad_norm": 0.6439306139945984,
      "learning_rate": 5.596133847189087e-05,
      "loss": 0.1762,
      "step": 12280
    },
    {
      "epoch": 0.7298403845012758,
      "grad_norm": 1.3816107511520386,
      "learning_rate": 5.571664525601028e-05,
      "loss": 0.1802,
      "step": 12300
    },
    {
      "epoch": 0.7310271168337982,
      "grad_norm": 0.8978223204612732,
      "learning_rate": 5.547195204012969e-05,
      "loss": 0.1568,
      "step": 12320
    },
    {
      "epoch": 0.7322138491663205,
      "grad_norm": 0.8628273010253906,
      "learning_rate": 5.522725882424909e-05,
      "loss": 0.1622,
      "step": 12340
    },
    {
      "epoch": 0.7334005814988429,
      "grad_norm": 1.2743124961853027,
      "learning_rate": 5.498256560836851e-05,
      "loss": 0.1662,
      "step": 12360
    },
    {
      "epoch": 0.7345873138313653,
      "grad_norm": 1.567068099975586,
      "learning_rate": 5.473787239248792e-05,
      "loss": 0.161,
      "step": 12380
    },
    {
      "epoch": 0.7357740461638878,
      "grad_norm": 0.9226250648498535,
      "learning_rate": 5.4493179176607336e-05,
      "loss": 0.191,
      "step": 12400
    },
    {
      "epoch": 0.7369607784964102,
      "grad_norm": 1.2909382581710815,
      "learning_rate": 5.424848596072674e-05,
      "loss": 0.1526,
      "step": 12420
    },
    {
      "epoch": 0.7381475108289325,
      "grad_norm": 1.1802120208740234,
      "learning_rate": 5.400379274484615e-05,
      "loss": 0.1692,
      "step": 12440
    },
    {
      "epoch": 0.7393342431614549,
      "grad_norm": 0.7781651616096497,
      "learning_rate": 5.375909952896556e-05,
      "loss": 0.1596,
      "step": 12460
    },
    {
      "epoch": 0.7405209754939773,
      "grad_norm": 0.6589269042015076,
      "learning_rate": 5.3514406313084973e-05,
      "loss": 0.1601,
      "step": 12480
    },
    {
      "epoch": 0.7417077078264998,
      "grad_norm": 1.0843333005905151,
      "learning_rate": 5.326971309720439e-05,
      "loss": 0.1589,
      "step": 12500
    },
    {
      "epoch": 0.7428944401590222,
      "grad_norm": 0.8429961800575256,
      "learning_rate": 5.302501988132379e-05,
      "loss": 0.1801,
      "step": 12520
    },
    {
      "epoch": 0.7440811724915445,
      "grad_norm": 2.493960380554199,
      "learning_rate": 5.27803266654432e-05,
      "loss": 0.1617,
      "step": 12540
    },
    {
      "epoch": 0.7452679048240669,
      "grad_norm": 1.06040358543396,
      "learning_rate": 5.253563344956262e-05,
      "loss": 0.1653,
      "step": 12560
    },
    {
      "epoch": 0.7464546371565893,
      "grad_norm": 2.120884895324707,
      "learning_rate": 5.229094023368203e-05,
      "loss": 0.1536,
      "step": 12580
    },
    {
      "epoch": 0.7476413694891118,
      "grad_norm": 2.8878087997436523,
      "learning_rate": 5.204624701780143e-05,
      "loss": 0.1687,
      "step": 12600
    },
    {
      "epoch": 0.7488281018216342,
      "grad_norm": 1.1188867092132568,
      "learning_rate": 5.180155380192084e-05,
      "loss": 0.1717,
      "step": 12620
    },
    {
      "epoch": 0.7500148341541565,
      "grad_norm": 0.6875267624855042,
      "learning_rate": 5.1556860586040255e-05,
      "loss": 0.177,
      "step": 12640
    },
    {
      "epoch": 0.7512015664866789,
      "grad_norm": 1.0520172119140625,
      "learning_rate": 5.131216737015967e-05,
      "loss": 0.173,
      "step": 12660
    },
    {
      "epoch": 0.7523882988192013,
      "grad_norm": 1.390306830406189,
      "learning_rate": 5.106747415427907e-05,
      "loss": 0.1775,
      "step": 12680
    },
    {
      "epoch": 0.7535750311517238,
      "grad_norm": 1.3953620195388794,
      "learning_rate": 5.0822780938398484e-05,
      "loss": 0.1623,
      "step": 12700
    },
    {
      "epoch": 0.7547617634842462,
      "grad_norm": 1.2323246002197266,
      "learning_rate": 5.05780877225179e-05,
      "loss": 0.1569,
      "step": 12720
    },
    {
      "epoch": 0.7559484958167685,
      "grad_norm": 47.839111328125,
      "learning_rate": 5.033339450663731e-05,
      "loss": 0.5652,
      "step": 12740
    },
    {
      "epoch": 0.7571352281492909,
      "grad_norm": 9.612114906311035,
      "learning_rate": 5.0088701290756714e-05,
      "loss": 0.7547,
      "step": 12760
    },
    {
      "epoch": 0.7583219604818133,
      "grad_norm": 1.2672762870788574,
      "learning_rate": 4.984400807487613e-05,
      "loss": 0.1886,
      "step": 12780
    },
    {
      "epoch": 0.7595086928143358,
      "grad_norm": 1.2038297653198242,
      "learning_rate": 4.9599314858995536e-05,
      "loss": 0.22,
      "step": 12800
    },
    {
      "epoch": 0.7606954251468582,
      "grad_norm": 0.474459171295166,
      "learning_rate": 4.935462164311494e-05,
      "loss": 0.1591,
      "step": 12820
    },
    {
      "epoch": 0.7618821574793805,
      "grad_norm": 0.9175671935081482,
      "learning_rate": 4.910992842723436e-05,
      "loss": 0.1754,
      "step": 12840
    },
    {
      "epoch": 0.7630688898119029,
      "grad_norm": 1.0090142488479614,
      "learning_rate": 4.8865235211353765e-05,
      "loss": 0.1565,
      "step": 12860
    },
    {
      "epoch": 0.7642556221444253,
      "grad_norm": 0.7027666568756104,
      "learning_rate": 4.862054199547318e-05,
      "loss": 0.1641,
      "step": 12880
    },
    {
      "epoch": 0.7654423544769478,
      "grad_norm": 0.9462083578109741,
      "learning_rate": 4.837584877959259e-05,
      "loss": 0.1521,
      "step": 12900
    },
    {
      "epoch": 0.7666290868094702,
      "grad_norm": 1.3414288759231567,
      "learning_rate": 4.8131155563712e-05,
      "loss": 0.1627,
      "step": 12920
    },
    {
      "epoch": 0.7678158191419925,
      "grad_norm": 1.0549986362457275,
      "learning_rate": 4.788646234783141e-05,
      "loss": 0.1547,
      "step": 12940
    },
    {
      "epoch": 0.7690025514745149,
      "grad_norm": 1.2210437059402466,
      "learning_rate": 4.7641769131950817e-05,
      "loss": 0.1611,
      "step": 12960
    },
    {
      "epoch": 0.7701892838070373,
      "grad_norm": 1.5889935493469238,
      "learning_rate": 4.7397075916070224e-05,
      "loss": 0.1659,
      "step": 12980
    },
    {
      "epoch": 0.7713760161395598,
      "grad_norm": 1.740614891052246,
      "learning_rate": 4.715238270018964e-05,
      "loss": 0.1472,
      "step": 13000
    },
    {
      "epoch": 0.7725627484720822,
      "grad_norm": 0.8346611261367798,
      "learning_rate": 4.6907689484309046e-05,
      "loss": 0.169,
      "step": 13020
    },
    {
      "epoch": 0.7737494808046045,
      "grad_norm": 2.294154405593872,
      "learning_rate": 4.666299626842846e-05,
      "loss": 0.165,
      "step": 13040
    },
    {
      "epoch": 0.7749362131371269,
      "grad_norm": 0.9757019877433777,
      "learning_rate": 4.641830305254787e-05,
      "loss": 0.162,
      "step": 13060
    },
    {
      "epoch": 0.7761229454696493,
      "grad_norm": 0.7179786562919617,
      "learning_rate": 4.617360983666728e-05,
      "loss": 0.1582,
      "step": 13080
    },
    {
      "epoch": 0.7773096778021718,
      "grad_norm": 1.3688009977340698,
      "learning_rate": 4.592891662078669e-05,
      "loss": 0.1655,
      "step": 13100
    },
    {
      "epoch": 0.7784964101346942,
      "grad_norm": 1.2378979921340942,
      "learning_rate": 4.5684223404906104e-05,
      "loss": 0.1469,
      "step": 13120
    },
    {
      "epoch": 0.7796831424672165,
      "grad_norm": 1.1145250797271729,
      "learning_rate": 4.543953018902551e-05,
      "loss": 0.1555,
      "step": 13140
    },
    {
      "epoch": 0.7808698747997389,
      "grad_norm": 0.5987105369567871,
      "learning_rate": 4.519483697314492e-05,
      "loss": 0.1605,
      "step": 13160
    },
    {
      "epoch": 0.7820566071322613,
      "grad_norm": 1.340095043182373,
      "learning_rate": 4.4950143757264334e-05,
      "loss": 0.1592,
      "step": 13180
    },
    {
      "epoch": 0.7832433394647837,
      "grad_norm": 0.5632576942443848,
      "learning_rate": 4.470545054138374e-05,
      "loss": 0.1599,
      "step": 13200
    },
    {
      "epoch": 0.7844300717973062,
      "grad_norm": 0.4038182199001312,
      "learning_rate": 4.4460757325503156e-05,
      "loss": 0.1715,
      "step": 13220
    },
    {
      "epoch": 0.7856168041298285,
      "grad_norm": 0.8155516982078552,
      "learning_rate": 4.4216064109622563e-05,
      "loss": 0.1567,
      "step": 13240
    },
    {
      "epoch": 0.7868035364623509,
      "grad_norm": 0.9075663685798645,
      "learning_rate": 4.397137089374198e-05,
      "loss": 0.1667,
      "step": 13260
    },
    {
      "epoch": 0.7879902687948733,
      "grad_norm": 0.6601107120513916,
      "learning_rate": 4.3726677677861385e-05,
      "loss": 0.1579,
      "step": 13280
    },
    {
      "epoch": 0.7891770011273957,
      "grad_norm": 0.8672672510147095,
      "learning_rate": 4.348198446198079e-05,
      "loss": 0.1671,
      "step": 13300
    },
    {
      "epoch": 0.7903637334599181,
      "grad_norm": 3.4951252937316895,
      "learning_rate": 4.32372912461002e-05,
      "loss": 0.1669,
      "step": 13320
    },
    {
      "epoch": 0.7915504657924405,
      "grad_norm": 1.2903674840927124,
      "learning_rate": 4.2992598030219615e-05,
      "loss": 0.1673,
      "step": 13340
    },
    {
      "epoch": 0.7927371981249629,
      "grad_norm": 0.9298946857452393,
      "learning_rate": 4.274790481433902e-05,
      "loss": 0.2148,
      "step": 13360
    },
    {
      "epoch": 0.7939239304574853,
      "grad_norm": 0.6980463266372681,
      "learning_rate": 4.250321159845844e-05,
      "loss": 0.1581,
      "step": 13380
    },
    {
      "epoch": 0.7951106627900077,
      "grad_norm": 0.7300869226455688,
      "learning_rate": 4.2258518382577845e-05,
      "loss": 0.1536,
      "step": 13400
    },
    {
      "epoch": 0.7962973951225301,
      "grad_norm": 0.35252898931503296,
      "learning_rate": 4.201382516669726e-05,
      "loss": 0.1831,
      "step": 13420
    },
    {
      "epoch": 0.7974841274550525,
      "grad_norm": 1.7265570163726807,
      "learning_rate": 4.1769131950816666e-05,
      "loss": 0.1708,
      "step": 13440
    },
    {
      "epoch": 0.7986708597875749,
      "grad_norm": 1.9915562868118286,
      "learning_rate": 4.152443873493608e-05,
      "loss": 0.1632,
      "step": 13460
    },
    {
      "epoch": 0.7998575921200973,
      "grad_norm": 0.6382090449333191,
      "learning_rate": 4.127974551905548e-05,
      "loss": 0.1761,
      "step": 13480
    },
    {
      "epoch": 0.8010443244526197,
      "grad_norm": 1.372817873954773,
      "learning_rate": 4.1035052303174896e-05,
      "loss": 0.1681,
      "step": 13500
    },
    {
      "epoch": 0.8022310567851421,
      "grad_norm": 1.3219023942947388,
      "learning_rate": 4.0790359087294304e-05,
      "loss": 0.1653,
      "step": 13520
    },
    {
      "epoch": 0.8034177891176645,
      "grad_norm": 16.041549682617188,
      "learning_rate": 4.054566587141372e-05,
      "loss": 0.1534,
      "step": 13540
    },
    {
      "epoch": 0.8046045214501869,
      "grad_norm": 1.3739166259765625,
      "learning_rate": 4.0300972655533126e-05,
      "loss": 0.1537,
      "step": 13560
    },
    {
      "epoch": 0.8057912537827093,
      "grad_norm": 1.3272490501403809,
      "learning_rate": 4.005627943965254e-05,
      "loss": 0.1597,
      "step": 13580
    },
    {
      "epoch": 0.8069779861152317,
      "grad_norm": 0.7823688983917236,
      "learning_rate": 3.981158622377195e-05,
      "loss": 0.1637,
      "step": 13600
    },
    {
      "epoch": 0.8081647184477541,
      "grad_norm": 0.7562476396560669,
      "learning_rate": 3.956689300789136e-05,
      "loss": 1.0025,
      "step": 13620
    },
    {
      "epoch": 0.8093514507802765,
      "grad_norm": 1.994645118713379,
      "learning_rate": 3.932219979201077e-05,
      "loss": 0.1681,
      "step": 13640
    },
    {
      "epoch": 0.8105381831127989,
      "grad_norm": 0.7238506078720093,
      "learning_rate": 3.907750657613018e-05,
      "loss": 0.1531,
      "step": 13660
    },
    {
      "epoch": 0.8117249154453213,
      "grad_norm": 0.764473021030426,
      "learning_rate": 3.8832813360249585e-05,
      "loss": 0.1661,
      "step": 13680
    },
    {
      "epoch": 0.8129116477778437,
      "grad_norm": 1.1854170560836792,
      "learning_rate": 3.8588120144369e-05,
      "loss": 0.1599,
      "step": 13700
    },
    {
      "epoch": 0.8140983801103661,
      "grad_norm": 0.5896233916282654,
      "learning_rate": 3.8343426928488407e-05,
      "loss": 0.1589,
      "step": 13720
    },
    {
      "epoch": 0.8152851124428885,
      "grad_norm": 4.809620380401611,
      "learning_rate": 3.809873371260782e-05,
      "loss": 0.1822,
      "step": 13740
    },
    {
      "epoch": 0.8164718447754109,
      "grad_norm": 0.9621735215187073,
      "learning_rate": 3.785404049672723e-05,
      "loss": 0.1647,
      "step": 13760
    },
    {
      "epoch": 0.8176585771079333,
      "grad_norm": 7.982512474060059,
      "learning_rate": 3.760934728084664e-05,
      "loss": 0.1648,
      "step": 13780
    },
    {
      "epoch": 0.8188453094404557,
      "grad_norm": 0.7217305898666382,
      "learning_rate": 3.736465406496605e-05,
      "loss": 0.1649,
      "step": 13800
    },
    {
      "epoch": 0.8200320417729781,
      "grad_norm": 1.9774013757705688,
      "learning_rate": 3.711996084908546e-05,
      "loss": 0.5993,
      "step": 13820
    },
    {
      "epoch": 0.8212187741055005,
      "grad_norm": 0.9243814945220947,
      "learning_rate": 3.6875267633204866e-05,
      "loss": 0.1544,
      "step": 13840
    },
    {
      "epoch": 0.8224055064380229,
      "grad_norm": 2.017976999282837,
      "learning_rate": 3.663057441732428e-05,
      "loss": 0.162,
      "step": 13860
    },
    {
      "epoch": 0.8235922387705453,
      "grad_norm": 0.7774618864059448,
      "learning_rate": 3.638588120144369e-05,
      "loss": 0.1501,
      "step": 13880
    },
    {
      "epoch": 0.8247789711030677,
      "grad_norm": 3.493450403213501,
      "learning_rate": 3.61411879855631e-05,
      "loss": 0.1506,
      "step": 13900
    },
    {
      "epoch": 0.8259657034355901,
      "grad_norm": 1.9583934545516968,
      "learning_rate": 3.5896494769682516e-05,
      "loss": 0.1545,
      "step": 13920
    },
    {
      "epoch": 0.8271524357681125,
      "grad_norm": 2.044523239135742,
      "learning_rate": 3.5651801553801924e-05,
      "loss": 0.1603,
      "step": 13940
    },
    {
      "epoch": 0.8283391681006349,
      "grad_norm": 0.9959497451782227,
      "learning_rate": 3.540710833792134e-05,
      "loss": 0.1618,
      "step": 13960
    },
    {
      "epoch": 0.8295259004331573,
      "grad_norm": 0.8165716528892517,
      "learning_rate": 3.5162415122040746e-05,
      "loss": 0.1699,
      "step": 13980
    },
    {
      "epoch": 0.8307126327656797,
      "grad_norm": 1.4158421754837036,
      "learning_rate": 3.4917721906160154e-05,
      "loss": 0.1523,
      "step": 14000
    },
    {
      "epoch": 0.8318993650982021,
      "grad_norm": 1.0245150327682495,
      "learning_rate": 3.467302869027956e-05,
      "loss": 0.1703,
      "step": 14020
    },
    {
      "epoch": 0.8330860974307245,
      "grad_norm": 6.247068405151367,
      "learning_rate": 3.4428335474398975e-05,
      "loss": 0.1575,
      "step": 14040
    },
    {
      "epoch": 0.8342728297632469,
      "grad_norm": 0.8642973303794861,
      "learning_rate": 3.418364225851838e-05,
      "loss": 0.1721,
      "step": 14060
    },
    {
      "epoch": 0.8354595620957693,
      "grad_norm": 1.3068419694900513,
      "learning_rate": 3.39389490426378e-05,
      "loss": 0.1657,
      "step": 14080
    },
    {
      "epoch": 0.8366462944282917,
      "grad_norm": 4.6165313720703125,
      "learning_rate": 3.3694255826757205e-05,
      "loss": 0.1673,
      "step": 14100
    },
    {
      "epoch": 0.8378330267608141,
      "grad_norm": 1.7734923362731934,
      "learning_rate": 3.344956261087662e-05,
      "loss": 0.1755,
      "step": 14120
    },
    {
      "epoch": 0.8390197590933365,
      "grad_norm": 1.6991769075393677,
      "learning_rate": 3.320486939499603e-05,
      "loss": 0.1721,
      "step": 14140
    },
    {
      "epoch": 0.8402064914258589,
      "grad_norm": 4.0147247314453125,
      "learning_rate": 3.2960176179115435e-05,
      "loss": 0.176,
      "step": 14160
    },
    {
      "epoch": 0.8413932237583813,
      "grad_norm": 1.659390926361084,
      "learning_rate": 3.271548296323484e-05,
      "loss": 0.1544,
      "step": 14180
    },
    {
      "epoch": 0.8425799560909037,
      "grad_norm": 2.14632511138916,
      "learning_rate": 3.2470789747354257e-05,
      "loss": 0.1383,
      "step": 14200
    },
    {
      "epoch": 0.8437666884234261,
      "grad_norm": 0.8445238471031189,
      "learning_rate": 3.2226096531473664e-05,
      "loss": 0.1653,
      "step": 14220
    },
    {
      "epoch": 0.8449534207559485,
      "grad_norm": 0.6856650114059448,
      "learning_rate": 3.198140331559308e-05,
      "loss": 0.1735,
      "step": 14240
    },
    {
      "epoch": 0.8461401530884709,
      "grad_norm": 1.0493597984313965,
      "learning_rate": 3.1736710099712486e-05,
      "loss": 0.1503,
      "step": 14260
    },
    {
      "epoch": 0.8473268854209933,
      "grad_norm": 1.2181426286697388,
      "learning_rate": 3.14920168838319e-05,
      "loss": 0.1582,
      "step": 14280
    },
    {
      "epoch": 0.8485136177535157,
      "grad_norm": 0.9137839078903198,
      "learning_rate": 3.124732366795131e-05,
      "loss": 0.1642,
      "step": 14300
    },
    {
      "epoch": 0.8497003500860381,
      "grad_norm": 0.6899024248123169,
      "learning_rate": 3.1002630452070716e-05,
      "loss": 0.1638,
      "step": 14320
    },
    {
      "epoch": 0.8508870824185605,
      "grad_norm": 0.5380958914756775,
      "learning_rate": 3.075793723619012e-05,
      "loss": 0.1781,
      "step": 14340
    },
    {
      "epoch": 0.8520738147510829,
      "grad_norm": 0.8822303414344788,
      "learning_rate": 3.051324402030954e-05,
      "loss": 0.1762,
      "step": 14360
    },
    {
      "epoch": 0.8532605470836053,
      "grad_norm": 0.8611375093460083,
      "learning_rate": 3.0268550804428945e-05,
      "loss": 0.1586,
      "step": 14380
    },
    {
      "epoch": 0.8544472794161277,
      "grad_norm": 0.6713533997535706,
      "learning_rate": 3.002385758854836e-05,
      "loss": 0.1602,
      "step": 14400
    },
    {
      "epoch": 0.8556340117486501,
      "grad_norm": 1.4206275939941406,
      "learning_rate": 2.9779164372667767e-05,
      "loss": 0.1651,
      "step": 14420
    },
    {
      "epoch": 0.8568207440811725,
      "grad_norm": 0.7707566618919373,
      "learning_rate": 2.953447115678718e-05,
      "loss": 0.165,
      "step": 14440
    },
    {
      "epoch": 0.8580074764136949,
      "grad_norm": 1.2299964427947998,
      "learning_rate": 2.928977794090659e-05,
      "loss": 0.1539,
      "step": 14460
    },
    {
      "epoch": 0.8591942087462173,
      "grad_norm": 1.3928683996200562,
      "learning_rate": 2.9045084725026e-05,
      "loss": 0.1668,
      "step": 14480
    },
    {
      "epoch": 0.8603809410787396,
      "grad_norm": 1.2690160274505615,
      "learning_rate": 2.8800391509145408e-05,
      "loss": 0.1677,
      "step": 14500
    },
    {
      "epoch": 0.8615676734112621,
      "grad_norm": 1.2586358785629272,
      "learning_rate": 2.8555698293264822e-05,
      "loss": 0.1776,
      "step": 14520
    },
    {
      "epoch": 0.8627544057437845,
      "grad_norm": 1.867425799369812,
      "learning_rate": 2.831100507738423e-05,
      "loss": 0.1496,
      "step": 14540
    },
    {
      "epoch": 0.8639411380763069,
      "grad_norm": 1.6336355209350586,
      "learning_rate": 2.806631186150364e-05,
      "loss": 0.1639,
      "step": 14560
    },
    {
      "epoch": 0.8651278704088293,
      "grad_norm": 0.737062931060791,
      "learning_rate": 2.7821618645623048e-05,
      "loss": 0.1689,
      "step": 14580
    },
    {
      "epoch": 0.8663146027413516,
      "grad_norm": 0.784083366394043,
      "learning_rate": 2.7576925429742462e-05,
      "loss": 0.1672,
      "step": 14600
    },
    {
      "epoch": 0.8675013350738741,
      "grad_norm": 1.484694004058838,
      "learning_rate": 2.7332232213861873e-05,
      "loss": 0.1542,
      "step": 14620
    },
    {
      "epoch": 0.8686880674063965,
      "grad_norm": 0.9976987838745117,
      "learning_rate": 2.708753899798128e-05,
      "loss": 0.1774,
      "step": 14640
    },
    {
      "epoch": 0.8698747997389189,
      "grad_norm": 0.9970031380653381,
      "learning_rate": 2.6842845782100695e-05,
      "loss": 0.1584,
      "step": 14660
    },
    {
      "epoch": 0.8710615320714413,
      "grad_norm": 2.835603952407837,
      "learning_rate": 2.6598152566220103e-05,
      "loss": 0.1608,
      "step": 14680
    },
    {
      "epoch": 0.8722482644039636,
      "grad_norm": 0.9447303414344788,
      "learning_rate": 2.6353459350339514e-05,
      "loss": 0.168,
      "step": 14700
    },
    {
      "epoch": 0.8734349967364861,
      "grad_norm": 0.6063681244850159,
      "learning_rate": 2.610876613445892e-05,
      "loss": 0.1532,
      "step": 14720
    },
    {
      "epoch": 0.8746217290690085,
      "grad_norm": 0.680978536605835,
      "learning_rate": 2.5864072918578336e-05,
      "loss": 0.1439,
      "step": 14740
    },
    {
      "epoch": 0.8758084614015309,
      "grad_norm": 1.58243989944458,
      "learning_rate": 2.5619379702697744e-05,
      "loss": 0.17,
      "step": 14760
    },
    {
      "epoch": 0.8769951937340533,
      "grad_norm": 1.0812537670135498,
      "learning_rate": 2.5374686486817158e-05,
      "loss": 0.1599,
      "step": 14780
    },
    {
      "epoch": 0.8781819260665756,
      "grad_norm": 1.4456377029418945,
      "learning_rate": 2.5129993270936562e-05,
      "loss": 0.1525,
      "step": 14800
    },
    {
      "epoch": 0.8793686583990981,
      "grad_norm": 1.4342262744903564,
      "learning_rate": 2.4885300055055973e-05,
      "loss": 0.1686,
      "step": 14820
    },
    {
      "epoch": 0.8805553907316205,
      "grad_norm": 0.7773745059967041,
      "learning_rate": 2.4640606839175384e-05,
      "loss": 0.1787,
      "step": 14840
    },
    {
      "epoch": 0.8817421230641429,
      "grad_norm": 1.3361079692840576,
      "learning_rate": 2.4395913623294795e-05,
      "loss": 0.1607,
      "step": 14860
    },
    {
      "epoch": 0.8829288553966653,
      "grad_norm": 0.5709905624389648,
      "learning_rate": 2.4151220407414206e-05,
      "loss": 0.1552,
      "step": 14880
    },
    {
      "epoch": 0.8841155877291876,
      "grad_norm": 1.5336130857467651,
      "learning_rate": 2.3906527191533614e-05,
      "loss": 0.1673,
      "step": 14900
    },
    {
      "epoch": 0.8853023200617101,
      "grad_norm": 0.85747891664505,
      "learning_rate": 2.3661833975653025e-05,
      "loss": 0.1425,
      "step": 14920
    },
    {
      "epoch": 0.8864890523942325,
      "grad_norm": 0.8676576018333435,
      "learning_rate": 2.3417140759772436e-05,
      "loss": 0.1661,
      "step": 14940
    },
    {
      "epoch": 0.8876757847267549,
      "grad_norm": 0.7159193754196167,
      "learning_rate": 2.3172447543891847e-05,
      "loss": 0.162,
      "step": 14960
    },
    {
      "epoch": 0.8888625170592773,
      "grad_norm": 1.0796159505844116,
      "learning_rate": 2.2927754328011258e-05,
      "loss": 0.1627,
      "step": 14980
    },
    {
      "epoch": 0.8900492493917996,
      "grad_norm": 0.9965197443962097,
      "learning_rate": 2.268306111213067e-05,
      "loss": 0.1582,
      "step": 15000
    },
    {
      "epoch": 0.8912359817243221,
      "grad_norm": 0.9632115364074707,
      "learning_rate": 2.243836789625008e-05,
      "loss": 0.1882,
      "step": 15020
    },
    {
      "epoch": 0.8924227140568445,
      "grad_norm": 1.74781334400177,
      "learning_rate": 2.219367468036949e-05,
      "loss": 0.1689,
      "step": 15040
    },
    {
      "epoch": 0.8936094463893669,
      "grad_norm": 0.9342125654220581,
      "learning_rate": 2.1948981464488898e-05,
      "loss": 0.1618,
      "step": 15060
    },
    {
      "epoch": 0.8947961787218893,
      "grad_norm": 0.748683750629425,
      "learning_rate": 2.170428824860831e-05,
      "loss": 0.1643,
      "step": 15080
    },
    {
      "epoch": 0.8959829110544116,
      "grad_norm": 0.9059740900993347,
      "learning_rate": 2.145959503272772e-05,
      "loss": 0.1538,
      "step": 15100
    },
    {
      "epoch": 0.8971696433869341,
      "grad_norm": 1.18144953250885,
      "learning_rate": 2.121490181684713e-05,
      "loss": 0.1443,
      "step": 15120
    },
    {
      "epoch": 0.8983563757194565,
      "grad_norm": 1.3917790651321411,
      "learning_rate": 2.097020860096654e-05,
      "loss": 0.1788,
      "step": 15140
    },
    {
      "epoch": 0.8995431080519789,
      "grad_norm": 0.7371928095817566,
      "learning_rate": 2.072551538508595e-05,
      "loss": 0.1702,
      "step": 15160
    },
    {
      "epoch": 0.9007298403845013,
      "grad_norm": 0.8071612119674683,
      "learning_rate": 2.048082216920536e-05,
      "loss": 0.1629,
      "step": 15180
    },
    {
      "epoch": 0.9019165727170236,
      "grad_norm": 0.8351633548736572,
      "learning_rate": 2.023612895332477e-05,
      "loss": 0.1483,
      "step": 15200
    },
    {
      "epoch": 0.9031033050495461,
      "grad_norm": 0.6077930927276611,
      "learning_rate": 1.999143573744418e-05,
      "loss": 0.1654,
      "step": 15220
    },
    {
      "epoch": 0.9042900373820685,
      "grad_norm": 0.9785411357879639,
      "learning_rate": 1.974674252156359e-05,
      "loss": 0.1533,
      "step": 15240
    },
    {
      "epoch": 0.9054767697145909,
      "grad_norm": 2.42098331451416,
      "learning_rate": 1.9502049305683e-05,
      "loss": 0.1642,
      "step": 15260
    },
    {
      "epoch": 0.9066635020471133,
      "grad_norm": 0.6920753121376038,
      "learning_rate": 1.9257356089802412e-05,
      "loss": 0.1547,
      "step": 15280
    },
    {
      "epoch": 0.9078502343796356,
      "grad_norm": 0.7097877860069275,
      "learning_rate": 1.9012662873921823e-05,
      "loss": 0.1531,
      "step": 15300
    },
    {
      "epoch": 0.9090369667121581,
      "grad_norm": 1.0595721006393433,
      "learning_rate": 1.876796965804123e-05,
      "loss": 0.1495,
      "step": 15320
    },
    {
      "epoch": 0.9102236990446805,
      "grad_norm": 1.1978870630264282,
      "learning_rate": 1.852327644216064e-05,
      "loss": 0.1676,
      "step": 15340
    },
    {
      "epoch": 0.9114104313772029,
      "grad_norm": 0.7912290096282959,
      "learning_rate": 1.8278583226280053e-05,
      "loss": 0.176,
      "step": 15360
    },
    {
      "epoch": 0.9125971637097253,
      "grad_norm": 0.6220386624336243,
      "learning_rate": 1.8033890010399464e-05,
      "loss": 0.1641,
      "step": 15380
    },
    {
      "epoch": 0.9137838960422476,
      "grad_norm": 1.1544493436813354,
      "learning_rate": 1.778919679451887e-05,
      "loss": 0.1736,
      "step": 15400
    },
    {
      "epoch": 0.9149706283747701,
      "grad_norm": 1.1443517208099365,
      "learning_rate": 1.7544503578638282e-05,
      "loss": 0.1439,
      "step": 15420
    },
    {
      "epoch": 0.9161573607072925,
      "grad_norm": 1.0551234483718872,
      "learning_rate": 1.7299810362757693e-05,
      "loss": 0.152,
      "step": 15440
    },
    {
      "epoch": 0.9173440930398149,
      "grad_norm": 1.015771508216858,
      "learning_rate": 1.7055117146877104e-05,
      "loss": 0.1622,
      "step": 15460
    },
    {
      "epoch": 0.9185308253723373,
      "grad_norm": 0.5987315773963928,
      "learning_rate": 1.6810423930996515e-05,
      "loss": 0.1604,
      "step": 15480
    },
    {
      "epoch": 0.9197175577048596,
      "grad_norm": 0.7189347147941589,
      "learning_rate": 1.6565730715115923e-05,
      "loss": 0.1586,
      "step": 15500
    },
    {
      "epoch": 0.9209042900373821,
      "grad_norm": 2.2277722358703613,
      "learning_rate": 1.6321037499235334e-05,
      "loss": 0.1497,
      "step": 15520
    },
    {
      "epoch": 0.9220910223699045,
      "grad_norm": 2.799410820007324,
      "learning_rate": 1.6076344283354745e-05,
      "loss": 0.1976,
      "step": 15540
    },
    {
      "epoch": 0.9232777547024269,
      "grad_norm": 0.6462675929069519,
      "learning_rate": 1.5831651067474156e-05,
      "loss": 0.1779,
      "step": 15560
    },
    {
      "epoch": 0.9244644870349493,
      "grad_norm": 0.9096196889877319,
      "learning_rate": 1.5586957851593563e-05,
      "loss": 0.1605,
      "step": 15580
    },
    {
      "epoch": 0.9256512193674716,
      "grad_norm": 1.154602289199829,
      "learning_rate": 1.5342264635712974e-05,
      "loss": 0.1578,
      "step": 15600
    },
    {
      "epoch": 0.9268379516999941,
      "grad_norm": 0.9969849586486816,
      "learning_rate": 1.5097571419832385e-05,
      "loss": 0.157,
      "step": 15620
    },
    {
      "epoch": 0.9280246840325165,
      "grad_norm": 1.1603344678878784,
      "learning_rate": 1.4852878203951794e-05,
      "loss": 0.1531,
      "step": 15640
    },
    {
      "epoch": 0.9292114163650389,
      "grad_norm": 0.845156192779541,
      "learning_rate": 1.4608184988071205e-05,
      "loss": 0.149,
      "step": 15660
    },
    {
      "epoch": 0.9303981486975612,
      "grad_norm": 1.1364569664001465,
      "learning_rate": 1.4363491772190615e-05,
      "loss": 0.1478,
      "step": 15680
    },
    {
      "epoch": 0.9315848810300836,
      "grad_norm": 1.0665384531021118,
      "learning_rate": 1.4118798556310029e-05,
      "loss": 0.1528,
      "step": 15700
    },
    {
      "epoch": 0.9327716133626061,
      "grad_norm": 0.8249064087867737,
      "learning_rate": 1.3874105340429438e-05,
      "loss": 0.1653,
      "step": 15720
    },
    {
      "epoch": 0.9339583456951285,
      "grad_norm": 0.9935134053230286,
      "learning_rate": 1.362941212454885e-05,
      "loss": 0.1619,
      "step": 15740
    },
    {
      "epoch": 0.9351450780276509,
      "grad_norm": 0.8924272060394287,
      "learning_rate": 1.3384718908668259e-05,
      "loss": 0.1603,
      "step": 15760
    },
    {
      "epoch": 0.9363318103601732,
      "grad_norm": 1.1407134532928467,
      "learning_rate": 1.314002569278767e-05,
      "loss": 0.1485,
      "step": 15780
    },
    {
      "epoch": 0.9375185426926956,
      "grad_norm": 1.891552448272705,
      "learning_rate": 1.2895332476907079e-05,
      "loss": 0.1707,
      "step": 15800
    },
    {
      "epoch": 0.9387052750252181,
      "grad_norm": 1.1200636625289917,
      "learning_rate": 1.265063926102649e-05,
      "loss": 0.1672,
      "step": 15820
    },
    {
      "epoch": 0.9398920073577405,
      "grad_norm": 0.9126407504081726,
      "learning_rate": 1.2405946045145899e-05,
      "loss": 0.1678,
      "step": 15840
    },
    {
      "epoch": 0.9410787396902629,
      "grad_norm": 0.8626967668533325,
      "learning_rate": 1.2161252829265308e-05,
      "loss": 0.1565,
      "step": 15860
    },
    {
      "epoch": 0.9422654720227852,
      "grad_norm": 0.7722967863082886,
      "learning_rate": 1.1916559613384721e-05,
      "loss": 0.1609,
      "step": 15880
    },
    {
      "epoch": 0.9434522043553076,
      "grad_norm": 1.3127286434173584,
      "learning_rate": 1.167186639750413e-05,
      "loss": 0.1474,
      "step": 15900
    },
    {
      "epoch": 0.94463893668783,
      "grad_norm": 1.3480408191680908,
      "learning_rate": 1.1427173181623541e-05,
      "loss": 0.1535,
      "step": 15920
    },
    {
      "epoch": 0.9458256690203525,
      "grad_norm": 0.9530019164085388,
      "learning_rate": 1.118247996574295e-05,
      "loss": 0.1643,
      "step": 15940
    },
    {
      "epoch": 0.9470124013528749,
      "grad_norm": 2.987548828125,
      "learning_rate": 1.0937786749862362e-05,
      "loss": 0.1658,
      "step": 15960
    },
    {
      "epoch": 0.9481991336853972,
      "grad_norm": 1.3987479209899902,
      "learning_rate": 1.069309353398177e-05,
      "loss": 0.1682,
      "step": 15980
    },
    {
      "epoch": 0.9493858660179196,
      "grad_norm": 0.9197956323623657,
      "learning_rate": 1.0448400318101182e-05,
      "loss": 0.1603,
      "step": 16000
    },
    {
      "epoch": 0.9493858660179196,
      "eval_f1_macro": 0.4867353902717846,
      "eval_f1_micro": 0.5515527950310559,
      "eval_hamming_loss": 0.1444,
      "eval_loss": 0.1691565364599228,
      "eval_runtime": 4860.0634,
      "eval_samples_per_second": 1.029,
      "eval_steps_per_second": 0.257,
      "eval_subset_accuracy": 0.4304,
      "step": 16000
    },
    {
      "epoch": 0.950572598350442,
      "grad_norm": 0.6365761756896973,
      "learning_rate": 1.0203707102220591e-05,
      "loss": 0.1587,
      "step": 16020
    },
    {
      "epoch": 0.9517593306829645,
      "grad_norm": 1.8893247842788696,
      "learning_rate": 9.959013886340002e-06,
      "loss": 0.1679,
      "step": 16040
    },
    {
      "epoch": 0.9529460630154869,
      "grad_norm": 0.9237708449363708,
      "learning_rate": 9.714320670459411e-06,
      "loss": 0.1623,
      "step": 16060
    },
    {
      "epoch": 0.9541327953480092,
      "grad_norm": 0.4053841829299927,
      "learning_rate": 9.469627454578822e-06,
      "loss": 0.1548,
      "step": 16080
    },
    {
      "epoch": 0.9553195276805316,
      "grad_norm": 1.0254708528518677,
      "learning_rate": 9.224934238698232e-06,
      "loss": 0.1639,
      "step": 16100
    },
    {
      "epoch": 0.956506260013054,
      "grad_norm": 0.5843693017959595,
      "learning_rate": 8.980241022817643e-06,
      "loss": 0.1587,
      "step": 16120
    },
    {
      "epoch": 0.9576929923455765,
      "grad_norm": 1.1783173084259033,
      "learning_rate": 8.735547806937054e-06,
      "loss": 0.1544,
      "step": 16140
    },
    {
      "epoch": 0.9588797246780989,
      "grad_norm": 1.032839059829712,
      "learning_rate": 8.490854591056463e-06,
      "loss": 0.1561,
      "step": 16160
    },
    {
      "epoch": 0.9600664570106212,
      "grad_norm": 0.8537080883979797,
      "learning_rate": 8.246161375175874e-06,
      "loss": 0.1664,
      "step": 16180
    },
    {
      "epoch": 0.9612531893431436,
      "grad_norm": 0.6428044438362122,
      "learning_rate": 8.001468159295283e-06,
      "loss": 0.1606,
      "step": 16200
    },
    {
      "epoch": 0.962439921675666,
      "grad_norm": 1.4927047491073608,
      "learning_rate": 7.756774943414694e-06,
      "loss": 0.1647,
      "step": 16220
    },
    {
      "epoch": 0.9636266540081885,
      "grad_norm": 1.0926580429077148,
      "learning_rate": 7.512081727534105e-06,
      "loss": 0.1666,
      "step": 16240
    },
    {
      "epoch": 0.9648133863407109,
      "grad_norm": 0.5307455658912659,
      "learning_rate": 7.267388511653515e-06,
      "loss": 0.1663,
      "step": 16260
    },
    {
      "epoch": 0.9660001186732332,
      "grad_norm": 0.8175646662712097,
      "learning_rate": 7.022695295772925e-06,
      "loss": 0.1746,
      "step": 16280
    },
    {
      "epoch": 0.9671868510057556,
      "grad_norm": 0.9222429990768433,
      "learning_rate": 6.778002079892335e-06,
      "loss": 0.1509,
      "step": 16300
    },
    {
      "epoch": 0.968373583338278,
      "grad_norm": 0.8569130897521973,
      "learning_rate": 6.5333088640117455e-06,
      "loss": 0.1532,
      "step": 16320
    },
    {
      "epoch": 0.9695603156708005,
      "grad_norm": 1.1873600482940674,
      "learning_rate": 6.2886156481311565e-06,
      "loss": 0.1733,
      "step": 16340
    },
    {
      "epoch": 0.9707470480033229,
      "grad_norm": 0.7996689677238464,
      "learning_rate": 6.043922432250567e-06,
      "loss": 0.1729,
      "step": 16360
    },
    {
      "epoch": 0.9719337803358452,
      "grad_norm": 1.0744088888168335,
      "learning_rate": 5.799229216369977e-06,
      "loss": 0.1578,
      "step": 16380
    },
    {
      "epoch": 0.9731205126683676,
      "grad_norm": 0.9427491426467896,
      "learning_rate": 5.554536000489387e-06,
      "loss": 0.1717,
      "step": 16400
    },
    {
      "epoch": 0.97430724500089,
      "grad_norm": 0.7725194096565247,
      "learning_rate": 5.309842784608797e-06,
      "loss": 0.1666,
      "step": 16420
    },
    {
      "epoch": 0.9754939773334125,
      "grad_norm": 0.9130957722663879,
      "learning_rate": 5.065149568728207e-06,
      "loss": 0.1561,
      "step": 16440
    },
    {
      "epoch": 0.9766807096659349,
      "grad_norm": 1.191407322883606,
      "learning_rate": 4.820456352847617e-06,
      "loss": 0.1747,
      "step": 16460
    },
    {
      "epoch": 0.9778674419984572,
      "grad_norm": 0.9419370889663696,
      "learning_rate": 4.5757631369670274e-06,
      "loss": 0.1414,
      "step": 16480
    },
    {
      "epoch": 0.9790541743309796,
      "grad_norm": 0.5485596656799316,
      "learning_rate": 4.3310699210864376e-06,
      "loss": 0.1639,
      "step": 16500
    },
    {
      "epoch": 0.980240906663502,
      "grad_norm": 0.9538251161575317,
      "learning_rate": 4.0863767052058485e-06,
      "loss": 0.1652,
      "step": 16520
    },
    {
      "epoch": 0.9814276389960245,
      "grad_norm": 0.5536516308784485,
      "learning_rate": 3.841683489325259e-06,
      "loss": 0.1603,
      "step": 16540
    },
    {
      "epoch": 0.9826143713285469,
      "grad_norm": 1.2896510362625122,
      "learning_rate": 3.5969902734446692e-06,
      "loss": 0.16,
      "step": 16560
    },
    {
      "epoch": 0.9838011036610692,
      "grad_norm": 1.1152864694595337,
      "learning_rate": 3.3522970575640794e-06,
      "loss": 0.1619,
      "step": 16580
    },
    {
      "epoch": 0.9849878359935916,
      "grad_norm": 1.8388656377792358,
      "learning_rate": 3.1076038416834895e-06,
      "loss": 0.1635,
      "step": 16600
    },
    {
      "epoch": 0.986174568326114,
      "grad_norm": 0.48479411005973816,
      "learning_rate": 2.8629106258028996e-06,
      "loss": 0.1508,
      "step": 16620
    },
    {
      "epoch": 0.9873613006586365,
      "grad_norm": 0.5145269632339478,
      "learning_rate": 2.6182174099223097e-06,
      "loss": 0.1579,
      "step": 16640
    },
    {
      "epoch": 0.9885480329911589,
      "grad_norm": 0.7910157442092896,
      "learning_rate": 2.3735241940417203e-06,
      "loss": 0.1534,
      "step": 16660
    },
    {
      "epoch": 0.9897347653236812,
      "grad_norm": 0.7174213528633118,
      "learning_rate": 2.1288309781611304e-06,
      "loss": 0.1529,
      "step": 16680
    },
    {
      "epoch": 0.9909214976562036,
      "grad_norm": 1.0991672277450562,
      "learning_rate": 1.8841377622805408e-06,
      "loss": 0.1556,
      "step": 16700
    },
    {
      "epoch": 0.992108229988726,
      "grad_norm": 0.9506292939186096,
      "learning_rate": 1.6394445463999511e-06,
      "loss": 0.1708,
      "step": 16720
    },
    {
      "epoch": 0.9932949623212485,
      "grad_norm": 0.6910584568977356,
      "learning_rate": 1.3947513305193615e-06,
      "loss": 0.1711,
      "step": 16740
    },
    {
      "epoch": 0.9944816946537708,
      "grad_norm": 1.054434061050415,
      "learning_rate": 1.1500581146387718e-06,
      "loss": 0.1898,
      "step": 16760
    },
    {
      "epoch": 0.9956684269862932,
      "grad_norm": 0.902158796787262,
      "learning_rate": 9.053648987581819e-07,
      "loss": 0.154,
      "step": 16780
    },
    {
      "epoch": 0.9968551593188156,
      "grad_norm": 1.566796064376831,
      "learning_rate": 6.606716828775923e-07,
      "loss": 0.1717,
      "step": 16800
    },
    {
      "epoch": 0.998041891651338,
      "grad_norm": 0.9398159384727478,
      "learning_rate": 4.1597846699700256e-07,
      "loss": 0.1675,
      "step": 16820
    },
    {
      "epoch": 0.9992286239838605,
      "grad_norm": 1.2990914583206177,
      "learning_rate": 1.712852511164128e-07,
      "loss": 0.167,
      "step": 16840
    }
  ],
  "logging_steps": 20,
  "max_steps": 16853,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 8000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.998310470171515e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
