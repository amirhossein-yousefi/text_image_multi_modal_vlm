# Core ML/DL
torch>=2.0.0
torchvision>=0.15.0

# Transformers & PEFT
transformers>=4.36.0
peft>=0.7.0
accelerate>=0.25.0

# Quantization (QLoRA)
bitsandbytes>=0.41.0

# Data processing
pandas>=2.0.0
numpy>=1.24.0
pillow>=10.0.0

# Evaluation
scikit-learn>=1.3.0

# Logging & Visualization
tensorboard>=2.14.0
tqdm>=4.66.0

# Data download helpers (used by scripts/prepare_data.py)
# Keep in sync with transformers' requirements (prevents import-time version check failures).
huggingface_hub>=0.34.0,<1.0
gdown>=5.2.0

# Optional: vLLM for inference serving
# vllm>=0.2.0

# Optional: Flash Attention 2
# flash-attn>=2.3.0

# Optional: AWS SageMaker SDK (launch training jobs + deploy endpoints)
# sagemaker>=2.200.0
# boto3>=1.28.0
