{
  "best_global_step": 8000,
  "best_metric": 0.5076618154656621,
  "best_model_checkpoint": "runs/qwen2vl_lora\\checkpoint-8000",
  "epoch": 0.4746929330089598,
  "eval_steps": 8000,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0011867323325223996,
      "grad_norm": 16.058977127075195,
      "learning_rate": 7.509881422924901e-06,
      "loss": 1.0387,
      "step": 20
    },
    {
      "epoch": 0.0023734646650447992,
      "grad_norm": 3.338996648788452,
      "learning_rate": 1.541501976284585e-05,
      "loss": 0.2969,
      "step": 40
    },
    {
      "epoch": 0.003560196997567199,
      "grad_norm": 1.3963139057159424,
      "learning_rate": 2.33201581027668e-05,
      "loss": 0.204,
      "step": 60
    },
    {
      "epoch": 0.0047469293300895984,
      "grad_norm": 2.1808836460113525,
      "learning_rate": 3.1225296442687746e-05,
      "loss": 0.1983,
      "step": 80
    },
    {
      "epoch": 0.005933661662611998,
      "grad_norm": 1.7146931886672974,
      "learning_rate": 3.91304347826087e-05,
      "loss": 0.2173,
      "step": 100
    },
    {
      "epoch": 0.007120393995134398,
      "grad_norm": 2.4646217823028564,
      "learning_rate": 4.7035573122529645e-05,
      "loss": 0.2057,
      "step": 120
    },
    {
      "epoch": 0.008307126327656797,
      "grad_norm": 3.84330677986145,
      "learning_rate": 5.49407114624506e-05,
      "loss": 0.1816,
      "step": 140
    },
    {
      "epoch": 0.009493858660179197,
      "grad_norm": 3.1994810104370117,
      "learning_rate": 6.284584980237155e-05,
      "loss": 0.1888,
      "step": 160
    },
    {
      "epoch": 0.010680590992701596,
      "grad_norm": 1.7622168064117432,
      "learning_rate": 7.075098814229249e-05,
      "loss": 0.2153,
      "step": 180
    },
    {
      "epoch": 0.011867323325223996,
      "grad_norm": 1.826794147491455,
      "learning_rate": 7.865612648221344e-05,
      "loss": 0.199,
      "step": 200
    },
    {
      "epoch": 0.013054055657746396,
      "grad_norm": 1.4592976570129395,
      "learning_rate": 8.65612648221344e-05,
      "loss": 0.1932,
      "step": 220
    },
    {
      "epoch": 0.014240787990268795,
      "grad_norm": 1.7129484415054321,
      "learning_rate": 9.446640316205534e-05,
      "loss": 0.194,
      "step": 240
    },
    {
      "epoch": 0.015427520322791195,
      "grad_norm": 1.2574540376663208,
      "learning_rate": 0.0001023715415019763,
      "loss": 0.1964,
      "step": 260
    },
    {
      "epoch": 0.016614252655313595,
      "grad_norm": 1.1025922298431396,
      "learning_rate": 0.00011027667984189724,
      "loss": 0.2198,
      "step": 280
    },
    {
      "epoch": 0.017800984987835992,
      "grad_norm": 1.7750619649887085,
      "learning_rate": 0.0001181818181818182,
      "loss": 0.1846,
      "step": 300
    },
    {
      "epoch": 0.018987717320358394,
      "grad_norm": 2.868051767349243,
      "learning_rate": 0.00012608695652173915,
      "loss": 0.1973,
      "step": 320
    },
    {
      "epoch": 0.02017444965288079,
      "grad_norm": 2.3595893383026123,
      "learning_rate": 0.0001339920948616601,
      "loss": 0.2145,
      "step": 340
    },
    {
      "epoch": 0.021361181985403193,
      "grad_norm": 1.1372511386871338,
      "learning_rate": 0.00014189723320158103,
      "loss": 0.2057,
      "step": 360
    },
    {
      "epoch": 0.02254791431792559,
      "grad_norm": 1.2041963338851929,
      "learning_rate": 0.00014980237154150198,
      "loss": 0.2178,
      "step": 380
    },
    {
      "epoch": 0.023734646650447992,
      "grad_norm": 1.4164191484451294,
      "learning_rate": 0.00015770750988142293,
      "loss": 0.199,
      "step": 400
    },
    {
      "epoch": 0.02492137898297039,
      "grad_norm": 1.6751861572265625,
      "learning_rate": 0.00016561264822134388,
      "loss": 0.1895,
      "step": 420
    },
    {
      "epoch": 0.02610811131549279,
      "grad_norm": 0.9750273823738098,
      "learning_rate": 0.00017351778656126484,
      "loss": 0.2022,
      "step": 440
    },
    {
      "epoch": 0.02729484364801519,
      "grad_norm": 0.9211957454681396,
      "learning_rate": 0.00018142292490118576,
      "loss": 0.1938,
      "step": 460
    },
    {
      "epoch": 0.02848157598053759,
      "grad_norm": 2.0753254890441895,
      "learning_rate": 0.00018932806324110672,
      "loss": 0.2231,
      "step": 480
    },
    {
      "epoch": 0.02966830831305999,
      "grad_norm": 0.5854642987251282,
      "learning_rate": 0.00019723320158102767,
      "loss": 0.2142,
      "step": 500
    },
    {
      "epoch": 0.03085504064558239,
      "grad_norm": 1.4102602005004883,
      "learning_rate": 0.00019984094940967762,
      "loss": 0.1912,
      "step": 520
    },
    {
      "epoch": 0.03204177297810479,
      "grad_norm": 1.4193586111068726,
      "learning_rate": 0.00019959625619379702,
      "loss": 0.2024,
      "step": 540
    },
    {
      "epoch": 0.03322850531062719,
      "grad_norm": 0.5126264095306396,
      "learning_rate": 0.00019935156297791644,
      "loss": 0.1806,
      "step": 560
    },
    {
      "epoch": 0.03441523764314959,
      "grad_norm": 1.0130695104599,
      "learning_rate": 0.00019910686976203586,
      "loss": 0.2038,
      "step": 580
    },
    {
      "epoch": 0.035601969975671985,
      "grad_norm": 1.4461658000946045,
      "learning_rate": 0.00019886217654615525,
      "loss": 0.1836,
      "step": 600
    },
    {
      "epoch": 0.036788702308194386,
      "grad_norm": 0.7882236242294312,
      "learning_rate": 0.00019861748333027467,
      "loss": 0.1725,
      "step": 620
    },
    {
      "epoch": 0.03797543464071679,
      "grad_norm": 0.9355607628822327,
      "learning_rate": 0.0001983727901143941,
      "loss": 0.2008,
      "step": 640
    },
    {
      "epoch": 0.03916216697323919,
      "grad_norm": 0.725584864616394,
      "learning_rate": 0.00019812809689851352,
      "loss": 0.1828,
      "step": 660
    },
    {
      "epoch": 0.04034889930576158,
      "grad_norm": 0.6243165135383606,
      "learning_rate": 0.0001978834036826329,
      "loss": 0.1859,
      "step": 680
    },
    {
      "epoch": 0.041535631638283985,
      "grad_norm": 1.5250613689422607,
      "learning_rate": 0.0001976387104667523,
      "loss": 0.2031,
      "step": 700
    },
    {
      "epoch": 0.042722363970806386,
      "grad_norm": 0.5795774459838867,
      "learning_rate": 0.00019739401725087173,
      "loss": 0.1653,
      "step": 720
    },
    {
      "epoch": 0.04390909630332879,
      "grad_norm": 0.9088283777236938,
      "learning_rate": 0.00019714932403499115,
      "loss": 0.181,
      "step": 740
    },
    {
      "epoch": 0.04509582863585118,
      "grad_norm": 1.0226508378982544,
      "learning_rate": 0.00019690463081911054,
      "loss": 0.2002,
      "step": 760
    },
    {
      "epoch": 0.04628256096837358,
      "grad_norm": 1.668888807296753,
      "learning_rate": 0.00019665993760322996,
      "loss": 0.1855,
      "step": 780
    },
    {
      "epoch": 0.047469293300895984,
      "grad_norm": 0.7595623135566711,
      "learning_rate": 0.00019641524438734938,
      "loss": 0.1957,
      "step": 800
    },
    {
      "epoch": 0.048656025633418386,
      "grad_norm": 0.9116789102554321,
      "learning_rate": 0.00019617055117146878,
      "loss": 0.204,
      "step": 820
    },
    {
      "epoch": 0.04984275796594078,
      "grad_norm": 1.3977446556091309,
      "learning_rate": 0.0001959258579555882,
      "loss": 0.1719,
      "step": 840
    },
    {
      "epoch": 0.05102949029846318,
      "grad_norm": 0.8237901926040649,
      "learning_rate": 0.00019568116473970762,
      "loss": 0.1888,
      "step": 860
    },
    {
      "epoch": 0.05221622263098558,
      "grad_norm": 0.5934572815895081,
      "learning_rate": 0.000195436471523827,
      "loss": 0.1743,
      "step": 880
    },
    {
      "epoch": 0.053402954963507984,
      "grad_norm": 0.6059253811836243,
      "learning_rate": 0.0001951917783079464,
      "loss": 0.1773,
      "step": 900
    },
    {
      "epoch": 0.05458968729603038,
      "grad_norm": 1.4160877466201782,
      "learning_rate": 0.00019494708509206583,
      "loss": 0.1744,
      "step": 920
    },
    {
      "epoch": 0.05577641962855278,
      "grad_norm": 0.5923179388046265,
      "learning_rate": 0.00019470239187618525,
      "loss": 0.1929,
      "step": 940
    },
    {
      "epoch": 0.05696315196107518,
      "grad_norm": 0.9830272197723389,
      "learning_rate": 0.00019445769866030464,
      "loss": 0.1737,
      "step": 960
    },
    {
      "epoch": 0.058149884293597576,
      "grad_norm": 0.758945882320404,
      "learning_rate": 0.00019421300544442406,
      "loss": 0.2056,
      "step": 980
    },
    {
      "epoch": 0.05933661662611998,
      "grad_norm": 1.1990796327590942,
      "learning_rate": 0.00019396831222854349,
      "loss": 0.1612,
      "step": 1000
    },
    {
      "epoch": 0.06052334895864238,
      "grad_norm": 0.9584963321685791,
      "learning_rate": 0.0001937236190126629,
      "loss": 0.1779,
      "step": 1020
    },
    {
      "epoch": 0.06171008129116478,
      "grad_norm": 1.80588698387146,
      "learning_rate": 0.00019347892579678227,
      "loss": 0.1805,
      "step": 1040
    },
    {
      "epoch": 0.06289681362368718,
      "grad_norm": 0.6639304757118225,
      "learning_rate": 0.0001932342325809017,
      "loss": 0.1635,
      "step": 1060
    },
    {
      "epoch": 0.06408354595620958,
      "grad_norm": 0.7055984139442444,
      "learning_rate": 0.00019298953936502112,
      "loss": 0.1655,
      "step": 1080
    },
    {
      "epoch": 0.06527027828873197,
      "grad_norm": 2.0254199504852295,
      "learning_rate": 0.0001927448461491405,
      "loss": 0.1898,
      "step": 1100
    },
    {
      "epoch": 0.06645701062125438,
      "grad_norm": 1.2921186685562134,
      "learning_rate": 0.00019250015293325993,
      "loss": 0.1735,
      "step": 1120
    },
    {
      "epoch": 0.06764374295377677,
      "grad_norm": 1.146475911140442,
      "learning_rate": 0.00019225545971737935,
      "loss": 0.1949,
      "step": 1140
    },
    {
      "epoch": 0.06883047528629918,
      "grad_norm": 0.8779932856559753,
      "learning_rate": 0.00019201076650149877,
      "loss": 0.1917,
      "step": 1160
    },
    {
      "epoch": 0.07001720761882158,
      "grad_norm": 0.6404765248298645,
      "learning_rate": 0.00019176607328561817,
      "loss": 0.179,
      "step": 1180
    },
    {
      "epoch": 0.07120393995134397,
      "grad_norm": 0.766296923160553,
      "learning_rate": 0.00019152138006973756,
      "loss": 0.1793,
      "step": 1200
    },
    {
      "epoch": 0.07239067228386638,
      "grad_norm": 0.694268524646759,
      "learning_rate": 0.00019127668685385698,
      "loss": 0.1531,
      "step": 1220
    },
    {
      "epoch": 0.07357740461638877,
      "grad_norm": 1.2137054204940796,
      "learning_rate": 0.0001910319936379764,
      "loss": 0.1685,
      "step": 1240
    },
    {
      "epoch": 0.07476413694891117,
      "grad_norm": 0.563490629196167,
      "learning_rate": 0.0001907873004220958,
      "loss": 0.1883,
      "step": 1260
    },
    {
      "epoch": 0.07595086928143358,
      "grad_norm": 0.3835148811340332,
      "learning_rate": 0.00019054260720621522,
      "loss": 0.1536,
      "step": 1280
    },
    {
      "epoch": 0.07713760161395597,
      "grad_norm": 1.0763607025146484,
      "learning_rate": 0.00019029791399033464,
      "loss": 0.1852,
      "step": 1300
    },
    {
      "epoch": 0.07832433394647838,
      "grad_norm": 1.0360091924667358,
      "learning_rate": 0.00019005322077445403,
      "loss": 0.1669,
      "step": 1320
    },
    {
      "epoch": 0.07951106627900077,
      "grad_norm": 0.7025079727172852,
      "learning_rate": 0.00018980852755857346,
      "loss": 0.1596,
      "step": 1340
    },
    {
      "epoch": 0.08069779861152317,
      "grad_norm": 0.8763463497161865,
      "learning_rate": 0.00018956383434269285,
      "loss": 0.1774,
      "step": 1360
    },
    {
      "epoch": 0.08188453094404557,
      "grad_norm": 1.1772055625915527,
      "learning_rate": 0.00018931914112681227,
      "loss": 0.1965,
      "step": 1380
    },
    {
      "epoch": 0.08307126327656797,
      "grad_norm": 0.9459922909736633,
      "learning_rate": 0.00018907444791093166,
      "loss": 0.182,
      "step": 1400
    },
    {
      "epoch": 0.08425799560909036,
      "grad_norm": 1.053378939628601,
      "learning_rate": 0.00018882975469505109,
      "loss": 0.1654,
      "step": 1420
    },
    {
      "epoch": 0.08544472794161277,
      "grad_norm": 1.0819978713989258,
      "learning_rate": 0.0001885850614791705,
      "loss": 0.172,
      "step": 1440
    },
    {
      "epoch": 0.08663146027413517,
      "grad_norm": 0.6912683248519897,
      "learning_rate": 0.0001883403682632899,
      "loss": 0.2027,
      "step": 1460
    },
    {
      "epoch": 0.08781819260665757,
      "grad_norm": 0.4822098910808563,
      "learning_rate": 0.00018809567504740932,
      "loss": 0.1669,
      "step": 1480
    },
    {
      "epoch": 0.08900492493917997,
      "grad_norm": 0.9574181437492371,
      "learning_rate": 0.00018785098183152874,
      "loss": 0.1726,
      "step": 1500
    },
    {
      "epoch": 0.09019165727170236,
      "grad_norm": 0.7048868536949158,
      "learning_rate": 0.00018760628861564814,
      "loss": 0.1518,
      "step": 1520
    },
    {
      "epoch": 0.09137838960422477,
      "grad_norm": 1.0499224662780762,
      "learning_rate": 0.00018736159539976753,
      "loss": 0.164,
      "step": 1540
    },
    {
      "epoch": 0.09256512193674717,
      "grad_norm": 1.0764355659484863,
      "learning_rate": 0.00018711690218388695,
      "loss": 0.1847,
      "step": 1560
    },
    {
      "epoch": 0.09375185426926956,
      "grad_norm": 0.7772706151008606,
      "learning_rate": 0.00018687220896800637,
      "loss": 0.18,
      "step": 1580
    },
    {
      "epoch": 0.09493858660179197,
      "grad_norm": 0.5502411723136902,
      "learning_rate": 0.00018662751575212577,
      "loss": 0.1595,
      "step": 1600
    },
    {
      "epoch": 0.09612531893431436,
      "grad_norm": 0.9970443844795227,
      "learning_rate": 0.0001863828225362452,
      "loss": 0.159,
      "step": 1620
    },
    {
      "epoch": 0.09731205126683677,
      "grad_norm": 0.8331958055496216,
      "learning_rate": 0.0001861381293203646,
      "loss": 0.1841,
      "step": 1640
    },
    {
      "epoch": 0.09849878359935917,
      "grad_norm": 0.9332199096679688,
      "learning_rate": 0.00018589343610448403,
      "loss": 0.1677,
      "step": 1660
    },
    {
      "epoch": 0.09968551593188156,
      "grad_norm": 0.5376999378204346,
      "learning_rate": 0.00018564874288860343,
      "loss": 0.1886,
      "step": 1680
    },
    {
      "epoch": 0.10087224826440397,
      "grad_norm": 0.3745105266571045,
      "learning_rate": 0.00018540404967272282,
      "loss": 0.1938,
      "step": 1700
    },
    {
      "epoch": 0.10205898059692636,
      "grad_norm": 0.9584606289863586,
      "learning_rate": 0.00018515935645684224,
      "loss": 0.1727,
      "step": 1720
    },
    {
      "epoch": 0.10324571292944876,
      "grad_norm": 1.3053098917007446,
      "learning_rate": 0.00018491466324096166,
      "loss": 0.1894,
      "step": 1740
    },
    {
      "epoch": 0.10443244526197117,
      "grad_norm": 0.9485064744949341,
      "learning_rate": 0.00018466997002508106,
      "loss": 0.1881,
      "step": 1760
    },
    {
      "epoch": 0.10561917759449356,
      "grad_norm": 0.7136642932891846,
      "learning_rate": 0.00018442527680920048,
      "loss": 0.1846,
      "step": 1780
    },
    {
      "epoch": 0.10680590992701597,
      "grad_norm": 0.4535760283470154,
      "learning_rate": 0.0001841805835933199,
      "loss": 0.1728,
      "step": 1800
    },
    {
      "epoch": 0.10799264225953836,
      "grad_norm": 1.4677637815475464,
      "learning_rate": 0.0001839358903774393,
      "loss": 0.1763,
      "step": 1820
    },
    {
      "epoch": 0.10917937459206076,
      "grad_norm": 1.056240200996399,
      "learning_rate": 0.0001836911971615587,
      "loss": 0.1528,
      "step": 1840
    },
    {
      "epoch": 0.11036610692458317,
      "grad_norm": 0.57002192735672,
      "learning_rate": 0.0001834465039456781,
      "loss": 0.1695,
      "step": 1860
    },
    {
      "epoch": 0.11155283925710556,
      "grad_norm": 0.4732687175273895,
      "learning_rate": 0.00018320181072979753,
      "loss": 0.1578,
      "step": 1880
    },
    {
      "epoch": 0.11273957158962795,
      "grad_norm": 1.073503851890564,
      "learning_rate": 0.00018295711751391692,
      "loss": 0.1831,
      "step": 1900
    },
    {
      "epoch": 0.11392630392215036,
      "grad_norm": 0.7111108303070068,
      "learning_rate": 0.00018271242429803634,
      "loss": 0.171,
      "step": 1920
    },
    {
      "epoch": 0.11511303625467276,
      "grad_norm": 0.49186792969703674,
      "learning_rate": 0.00018246773108215576,
      "loss": 0.1724,
      "step": 1940
    },
    {
      "epoch": 0.11629976858719515,
      "grad_norm": 0.7406271696090698,
      "learning_rate": 0.00018222303786627516,
      "loss": 0.1906,
      "step": 1960
    },
    {
      "epoch": 0.11748650091971756,
      "grad_norm": 1.094698190689087,
      "learning_rate": 0.00018197834465039458,
      "loss": 0.1829,
      "step": 1980
    },
    {
      "epoch": 0.11867323325223995,
      "grad_norm": 0.5397536158561707,
      "learning_rate": 0.000181733651434514,
      "loss": 0.1666,
      "step": 2000
    },
    {
      "epoch": 0.11985996558476236,
      "grad_norm": 0.6664129495620728,
      "learning_rate": 0.0001814889582186334,
      "loss": 0.1749,
      "step": 2020
    },
    {
      "epoch": 0.12104669791728476,
      "grad_norm": 1.1101148128509521,
      "learning_rate": 0.0001812442650027528,
      "loss": 0.1686,
      "step": 2040
    },
    {
      "epoch": 0.12223343024980715,
      "grad_norm": 0.5911523699760437,
      "learning_rate": 0.0001809995717868722,
      "loss": 0.1777,
      "step": 2060
    },
    {
      "epoch": 0.12342016258232956,
      "grad_norm": 0.7469328045845032,
      "learning_rate": 0.00018075487857099163,
      "loss": 0.1861,
      "step": 2080
    },
    {
      "epoch": 0.12460689491485195,
      "grad_norm": 0.31800663471221924,
      "learning_rate": 0.00018051018535511105,
      "loss": 0.1627,
      "step": 2100
    },
    {
      "epoch": 0.12579362724737436,
      "grad_norm": 0.48015668988227844,
      "learning_rate": 0.00018026549213923045,
      "loss": 0.1627,
      "step": 2120
    },
    {
      "epoch": 0.12698035957989676,
      "grad_norm": 1.0048174858093262,
      "learning_rate": 0.00018002079892334987,
      "loss": 0.1843,
      "step": 2140
    },
    {
      "epoch": 0.12816709191241915,
      "grad_norm": 0.6180223226547241,
      "learning_rate": 0.0001797761057074693,
      "loss": 0.1774,
      "step": 2160
    },
    {
      "epoch": 0.12935382424494155,
      "grad_norm": 0.8206998109817505,
      "learning_rate": 0.00017953141249158866,
      "loss": 0.1609,
      "step": 2180
    },
    {
      "epoch": 0.13054055657746394,
      "grad_norm": 1.3118736743927002,
      "learning_rate": 0.00017928671927570808,
      "loss": 0.1886,
      "step": 2200
    },
    {
      "epoch": 0.13172728890998636,
      "grad_norm": 0.9671075940132141,
      "learning_rate": 0.0001790420260598275,
      "loss": 0.1776,
      "step": 2220
    },
    {
      "epoch": 0.13291402124250876,
      "grad_norm": 1.5553646087646484,
      "learning_rate": 0.00017879733284394692,
      "loss": 0.1747,
      "step": 2240
    },
    {
      "epoch": 0.13410075357503115,
      "grad_norm": 0.6957961320877075,
      "learning_rate": 0.0001785526396280663,
      "loss": 0.1555,
      "step": 2260
    },
    {
      "epoch": 0.13528748590755355,
      "grad_norm": 1.2844537496566772,
      "learning_rate": 0.00017830794641218573,
      "loss": 0.1815,
      "step": 2280
    },
    {
      "epoch": 0.13647421824007594,
      "grad_norm": 0.8869533538818359,
      "learning_rate": 0.00017806325319630516,
      "loss": 0.1681,
      "step": 2300
    },
    {
      "epoch": 0.13766095057259836,
      "grad_norm": 0.6070054173469543,
      "learning_rate": 0.00017781855998042455,
      "loss": 0.1884,
      "step": 2320
    },
    {
      "epoch": 0.13884768290512076,
      "grad_norm": 0.6387043595314026,
      "learning_rate": 0.00017757386676454397,
      "loss": 0.1785,
      "step": 2340
    },
    {
      "epoch": 0.14003441523764315,
      "grad_norm": 0.8562039136886597,
      "learning_rate": 0.00017732917354866336,
      "loss": 0.1765,
      "step": 2360
    },
    {
      "epoch": 0.14122114757016554,
      "grad_norm": 0.6733729243278503,
      "learning_rate": 0.00017708448033278279,
      "loss": 0.1728,
      "step": 2380
    },
    {
      "epoch": 0.14240787990268794,
      "grad_norm": 0.541414201259613,
      "learning_rate": 0.00017683978711690218,
      "loss": 0.1751,
      "step": 2400
    },
    {
      "epoch": 0.14359461223521036,
      "grad_norm": 0.72004634141922,
      "learning_rate": 0.0001765950939010216,
      "loss": 0.1768,
      "step": 2420
    },
    {
      "epoch": 0.14478134456773276,
      "grad_norm": 1.3256465196609497,
      "learning_rate": 0.00017635040068514102,
      "loss": 0.1982,
      "step": 2440
    },
    {
      "epoch": 0.14596807690025515,
      "grad_norm": 0.8342276811599731,
      "learning_rate": 0.00017610570746926042,
      "loss": 0.1738,
      "step": 2460
    },
    {
      "epoch": 0.14715480923277754,
      "grad_norm": 0.7471433281898499,
      "learning_rate": 0.00017586101425337984,
      "loss": 0.1691,
      "step": 2480
    },
    {
      "epoch": 0.14834154156529994,
      "grad_norm": 0.6749514937400818,
      "learning_rate": 0.00017561632103749926,
      "loss": 0.1703,
      "step": 2500
    },
    {
      "epoch": 0.14952827389782233,
      "grad_norm": 1.5795814990997314,
      "learning_rate": 0.00017537162782161865,
      "loss": 0.1713,
      "step": 2520
    },
    {
      "epoch": 0.15071500623034476,
      "grad_norm": 0.6846436858177185,
      "learning_rate": 0.00017512693460573805,
      "loss": 0.1813,
      "step": 2540
    },
    {
      "epoch": 0.15190173856286715,
      "grad_norm": 0.8128787875175476,
      "learning_rate": 0.00017488224138985747,
      "loss": 0.1818,
      "step": 2560
    },
    {
      "epoch": 0.15308847089538954,
      "grad_norm": 0.7355286478996277,
      "learning_rate": 0.0001746375481739769,
      "loss": 0.1709,
      "step": 2580
    },
    {
      "epoch": 0.15427520322791194,
      "grad_norm": 0.48653507232666016,
      "learning_rate": 0.0001743928549580963,
      "loss": 0.1807,
      "step": 2600
    },
    {
      "epoch": 0.15546193556043433,
      "grad_norm": 0.47177016735076904,
      "learning_rate": 0.0001741481617422157,
      "loss": 0.159,
      "step": 2620
    },
    {
      "epoch": 0.15664866789295676,
      "grad_norm": 0.7566419243812561,
      "learning_rate": 0.00017390346852633513,
      "loss": 0.1569,
      "step": 2640
    },
    {
      "epoch": 0.15783540022547915,
      "grad_norm": 1.011892318725586,
      "learning_rate": 0.00017365877531045455,
      "loss": 0.1787,
      "step": 2660
    },
    {
      "epoch": 0.15902213255800154,
      "grad_norm": 0.5011774897575378,
      "learning_rate": 0.0001734140820945739,
      "loss": 0.1843,
      "step": 2680
    },
    {
      "epoch": 0.16020886489052394,
      "grad_norm": 0.844852089881897,
      "learning_rate": 0.00017316938887869333,
      "loss": 0.1781,
      "step": 2700
    },
    {
      "epoch": 0.16139559722304633,
      "grad_norm": 0.6301392912864685,
      "learning_rate": 0.00017292469566281276,
      "loss": 0.1694,
      "step": 2720
    },
    {
      "epoch": 0.16258232955556876,
      "grad_norm": 0.4192286729812622,
      "learning_rate": 0.00017268000244693218,
      "loss": 0.1681,
      "step": 2740
    },
    {
      "epoch": 0.16376906188809115,
      "grad_norm": 0.7322239279747009,
      "learning_rate": 0.00017243530923105157,
      "loss": 0.1685,
      "step": 2760
    },
    {
      "epoch": 0.16495579422061354,
      "grad_norm": 0.631675124168396,
      "learning_rate": 0.000172190616015171,
      "loss": 0.1735,
      "step": 2780
    },
    {
      "epoch": 0.16614252655313594,
      "grad_norm": 0.8527517914772034,
      "learning_rate": 0.0001719459227992904,
      "loss": 0.1761,
      "step": 2800
    },
    {
      "epoch": 0.16732925888565833,
      "grad_norm": 0.40665340423583984,
      "learning_rate": 0.0001717012295834098,
      "loss": 0.1615,
      "step": 2820
    },
    {
      "epoch": 0.16851599121818073,
      "grad_norm": 0.5535704493522644,
      "learning_rate": 0.0001714565363675292,
      "loss": 0.1624,
      "step": 2840
    },
    {
      "epoch": 0.16970272355070315,
      "grad_norm": 0.6593342423439026,
      "learning_rate": 0.00017121184315164862,
      "loss": 0.1851,
      "step": 2860
    },
    {
      "epoch": 0.17088945588322554,
      "grad_norm": 1.3504664897918701,
      "learning_rate": 0.00017096714993576804,
      "loss": 0.1818,
      "step": 2880
    },
    {
      "epoch": 0.17207618821574794,
      "grad_norm": 0.3278674781322479,
      "learning_rate": 0.00017072245671988744,
      "loss": 0.162,
      "step": 2900
    },
    {
      "epoch": 0.17326292054827033,
      "grad_norm": 0.7130964994430542,
      "learning_rate": 0.00017047776350400686,
      "loss": 0.1817,
      "step": 2920
    },
    {
      "epoch": 0.17444965288079273,
      "grad_norm": 1.2378586530685425,
      "learning_rate": 0.00017023307028812628,
      "loss": 0.173,
      "step": 2940
    },
    {
      "epoch": 0.17563638521331515,
      "grad_norm": 0.9073180556297302,
      "learning_rate": 0.00016998837707224567,
      "loss": 0.1728,
      "step": 2960
    },
    {
      "epoch": 0.17682311754583754,
      "grad_norm": 0.5911349058151245,
      "learning_rate": 0.0001697436838563651,
      "loss": 0.1748,
      "step": 2980
    },
    {
      "epoch": 0.17800984987835994,
      "grad_norm": 1.4161670207977295,
      "learning_rate": 0.0001694989906404845,
      "loss": 0.1905,
      "step": 3000
    },
    {
      "epoch": 0.17919658221088233,
      "grad_norm": 0.9137594103813171,
      "learning_rate": 0.0001692542974246039,
      "loss": 0.1809,
      "step": 3020
    },
    {
      "epoch": 0.18038331454340473,
      "grad_norm": 0.7186339497566223,
      "learning_rate": 0.0001690096042087233,
      "loss": 0.1522,
      "step": 3040
    },
    {
      "epoch": 0.18157004687592712,
      "grad_norm": 0.7299916744232178,
      "learning_rate": 0.00016876491099284273,
      "loss": 0.1771,
      "step": 3060
    },
    {
      "epoch": 0.18275677920844954,
      "grad_norm": 0.6104021072387695,
      "learning_rate": 0.00016852021777696215,
      "loss": 0.1665,
      "step": 3080
    },
    {
      "epoch": 0.18394351154097194,
      "grad_norm": 0.6279229521751404,
      "learning_rate": 0.00016827552456108157,
      "loss": 0.1763,
      "step": 3100
    },
    {
      "epoch": 0.18513024387349433,
      "grad_norm": 0.799588143825531,
      "learning_rate": 0.00016803083134520096,
      "loss": 0.1895,
      "step": 3120
    },
    {
      "epoch": 0.18631697620601673,
      "grad_norm": 0.7979286909103394,
      "learning_rate": 0.00016778613812932038,
      "loss": 0.1905,
      "step": 3140
    },
    {
      "epoch": 0.18750370853853912,
      "grad_norm": 0.6708881258964539,
      "learning_rate": 0.0001675414449134398,
      "loss": 0.1833,
      "step": 3160
    },
    {
      "epoch": 0.18869044087106154,
      "grad_norm": 0.5099575519561768,
      "learning_rate": 0.0001672967516975592,
      "loss": 0.1652,
      "step": 3180
    },
    {
      "epoch": 0.18987717320358394,
      "grad_norm": 0.707276463508606,
      "learning_rate": 0.0001670520584816786,
      "loss": 0.1729,
      "step": 3200
    },
    {
      "epoch": 0.19106390553610633,
      "grad_norm": 0.6178401708602905,
      "learning_rate": 0.000166807365265798,
      "loss": 0.1633,
      "step": 3220
    },
    {
      "epoch": 0.19225063786862873,
      "grad_norm": 1.486738920211792,
      "learning_rate": 0.00016656267204991743,
      "loss": 0.1774,
      "step": 3240
    },
    {
      "epoch": 0.19343737020115112,
      "grad_norm": 1.163561463356018,
      "learning_rate": 0.00016631797883403683,
      "loss": 0.1828,
      "step": 3260
    },
    {
      "epoch": 0.19462410253367354,
      "grad_norm": 0.5214402079582214,
      "learning_rate": 0.00016607328561815625,
      "loss": 0.1629,
      "step": 3280
    },
    {
      "epoch": 0.19581083486619594,
      "grad_norm": 0.5299138426780701,
      "learning_rate": 0.00016582859240227567,
      "loss": 0.1807,
      "step": 3300
    },
    {
      "epoch": 0.19699756719871833,
      "grad_norm": 0.5696702003479004,
      "learning_rate": 0.00016558389918639506,
      "loss": 0.1799,
      "step": 3320
    },
    {
      "epoch": 0.19818429953124073,
      "grad_norm": 0.7235682606697083,
      "learning_rate": 0.00016533920597051446,
      "loss": 0.1836,
      "step": 3340
    },
    {
      "epoch": 0.19937103186376312,
      "grad_norm": 0.7959086894989014,
      "learning_rate": 0.00016509451275463388,
      "loss": 0.1625,
      "step": 3360
    },
    {
      "epoch": 0.20055776419628552,
      "grad_norm": 0.4778512120246887,
      "learning_rate": 0.0001648498195387533,
      "loss": 0.187,
      "step": 3380
    },
    {
      "epoch": 0.20174449652880794,
      "grad_norm": 0.8882611393928528,
      "learning_rate": 0.0001646051263228727,
      "loss": 0.1747,
      "step": 3400
    },
    {
      "epoch": 0.20293122886133033,
      "grad_norm": 1.088204026222229,
      "learning_rate": 0.00016436043310699212,
      "loss": 0.1752,
      "step": 3420
    },
    {
      "epoch": 0.20411796119385273,
      "grad_norm": 0.6490910649299622,
      "learning_rate": 0.00016411573989111154,
      "loss": 0.1817,
      "step": 3440
    },
    {
      "epoch": 0.20530469352637512,
      "grad_norm": 0.463487446308136,
      "learning_rate": 0.00016387104667523093,
      "loss": 0.1713,
      "step": 3460
    },
    {
      "epoch": 0.20649142585889751,
      "grad_norm": 87.41232299804688,
      "learning_rate": 0.00016362635345935035,
      "loss": 3.4559,
      "step": 3480
    },
    {
      "epoch": 0.20767815819141994,
      "grad_norm": 41.957523345947266,
      "learning_rate": 0.00016338166024346975,
      "loss": 1.8031,
      "step": 3500
    },
    {
      "epoch": 0.20886489052394233,
      "grad_norm": 0.9760203957557678,
      "learning_rate": 0.00016313696702758917,
      "loss": 0.6273,
      "step": 3520
    },
    {
      "epoch": 0.21005162285646473,
      "grad_norm": 0.9361951947212219,
      "learning_rate": 0.00016289227381170856,
      "loss": 0.23,
      "step": 3540
    },
    {
      "epoch": 0.21123835518898712,
      "grad_norm": 1.4854176044464111,
      "learning_rate": 0.00016264758059582798,
      "loss": 0.1715,
      "step": 3560
    },
    {
      "epoch": 0.21242508752150951,
      "grad_norm": 1.2274736166000366,
      "learning_rate": 0.0001624028873799474,
      "loss": 0.5363,
      "step": 3580
    },
    {
      "epoch": 0.21361181985403194,
      "grad_norm": 328.24237060546875,
      "learning_rate": 0.00016215819416406682,
      "loss": 0.2082,
      "step": 3600
    },
    {
      "epoch": 0.21479855218655433,
      "grad_norm": 3.1821999549865723,
      "learning_rate": 0.00016191350094818622,
      "loss": 0.1946,
      "step": 3620
    },
    {
      "epoch": 0.21598528451907673,
      "grad_norm": 0.7440794110298157,
      "learning_rate": 0.00016166880773230564,
      "loss": 0.1614,
      "step": 3640
    },
    {
      "epoch": 0.21717201685159912,
      "grad_norm": 0.850250780582428,
      "learning_rate": 0.00016142411451642503,
      "loss": 0.1897,
      "step": 3660
    },
    {
      "epoch": 0.21835874918412151,
      "grad_norm": 1.1185108423233032,
      "learning_rate": 0.00016117942130054446,
      "loss": 0.1705,
      "step": 3680
    },
    {
      "epoch": 0.2195454815166439,
      "grad_norm": 0.684779942035675,
      "learning_rate": 0.00016093472808466385,
      "loss": 0.1747,
      "step": 3700
    },
    {
      "epoch": 0.22073221384916633,
      "grad_norm": 0.6430562138557434,
      "learning_rate": 0.00016069003486878327,
      "loss": 0.1685,
      "step": 3720
    },
    {
      "epoch": 0.22191894618168873,
      "grad_norm": 0.9009201526641846,
      "learning_rate": 0.0001604453416529027,
      "loss": 0.178,
      "step": 3740
    },
    {
      "epoch": 0.22310567851421112,
      "grad_norm": 1.0389184951782227,
      "learning_rate": 0.00016020064843702209,
      "loss": 0.2022,
      "step": 3760
    },
    {
      "epoch": 0.22429241084673351,
      "grad_norm": 1.5340237617492676,
      "learning_rate": 0.0001599559552211415,
      "loss": 0.1632,
      "step": 3780
    },
    {
      "epoch": 0.2254791431792559,
      "grad_norm": 0.4583185911178589,
      "learning_rate": 0.00015971126200526093,
      "loss": 0.1719,
      "step": 3800
    },
    {
      "epoch": 0.22666587551177833,
      "grad_norm": 0.5563245415687561,
      "learning_rate": 0.00015946656878938032,
      "loss": 0.1711,
      "step": 3820
    },
    {
      "epoch": 0.22785260784430073,
      "grad_norm": 0.9405747056007385,
      "learning_rate": 0.00015922187557349972,
      "loss": 0.1798,
      "step": 3840
    },
    {
      "epoch": 0.22903934017682312,
      "grad_norm": 1.4520392417907715,
      "learning_rate": 0.00015897718235761914,
      "loss": 0.1668,
      "step": 3860
    },
    {
      "epoch": 0.23022607250934551,
      "grad_norm": 1.169108510017395,
      "learning_rate": 0.00015873248914173856,
      "loss": 0.1927,
      "step": 3880
    },
    {
      "epoch": 0.2314128048418679,
      "grad_norm": 1.0358880758285522,
      "learning_rate": 0.00015848779592585795,
      "loss": 0.1796,
      "step": 3900
    },
    {
      "epoch": 0.2325995371743903,
      "grad_norm": 0.611681342124939,
      "learning_rate": 0.00015824310270997737,
      "loss": 0.18,
      "step": 3920
    },
    {
      "epoch": 0.23378626950691273,
      "grad_norm": 0.5284295082092285,
      "learning_rate": 0.0001579984094940968,
      "loss": 0.1576,
      "step": 3940
    },
    {
      "epoch": 0.23497300183943512,
      "grad_norm": 4.736672401428223,
      "learning_rate": 0.0001577537162782162,
      "loss": 0.2205,
      "step": 3960
    },
    {
      "epoch": 0.2361597341719575,
      "grad_norm": 0.5845065116882324,
      "learning_rate": 0.0001575090230623356,
      "loss": 0.1528,
      "step": 3980
    },
    {
      "epoch": 0.2373464665044799,
      "grad_norm": 0.8949515223503113,
      "learning_rate": 0.000157264329846455,
      "loss": 0.1781,
      "step": 4000
    },
    {
      "epoch": 0.2385331988370023,
      "grad_norm": 1.2211978435516357,
      "learning_rate": 0.00015701963663057442,
      "loss": 0.1595,
      "step": 4020
    },
    {
      "epoch": 0.23971993116952472,
      "grad_norm": 1.1786205768585205,
      "learning_rate": 0.00015677494341469382,
      "loss": 0.1693,
      "step": 4040
    },
    {
      "epoch": 0.24090666350204712,
      "grad_norm": 0.9738118648529053,
      "learning_rate": 0.00015653025019881324,
      "loss": 0.1639,
      "step": 4060
    },
    {
      "epoch": 0.2420933958345695,
      "grad_norm": 0.8663210272789001,
      "learning_rate": 0.00015628555698293266,
      "loss": 0.1851,
      "step": 4080
    },
    {
      "epoch": 0.2432801281670919,
      "grad_norm": 0.885305643081665,
      "learning_rate": 0.00015604086376705208,
      "loss": 0.1754,
      "step": 4100
    },
    {
      "epoch": 0.2444668604996143,
      "grad_norm": 0.6017959713935852,
      "learning_rate": 0.00015579617055117148,
      "loss": 0.1947,
      "step": 4120
    },
    {
      "epoch": 0.24565359283213672,
      "grad_norm": 1.0310851335525513,
      "learning_rate": 0.0001555514773352909,
      "loss": 0.1864,
      "step": 4140
    },
    {
      "epoch": 0.24684032516465912,
      "grad_norm": 0.7444639205932617,
      "learning_rate": 0.0001553067841194103,
      "loss": 0.196,
      "step": 4160
    },
    {
      "epoch": 0.2480270574971815,
      "grad_norm": 0.8582164645195007,
      "learning_rate": 0.0001550620909035297,
      "loss": 0.1953,
      "step": 4180
    },
    {
      "epoch": 0.2492137898297039,
      "grad_norm": 40.604835510253906,
      "learning_rate": 0.0001548173976876491,
      "loss": 0.2367,
      "step": 4200
    },
    {
      "epoch": 0.2504005221622263,
      "grad_norm": 0.8108139634132385,
      "learning_rate": 0.00015457270447176853,
      "loss": 0.1813,
      "step": 4220
    },
    {
      "epoch": 0.2515872544947487,
      "grad_norm": 13.872315406799316,
      "learning_rate": 0.00015432801125588795,
      "loss": 0.7042,
      "step": 4240
    },
    {
      "epoch": 0.2527739868272711,
      "grad_norm": 6.689643383026123,
      "learning_rate": 0.00015408331804000734,
      "loss": 0.4296,
      "step": 4260
    },
    {
      "epoch": 0.2539607191597935,
      "grad_norm": 8.426287651062012,
      "learning_rate": 0.00015383862482412676,
      "loss": 0.1839,
      "step": 4280
    },
    {
      "epoch": 0.25514745149231594,
      "grad_norm": 2.531038999557495,
      "learning_rate": 0.00015359393160824619,
      "loss": 0.1883,
      "step": 4300
    },
    {
      "epoch": 0.2563341838248383,
      "grad_norm": 0.8161940574645996,
      "learning_rate": 0.00015334923839236558,
      "loss": 0.202,
      "step": 4320
    },
    {
      "epoch": 0.2575209161573607,
      "grad_norm": 3.778665542602539,
      "learning_rate": 0.00015310454517648497,
      "loss": 0.271,
      "step": 4340
    },
    {
      "epoch": 0.2587076484898831,
      "grad_norm": 5.831120491027832,
      "learning_rate": 0.0001528598519606044,
      "loss": 0.239,
      "step": 4360
    },
    {
      "epoch": 0.2598943808224055,
      "grad_norm": 6.120175361633301,
      "learning_rate": 0.00015261515874472382,
      "loss": 0.1873,
      "step": 4380
    },
    {
      "epoch": 0.2610811131549279,
      "grad_norm": 4.9133758544921875,
      "learning_rate": 0.0001523704655288432,
      "loss": 0.2062,
      "step": 4400
    },
    {
      "epoch": 0.2622678454874503,
      "grad_norm": 0.4924696683883667,
      "learning_rate": 0.00015212577231296263,
      "loss": 0.1691,
      "step": 4420
    },
    {
      "epoch": 0.2634545778199727,
      "grad_norm": 8.098684310913086,
      "learning_rate": 0.00015188107909708205,
      "loss": 0.1939,
      "step": 4440
    },
    {
      "epoch": 0.2646413101524951,
      "grad_norm": 1.5233451128005981,
      "learning_rate": 0.00015163638588120145,
      "loss": 0.1836,
      "step": 4460
    },
    {
      "epoch": 0.2658280424850175,
      "grad_norm": 0.876188337802887,
      "learning_rate": 0.00015139169266532087,
      "loss": 0.1827,
      "step": 4480
    },
    {
      "epoch": 0.2670147748175399,
      "grad_norm": 12.803918838500977,
      "learning_rate": 0.00015114699944944026,
      "loss": 0.191,
      "step": 4500
    },
    {
      "epoch": 0.2682015071500623,
      "grad_norm": 2.8493897914886475,
      "learning_rate": 0.00015090230623355968,
      "loss": 0.1769,
      "step": 4520
    },
    {
      "epoch": 0.2693882394825847,
      "grad_norm": 3.8985259532928467,
      "learning_rate": 0.00015065761301767908,
      "loss": 0.1733,
      "step": 4540
    },
    {
      "epoch": 0.2705749718151071,
      "grad_norm": 5.682783126831055,
      "learning_rate": 0.0001504129198017985,
      "loss": 0.215,
      "step": 4560
    },
    {
      "epoch": 0.2717617041476295,
      "grad_norm": 1.2603858709335327,
      "learning_rate": 0.00015016822658591792,
      "loss": 0.1751,
      "step": 4580
    },
    {
      "epoch": 0.2729484364801519,
      "grad_norm": 3.8710672855377197,
      "learning_rate": 0.00014992353337003734,
      "loss": 0.1529,
      "step": 4600
    },
    {
      "epoch": 0.2741351688126743,
      "grad_norm": 4.567991733551025,
      "learning_rate": 0.00014967884015415673,
      "loss": 0.1819,
      "step": 4620
    },
    {
      "epoch": 0.2753219011451967,
      "grad_norm": 1.0108650922775269,
      "learning_rate": 0.00014943414693827616,
      "loss": 0.1851,
      "step": 4640
    },
    {
      "epoch": 0.2765086334777191,
      "grad_norm": 1.1534523963928223,
      "learning_rate": 0.00014918945372239555,
      "loss": 0.1685,
      "step": 4660
    },
    {
      "epoch": 0.2776953658102415,
      "grad_norm": 6.444522380828857,
      "learning_rate": 0.00014894476050651497,
      "loss": 0.1892,
      "step": 4680
    },
    {
      "epoch": 0.2788820981427639,
      "grad_norm": 0.6402760744094849,
      "learning_rate": 0.00014870006729063436,
      "loss": 0.1686,
      "step": 4700
    },
    {
      "epoch": 0.2800688304752863,
      "grad_norm": 6.809281349182129,
      "learning_rate": 0.00014845537407475379,
      "loss": 0.1714,
      "step": 4720
    },
    {
      "epoch": 0.2812555628078087,
      "grad_norm": 2.4935927391052246,
      "learning_rate": 0.0001482106808588732,
      "loss": 0.1788,
      "step": 4740
    },
    {
      "epoch": 0.2824422951403311,
      "grad_norm": 1.403747320175171,
      "learning_rate": 0.0001479659876429926,
      "loss": 0.1745,
      "step": 4760
    },
    {
      "epoch": 0.2836290274728535,
      "grad_norm": 1.0164713859558105,
      "learning_rate": 0.00014772129442711202,
      "loss": 0.1691,
      "step": 4780
    },
    {
      "epoch": 0.2848157598053759,
      "grad_norm": 2.4749810695648193,
      "learning_rate": 0.00014747660121123144,
      "loss": 0.1633,
      "step": 4800
    },
    {
      "epoch": 0.2860024921378983,
      "grad_norm": 0.9152519702911377,
      "learning_rate": 0.00014723190799535084,
      "loss": 0.1925,
      "step": 4820
    },
    {
      "epoch": 0.2871892244704207,
      "grad_norm": 2.941408634185791,
      "learning_rate": 0.00014698721477947023,
      "loss": 0.1728,
      "step": 4840
    },
    {
      "epoch": 0.2883759568029431,
      "grad_norm": 7.200240135192871,
      "learning_rate": 0.00014674252156358965,
      "loss": 0.1784,
      "step": 4860
    },
    {
      "epoch": 0.2895626891354655,
      "grad_norm": 2.1803476810455322,
      "learning_rate": 0.00014649782834770907,
      "loss": 0.2241,
      "step": 4880
    },
    {
      "epoch": 0.2907494214679879,
      "grad_norm": 3.621522903442383,
      "learning_rate": 0.00014625313513182847,
      "loss": 0.1821,
      "step": 4900
    },
    {
      "epoch": 0.2919361538005103,
      "grad_norm": 9.171581268310547,
      "learning_rate": 0.0001460084419159479,
      "loss": 0.1745,
      "step": 4920
    },
    {
      "epoch": 0.29312288613303267,
      "grad_norm": 0.8162786960601807,
      "learning_rate": 0.0001457637487000673,
      "loss": 0.182,
      "step": 4940
    },
    {
      "epoch": 0.2943096184655551,
      "grad_norm": 4.654858112335205,
      "learning_rate": 0.0001455190554841867,
      "loss": 0.1577,
      "step": 4960
    },
    {
      "epoch": 0.2954963507980775,
      "grad_norm": 9.50095272064209,
      "learning_rate": 0.0001452743622683061,
      "loss": 0.2151,
      "step": 4980
    },
    {
      "epoch": 0.2966830831305999,
      "grad_norm": 3.4608633518218994,
      "learning_rate": 0.00014502966905242552,
      "loss": 0.1896,
      "step": 5000
    },
    {
      "epoch": 0.2978698154631223,
      "grad_norm": 6.7744526863098145,
      "learning_rate": 0.00014478497583654494,
      "loss": 0.1817,
      "step": 5020
    },
    {
      "epoch": 0.29905654779564467,
      "grad_norm": 1.6864219903945923,
      "learning_rate": 0.00014454028262066433,
      "loss": 0.1598,
      "step": 5040
    },
    {
      "epoch": 0.3002432801281671,
      "grad_norm": 1.2645649909973145,
      "learning_rate": 0.00014429558940478376,
      "loss": 0.1833,
      "step": 5060
    },
    {
      "epoch": 0.3014300124606895,
      "grad_norm": 0.8296667337417603,
      "learning_rate": 0.00014405089618890318,
      "loss": 0.1665,
      "step": 5080
    },
    {
      "epoch": 0.3026167447932119,
      "grad_norm": 9.670210838317871,
      "learning_rate": 0.0001438062029730226,
      "loss": 0.182,
      "step": 5100
    },
    {
      "epoch": 0.3038034771257343,
      "grad_norm": 1.1169532537460327,
      "learning_rate": 0.000143561509757142,
      "loss": 0.1622,
      "step": 5120
    },
    {
      "epoch": 0.30499020945825667,
      "grad_norm": 5.790740013122559,
      "learning_rate": 0.00014331681654126139,
      "loss": 0.2082,
      "step": 5140
    },
    {
      "epoch": 0.3061769417907791,
      "grad_norm": 1.2531321048736572,
      "learning_rate": 0.0001430721233253808,
      "loss": 0.1838,
      "step": 5160
    },
    {
      "epoch": 0.3073636741233015,
      "grad_norm": 2.624356746673584,
      "learning_rate": 0.00014282743010950023,
      "loss": 0.1741,
      "step": 5180
    },
    {
      "epoch": 0.3085504064558239,
      "grad_norm": 1.0398576259613037,
      "learning_rate": 0.00014258273689361962,
      "loss": 0.1684,
      "step": 5200
    },
    {
      "epoch": 0.3097371387883463,
      "grad_norm": 7.879695415496826,
      "learning_rate": 0.00014233804367773904,
      "loss": 0.1742,
      "step": 5220
    },
    {
      "epoch": 0.31092387112086867,
      "grad_norm": 4.87844181060791,
      "learning_rate": 0.00014209335046185846,
      "loss": 0.1937,
      "step": 5240
    },
    {
      "epoch": 0.3121106034533911,
      "grad_norm": 1.1635853052139282,
      "learning_rate": 0.00014184865724597786,
      "loss": 0.1858,
      "step": 5260
    },
    {
      "epoch": 0.3132973357859135,
      "grad_norm": 2.0461111068725586,
      "learning_rate": 0.00014160396403009728,
      "loss": 0.2123,
      "step": 5280
    },
    {
      "epoch": 0.3144840681184359,
      "grad_norm": 3.1764304637908936,
      "learning_rate": 0.0001413592708142167,
      "loss": 0.1827,
      "step": 5300
    },
    {
      "epoch": 0.3156708004509583,
      "grad_norm": 2.6496407985687256,
      "learning_rate": 0.0001411145775983361,
      "loss": 0.1755,
      "step": 5320
    },
    {
      "epoch": 0.31685753278348067,
      "grad_norm": 3.4342269897460938,
      "learning_rate": 0.0001408698843824555,
      "loss": 0.2048,
      "step": 5340
    },
    {
      "epoch": 0.3180442651160031,
      "grad_norm": 5.3983917236328125,
      "learning_rate": 0.0001406251911665749,
      "loss": 0.1925,
      "step": 5360
    },
    {
      "epoch": 0.3192309974485255,
      "grad_norm": 2.419285535812378,
      "learning_rate": 0.00014038049795069433,
      "loss": 0.1593,
      "step": 5380
    },
    {
      "epoch": 0.3204177297810479,
      "grad_norm": 1.578204870223999,
      "learning_rate": 0.00014013580473481372,
      "loss": 0.1812,
      "step": 5400
    },
    {
      "epoch": 0.3216044621135703,
      "grad_norm": 1.1957728862762451,
      "learning_rate": 0.00013989111151893315,
      "loss": 0.177,
      "step": 5420
    },
    {
      "epoch": 0.32279119444609267,
      "grad_norm": 1.1898016929626465,
      "learning_rate": 0.00013964641830305257,
      "loss": 0.188,
      "step": 5440
    },
    {
      "epoch": 0.3239779267786151,
      "grad_norm": 0.889805793762207,
      "learning_rate": 0.000139401725087172,
      "loss": 0.1745,
      "step": 5460
    },
    {
      "epoch": 0.3251646591111375,
      "grad_norm": 0.8465717434883118,
      "learning_rate": 0.00013915703187129136,
      "loss": 0.1618,
      "step": 5480
    },
    {
      "epoch": 0.3263513914436599,
      "grad_norm": 1.2032173871994019,
      "learning_rate": 0.00013891233865541078,
      "loss": 0.1862,
      "step": 5500
    },
    {
      "epoch": 0.3275381237761823,
      "grad_norm": 1.4246822595596313,
      "learning_rate": 0.0001386676454395302,
      "loss": 0.1893,
      "step": 5520
    },
    {
      "epoch": 0.32872485610870467,
      "grad_norm": 0.6001741290092468,
      "learning_rate": 0.0001384229522236496,
      "loss": 0.1811,
      "step": 5540
    },
    {
      "epoch": 0.3299115884412271,
      "grad_norm": 1.0435596704483032,
      "learning_rate": 0.000138178259007769,
      "loss": 0.1954,
      "step": 5560
    },
    {
      "epoch": 0.33109832077374945,
      "grad_norm": 0.8947221040725708,
      "learning_rate": 0.00013793356579188843,
      "loss": 0.1604,
      "step": 5580
    },
    {
      "epoch": 0.3322850531062719,
      "grad_norm": 1.2344961166381836,
      "learning_rate": 0.00013768887257600785,
      "loss": 0.1779,
      "step": 5600
    },
    {
      "epoch": 0.3334717854387943,
      "grad_norm": 1.0585870742797852,
      "learning_rate": 0.00013744417936012725,
      "loss": 0.1765,
      "step": 5620
    },
    {
      "epoch": 0.33465851777131667,
      "grad_norm": 1.2151741981506348,
      "learning_rate": 0.00013719948614424664,
      "loss": 0.1635,
      "step": 5640
    },
    {
      "epoch": 0.3358452501038391,
      "grad_norm": 1.2959781885147095,
      "learning_rate": 0.00013695479292836606,
      "loss": 0.1617,
      "step": 5660
    },
    {
      "epoch": 0.33703198243636145,
      "grad_norm": 1.0395054817199707,
      "learning_rate": 0.00013671009971248549,
      "loss": 0.1932,
      "step": 5680
    },
    {
      "epoch": 0.3382187147688839,
      "grad_norm": 1.1350691318511963,
      "learning_rate": 0.00013646540649660488,
      "loss": 0.1842,
      "step": 5700
    },
    {
      "epoch": 0.3394054471014063,
      "grad_norm": 1.0142441987991333,
      "learning_rate": 0.0001362207132807243,
      "loss": 0.1752,
      "step": 5720
    },
    {
      "epoch": 0.34059217943392867,
      "grad_norm": 0.9044297337532043,
      "learning_rate": 0.00013597602006484372,
      "loss": 0.1809,
      "step": 5740
    },
    {
      "epoch": 0.3417789117664511,
      "grad_norm": 0.9799180030822754,
      "learning_rate": 0.00013573132684896312,
      "loss": 0.1623,
      "step": 5760
    },
    {
      "epoch": 0.34296564409897345,
      "grad_norm": 0.3925086259841919,
      "learning_rate": 0.00013548663363308254,
      "loss": 0.1676,
      "step": 5780
    },
    {
      "epoch": 0.3441523764314959,
      "grad_norm": 0.8392041921615601,
      "learning_rate": 0.00013524194041720193,
      "loss": 0.1738,
      "step": 5800
    },
    {
      "epoch": 0.3453391087640183,
      "grad_norm": 2.0266966819763184,
      "learning_rate": 0.00013499724720132135,
      "loss": 0.1713,
      "step": 5820
    },
    {
      "epoch": 0.34652584109654067,
      "grad_norm": 0.605461061000824,
      "learning_rate": 0.00013475255398544075,
      "loss": 0.1744,
      "step": 5840
    },
    {
      "epoch": 0.3477125734290631,
      "grad_norm": 1.0020025968551636,
      "learning_rate": 0.00013450786076956017,
      "loss": 0.1715,
      "step": 5860
    },
    {
      "epoch": 0.34889930576158545,
      "grad_norm": 0.8968877792358398,
      "learning_rate": 0.0001342631675536796,
      "loss": 0.168,
      "step": 5880
    },
    {
      "epoch": 0.3500860380941079,
      "grad_norm": 0.6792104244232178,
      "learning_rate": 0.00013401847433779898,
      "loss": 0.17,
      "step": 5900
    },
    {
      "epoch": 0.3512727704266303,
      "grad_norm": 0.5422672629356384,
      "learning_rate": 0.0001337737811219184,
      "loss": 0.1863,
      "step": 5920
    },
    {
      "epoch": 0.35245950275915267,
      "grad_norm": 1.1948546171188354,
      "learning_rate": 0.00013352908790603782,
      "loss": 0.1614,
      "step": 5940
    },
    {
      "epoch": 0.3536462350916751,
      "grad_norm": 2.3576252460479736,
      "learning_rate": 0.00013328439469015725,
      "loss": 0.166,
      "step": 5960
    },
    {
      "epoch": 0.35483296742419745,
      "grad_norm": 0.841102123260498,
      "learning_rate": 0.0001330397014742766,
      "loss": 0.1745,
      "step": 5980
    },
    {
      "epoch": 0.3560196997567199,
      "grad_norm": 0.439403235912323,
      "learning_rate": 0.00013279500825839603,
      "loss": 0.181,
      "step": 6000
    },
    {
      "epoch": 0.3572064320892423,
      "grad_norm": 0.5716937780380249,
      "learning_rate": 0.00013255031504251545,
      "loss": 0.1629,
      "step": 6020
    },
    {
      "epoch": 0.35839316442176467,
      "grad_norm": 0.5035268664360046,
      "learning_rate": 0.00013230562182663485,
      "loss": 0.1713,
      "step": 6040
    },
    {
      "epoch": 0.3595798967542871,
      "grad_norm": 0.896990954875946,
      "learning_rate": 0.00013206092861075427,
      "loss": 0.1732,
      "step": 6060
    },
    {
      "epoch": 0.36076662908680945,
      "grad_norm": 0.7655892372131348,
      "learning_rate": 0.0001318162353948737,
      "loss": 0.1689,
      "step": 6080
    },
    {
      "epoch": 0.3619533614193319,
      "grad_norm": 1.6921346187591553,
      "learning_rate": 0.0001315715421789931,
      "loss": 0.1899,
      "step": 6100
    },
    {
      "epoch": 0.36314009375185424,
      "grad_norm": 1.13388991355896,
      "learning_rate": 0.0001313268489631125,
      "loss": 0.1878,
      "step": 6120
    },
    {
      "epoch": 0.36432682608437666,
      "grad_norm": 0.9791429042816162,
      "learning_rate": 0.0001310821557472319,
      "loss": 0.1774,
      "step": 6140
    },
    {
      "epoch": 0.3655135584168991,
      "grad_norm": 0.6616879105567932,
      "learning_rate": 0.00013083746253135132,
      "loss": 0.1424,
      "step": 6160
    },
    {
      "epoch": 0.36670029074942145,
      "grad_norm": 1.074009895324707,
      "learning_rate": 0.00013059276931547074,
      "loss": 0.1782,
      "step": 6180
    },
    {
      "epoch": 0.3678870230819439,
      "grad_norm": 0.5891243815422058,
      "learning_rate": 0.00013034807609959014,
      "loss": 0.1774,
      "step": 6200
    },
    {
      "epoch": 0.36907375541446624,
      "grad_norm": 0.7237803936004639,
      "learning_rate": 0.00013010338288370956,
      "loss": 0.1698,
      "step": 6220
    },
    {
      "epoch": 0.37026048774698866,
      "grad_norm": 0.6254242062568665,
      "learning_rate": 0.00012985868966782898,
      "loss": 0.1686,
      "step": 6240
    },
    {
      "epoch": 0.3714472200795111,
      "grad_norm": 1.0693565607070923,
      "learning_rate": 0.00012961399645194837,
      "loss": 0.1641,
      "step": 6260
    },
    {
      "epoch": 0.37263395241203345,
      "grad_norm": 0.6986558437347412,
      "learning_rate": 0.0001293693032360678,
      "loss": 0.1608,
      "step": 6280
    },
    {
      "epoch": 0.3738206847445559,
      "grad_norm": 0.792923092842102,
      "learning_rate": 0.0001291246100201872,
      "loss": 0.1636,
      "step": 6300
    },
    {
      "epoch": 0.37500741707707824,
      "grad_norm": 1.2929229736328125,
      "learning_rate": 0.0001288799168043066,
      "loss": 0.1838,
      "step": 6320
    },
    {
      "epoch": 0.37619414940960066,
      "grad_norm": 0.7715321779251099,
      "learning_rate": 0.000128635223588426,
      "loss": 0.1722,
      "step": 6340
    },
    {
      "epoch": 0.3773808817421231,
      "grad_norm": 1.2694029808044434,
      "learning_rate": 0.00012839053037254542,
      "loss": 0.1735,
      "step": 6360
    },
    {
      "epoch": 0.37856761407464545,
      "grad_norm": 0.7846623063087463,
      "learning_rate": 0.00012814583715666485,
      "loss": 0.1868,
      "step": 6380
    },
    {
      "epoch": 0.3797543464071679,
      "grad_norm": 16.973602294921875,
      "learning_rate": 0.00012790114394078424,
      "loss": 0.3464,
      "step": 6400
    },
    {
      "epoch": 0.38094107873969024,
      "grad_norm": 1.2678704261779785,
      "learning_rate": 0.00012765645072490366,
      "loss": 0.167,
      "step": 6420
    },
    {
      "epoch": 0.38212781107221266,
      "grad_norm": 41.899112701416016,
      "learning_rate": 0.00012741175750902308,
      "loss": 0.2807,
      "step": 6440
    },
    {
      "epoch": 0.3833145434047351,
      "grad_norm": 4.935497760772705,
      "learning_rate": 0.00012716706429314248,
      "loss": 0.3913,
      "step": 6460
    },
    {
      "epoch": 0.38450127573725745,
      "grad_norm": 62.05120849609375,
      "learning_rate": 0.00012692237107726187,
      "loss": 0.2166,
      "step": 6480
    },
    {
      "epoch": 0.3856880080697799,
      "grad_norm": 6.091353416442871,
      "learning_rate": 0.0001266776778613813,
      "loss": 0.2494,
      "step": 6500
    },
    {
      "epoch": 0.38687474040230224,
      "grad_norm": 1.0573209524154663,
      "learning_rate": 0.0001264329846455007,
      "loss": 0.1814,
      "step": 6520
    },
    {
      "epoch": 0.38806147273482466,
      "grad_norm": 1.1235077381134033,
      "learning_rate": 0.00012618829142962013,
      "loss": 0.1717,
      "step": 6540
    },
    {
      "epoch": 0.3892482050673471,
      "grad_norm": 2.6438918113708496,
      "learning_rate": 0.00012594359821373953,
      "loss": 0.1663,
      "step": 6560
    },
    {
      "epoch": 0.39043493739986945,
      "grad_norm": 1.5034865140914917,
      "learning_rate": 0.00012569890499785895,
      "loss": 0.1699,
      "step": 6580
    },
    {
      "epoch": 0.3916216697323919,
      "grad_norm": 0.8213186860084534,
      "learning_rate": 0.00012545421178197837,
      "loss": 0.166,
      "step": 6600
    },
    {
      "epoch": 0.39280840206491424,
      "grad_norm": 0.9810675382614136,
      "learning_rate": 0.00012520951856609774,
      "loss": 0.1864,
      "step": 6620
    },
    {
      "epoch": 0.39399513439743666,
      "grad_norm": 0.6361470818519592,
      "learning_rate": 0.00012496482535021716,
      "loss": 0.1666,
      "step": 6640
    },
    {
      "epoch": 0.39518186672995903,
      "grad_norm": 0.7041540741920471,
      "learning_rate": 0.00012472013213433658,
      "loss": 0.172,
      "step": 6660
    },
    {
      "epoch": 0.39636859906248145,
      "grad_norm": 1.1377387046813965,
      "learning_rate": 0.000124475438918456,
      "loss": 0.1673,
      "step": 6680
    },
    {
      "epoch": 0.3975553313950039,
      "grad_norm": 0.7107609510421753,
      "learning_rate": 0.0001242307457025754,
      "loss": 0.1605,
      "step": 6700
    },
    {
      "epoch": 0.39874206372752624,
      "grad_norm": 0.804628849029541,
      "learning_rate": 0.00012398605248669482,
      "loss": 0.1668,
      "step": 6720
    },
    {
      "epoch": 0.39992879606004866,
      "grad_norm": 1.0936119556427002,
      "learning_rate": 0.00012374135927081424,
      "loss": 0.1672,
      "step": 6740
    },
    {
      "epoch": 0.40111552839257103,
      "grad_norm": 4.938705921173096,
      "learning_rate": 0.00012349666605493363,
      "loss": 0.1724,
      "step": 6760
    },
    {
      "epoch": 0.40230226072509345,
      "grad_norm": 1.0894315242767334,
      "learning_rate": 0.00012325197283905305,
      "loss": 0.1584,
      "step": 6780
    },
    {
      "epoch": 0.4034889930576159,
      "grad_norm": 1.688414454460144,
      "learning_rate": 0.00012300727962317245,
      "loss": 0.1822,
      "step": 6800
    },
    {
      "epoch": 0.40467572539013824,
      "grad_norm": 0.5168728828430176,
      "learning_rate": 0.00012276258640729187,
      "loss": 0.1623,
      "step": 6820
    },
    {
      "epoch": 0.40586245772266066,
      "grad_norm": 1.1598070859909058,
      "learning_rate": 0.00012251789319141126,
      "loss": 0.1586,
      "step": 6840
    },
    {
      "epoch": 0.40704919005518303,
      "grad_norm": 1.077757477760315,
      "learning_rate": 0.00012227319997553068,
      "loss": 0.1732,
      "step": 6860
    },
    {
      "epoch": 0.40823592238770545,
      "grad_norm": 1.4394081830978394,
      "learning_rate": 0.0001220285067596501,
      "loss": 0.1852,
      "step": 6880
    },
    {
      "epoch": 0.4094226547202279,
      "grad_norm": 1.2819745540618896,
      "learning_rate": 0.00012178381354376951,
      "loss": 0.1644,
      "step": 6900
    },
    {
      "epoch": 0.41060938705275024,
      "grad_norm": 0.7881737351417542,
      "learning_rate": 0.00012153912032788892,
      "loss": 0.1812,
      "step": 6920
    },
    {
      "epoch": 0.41179611938527266,
      "grad_norm": 1.2907514572143555,
      "learning_rate": 0.00012129442711200834,
      "loss": 0.1684,
      "step": 6940
    },
    {
      "epoch": 0.41298285171779503,
      "grad_norm": 1.647422194480896,
      "learning_rate": 0.00012104973389612772,
      "loss": 0.1543,
      "step": 6960
    },
    {
      "epoch": 0.41416958405031745,
      "grad_norm": 0.9219055771827698,
      "learning_rate": 0.00012080504068024714,
      "loss": 0.164,
      "step": 6980
    },
    {
      "epoch": 0.4153563163828399,
      "grad_norm": 1.1529688835144043,
      "learning_rate": 0.00012056034746436655,
      "loss": 0.1915,
      "step": 7000
    },
    {
      "epoch": 0.41654304871536224,
      "grad_norm": 0.7309156656265259,
      "learning_rate": 0.00012031565424848597,
      "loss": 0.165,
      "step": 7020
    },
    {
      "epoch": 0.41772978104788466,
      "grad_norm": 9.753174781799316,
      "learning_rate": 0.00012007096103260538,
      "loss": 0.1893,
      "step": 7040
    },
    {
      "epoch": 0.41891651338040703,
      "grad_norm": 1.3666372299194336,
      "learning_rate": 0.00011982626781672479,
      "loss": 0.1837,
      "step": 7060
    },
    {
      "epoch": 0.42010324571292945,
      "grad_norm": 0.6707636713981628,
      "learning_rate": 0.0001195815746008442,
      "loss": 0.1713,
      "step": 7080
    },
    {
      "epoch": 0.4212899780454519,
      "grad_norm": 1.3516113758087158,
      "learning_rate": 0.00011933688138496361,
      "loss": 0.168,
      "step": 7100
    },
    {
      "epoch": 0.42247671037797424,
      "grad_norm": 0.8270538449287415,
      "learning_rate": 0.00011909218816908301,
      "loss": 0.1791,
      "step": 7120
    },
    {
      "epoch": 0.42366344271049666,
      "grad_norm": 4.664190292358398,
      "learning_rate": 0.00011884749495320242,
      "loss": 0.15,
      "step": 7140
    },
    {
      "epoch": 0.42485017504301903,
      "grad_norm": 1.1409603357315063,
      "learning_rate": 0.00011860280173732184,
      "loss": 0.1512,
      "step": 7160
    },
    {
      "epoch": 0.42603690737554145,
      "grad_norm": 1.805514931678772,
      "learning_rate": 0.00011835810852144124,
      "loss": 0.4022,
      "step": 7180
    },
    {
      "epoch": 0.4272236397080639,
      "grad_norm": 1.7499234676361084,
      "learning_rate": 0.00011811341530556067,
      "loss": 0.1666,
      "step": 7200
    },
    {
      "epoch": 0.42841037204058624,
      "grad_norm": 0.9275690913200378,
      "learning_rate": 0.00011786872208968007,
      "loss": 0.1703,
      "step": 7220
    },
    {
      "epoch": 0.42959710437310866,
      "grad_norm": 0.5231330990791321,
      "learning_rate": 0.00011762402887379948,
      "loss": 0.1651,
      "step": 7240
    },
    {
      "epoch": 0.43078383670563103,
      "grad_norm": 1.2783204317092896,
      "learning_rate": 0.0001173793356579189,
      "loss": 0.171,
      "step": 7260
    },
    {
      "epoch": 0.43197056903815345,
      "grad_norm": 0.6127715706825256,
      "learning_rate": 0.0001171346424420383,
      "loss": 0.1516,
      "step": 7280
    },
    {
      "epoch": 0.4331573013706758,
      "grad_norm": 1.472511649131775,
      "learning_rate": 0.0001168899492261577,
      "loss": 0.1868,
      "step": 7300
    },
    {
      "epoch": 0.43434403370319824,
      "grad_norm": 1.1705501079559326,
      "learning_rate": 0.00011664525601027711,
      "loss": 0.1658,
      "step": 7320
    },
    {
      "epoch": 0.43553076603572066,
      "grad_norm": 1.1600799560546875,
      "learning_rate": 0.00011640056279439653,
      "loss": 0.1935,
      "step": 7340
    },
    {
      "epoch": 0.43671749836824303,
      "grad_norm": 0.8782849907875061,
      "learning_rate": 0.00011615586957851594,
      "loss": 0.1608,
      "step": 7360
    },
    {
      "epoch": 0.43790423070076545,
      "grad_norm": 1.052977204322815,
      "learning_rate": 0.00011591117636263536,
      "loss": 0.1619,
      "step": 7380
    },
    {
      "epoch": 0.4390909630332878,
      "grad_norm": 0.47992339730262756,
      "learning_rate": 0.00011566648314675477,
      "loss": 0.1506,
      "step": 7400
    },
    {
      "epoch": 0.44027769536581024,
      "grad_norm": 1.2783608436584473,
      "learning_rate": 0.00011542178993087418,
      "loss": 0.1684,
      "step": 7420
    },
    {
      "epoch": 0.44146442769833266,
      "grad_norm": 2.090376853942871,
      "learning_rate": 0.0001151770967149936,
      "loss": 0.1795,
      "step": 7440
    },
    {
      "epoch": 0.44265116003085503,
      "grad_norm": 0.5041515231132507,
      "learning_rate": 0.00011493240349911298,
      "loss": 0.1745,
      "step": 7460
    },
    {
      "epoch": 0.44383789236337745,
      "grad_norm": 9.69812297821045,
      "learning_rate": 0.0001146877102832324,
      "loss": 0.1966,
      "step": 7480
    },
    {
      "epoch": 0.4450246246958998,
      "grad_norm": 1.7831993103027344,
      "learning_rate": 0.0001144430170673518,
      "loss": 0.1808,
      "step": 7500
    },
    {
      "epoch": 0.44621135702842224,
      "grad_norm": 0.9546399116516113,
      "learning_rate": 0.00011419832385147123,
      "loss": 0.1739,
      "step": 7520
    },
    {
      "epoch": 0.44739808936094466,
      "grad_norm": 83.06874084472656,
      "learning_rate": 0.00011395363063559063,
      "loss": 0.1583,
      "step": 7540
    },
    {
      "epoch": 0.44858482169346703,
      "grad_norm": 0.8123738765716553,
      "learning_rate": 0.00011370893741971004,
      "loss": 0.1735,
      "step": 7560
    },
    {
      "epoch": 0.44977155402598945,
      "grad_norm": 1.7758125066757202,
      "learning_rate": 0.00011346424420382946,
      "loss": 0.1609,
      "step": 7580
    },
    {
      "epoch": 0.4509582863585118,
      "grad_norm": 0.5192275643348694,
      "learning_rate": 0.00011321955098794887,
      "loss": 0.1649,
      "step": 7600
    },
    {
      "epoch": 0.45214501869103424,
      "grad_norm": 0.8037506341934204,
      "learning_rate": 0.00011297485777206827,
      "loss": 0.1687,
      "step": 7620
    },
    {
      "epoch": 0.45333175102355666,
      "grad_norm": 0.8955836296081543,
      "learning_rate": 0.00011273016455618767,
      "loss": 0.1799,
      "step": 7640
    },
    {
      "epoch": 0.45451848335607903,
      "grad_norm": 1.079813838005066,
      "learning_rate": 0.0001124854713403071,
      "loss": 0.1715,
      "step": 7660
    },
    {
      "epoch": 0.45570521568860145,
      "grad_norm": 1.1410354375839233,
      "learning_rate": 0.0001122407781244265,
      "loss": 0.18,
      "step": 7680
    },
    {
      "epoch": 0.4568919480211238,
      "grad_norm": 18.730350494384766,
      "learning_rate": 0.00011199608490854592,
      "loss": 0.1637,
      "step": 7700
    },
    {
      "epoch": 0.45807868035364624,
      "grad_norm": 1.0099570751190186,
      "learning_rate": 0.00011175139169266533,
      "loss": 0.1683,
      "step": 7720
    },
    {
      "epoch": 0.45926541268616866,
      "grad_norm": 0.8456980586051941,
      "learning_rate": 0.00011150669847678474,
      "loss": 0.1734,
      "step": 7740
    },
    {
      "epoch": 0.46045214501869103,
      "grad_norm": 0.7574126720428467,
      "learning_rate": 0.00011126200526090416,
      "loss": 0.1727,
      "step": 7760
    },
    {
      "epoch": 0.46163887735121345,
      "grad_norm": 2.4323596954345703,
      "learning_rate": 0.00011101731204502355,
      "loss": 0.1573,
      "step": 7780
    },
    {
      "epoch": 0.4628256096837358,
      "grad_norm": 0.8543254137039185,
      "learning_rate": 0.00011077261882914296,
      "loss": 0.1775,
      "step": 7800
    },
    {
      "epoch": 0.46401234201625824,
      "grad_norm": 3.1066434383392334,
      "learning_rate": 0.00011052792561326237,
      "loss": 0.1586,
      "step": 7820
    },
    {
      "epoch": 0.4651990743487806,
      "grad_norm": 1.8382399082183838,
      "learning_rate": 0.00011028323239738179,
      "loss": 0.1734,
      "step": 7840
    },
    {
      "epoch": 0.46638580668130303,
      "grad_norm": 2.1557140350341797,
      "learning_rate": 0.0001100385391815012,
      "loss": 0.1717,
      "step": 7860
    },
    {
      "epoch": 0.46757253901382545,
      "grad_norm": 0.6277376413345337,
      "learning_rate": 0.00010979384596562062,
      "loss": 0.1662,
      "step": 7880
    },
    {
      "epoch": 0.4687592713463478,
      "grad_norm": 1.2579158544540405,
      "learning_rate": 0.00010954915274974003,
      "loss": 0.1815,
      "step": 7900
    },
    {
      "epoch": 0.46994600367887024,
      "grad_norm": 2.0366077423095703,
      "learning_rate": 0.00010930445953385943,
      "loss": 0.1662,
      "step": 7920
    },
    {
      "epoch": 0.4711327360113926,
      "grad_norm": 0.7427613735198975,
      "learning_rate": 0.00010905976631797883,
      "loss": 0.167,
      "step": 7940
    },
    {
      "epoch": 0.472319468343915,
      "grad_norm": 7.9315266609191895,
      "learning_rate": 0.00010881507310209823,
      "loss": 0.1906,
      "step": 7960
    },
    {
      "epoch": 0.47350620067643745,
      "grad_norm": 0.747260570526123,
      "learning_rate": 0.00010857037988621766,
      "loss": 0.1511,
      "step": 7980
    },
    {
      "epoch": 0.4746929330089598,
      "grad_norm": 14.752504348754883,
      "learning_rate": 0.00010832568667033706,
      "loss": 0.1692,
      "step": 8000
    },
    {
      "epoch": 0.4746929330089598,
      "eval_f1_macro": 0.5076618154656621,
      "eval_f1_micro": 0.6171833100933176,
      "eval_hamming_loss": 0.14276,
      "eval_loss": 0.1727403998374939,
      "eval_runtime": 2549.5716,
      "eval_samples_per_second": 1.961,
      "eval_steps_per_second": 0.49,
      "eval_subset_accuracy": 0.4366,
      "step": 8000
    }
  ],
  "logging_steps": 20,
  "max_steps": 16853,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 8000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.8474678817154662e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
