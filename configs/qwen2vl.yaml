# Example configuration for Qwen2-VL training on MMHS150K
# These values mirror the script defaults; use them as reference when passing CLI flags.

train_csv: data/mmhs150k/train.csv
val_csv: data/mmhs150k/val.csv
test_csv: data/mmhs150k/test.csv
image_root: data/mmhs150k/images
class_names: data/mmhs150k/class_names.txt

out_dir: runs/qwen2vl_lora
model_id: Qwen/Qwen2-VL-2B-Instruct
use_lora: true
load_in_4bit: false

num_train_epochs: 1
per_device_train_batch_size: 4
per_device_eval_batch_size: 4
gradient_accumulation_steps: 2
learning_rate: 2e-4
warmup_ratio: 0.03

# LoRA specifics
lora_r: 4
lora_alpha: 32
lora_dropout: 0.05
lora_target_modules: q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj
